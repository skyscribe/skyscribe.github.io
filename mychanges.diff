diff --git a/.gitignore b/.gitignore
index 5c4866d..456a09c 100644
--- a/.gitignore
+++ b/.gitignore
@@ -1,14 +1,3 @@
-*.gem
-*.sublime-project
-*.sublime-workspace
-.bundle
-.DS_Store
-.jekyll-metadata
-.sass-cache
-_asset_bundler_cache
+*.swp
 _site
-codekit-config.json
-example/_site
-Gemfile.lock
-node_modules
-npm-debug.log*
\ No newline at end of file
+_deploy
diff --git a/Gemfile b/Gemfile
index 4a06f4a..addedaa 100644
--- a/Gemfile
+++ b/Gemfile
@@ -8,5 +8,7 @@ group :jekyll_plugins do
     gem "jekyll-gist"
     gem "jekyll-feed"
     gem "jekyll-archives"
+    gem "jekyll-compose"
+    gem "jekyll-plantuml"
     gem "jemoji"
 end
diff --git a/Gemfile.lock b/Gemfile.lock
new file mode 100644
index 0000000..47c620e
--- /dev/null
+++ b/Gemfile.lock
@@ -0,0 +1,213 @@
+GEM
+  remote: https://rubygems.org/
+  specs:
+    activesupport (4.2.8)
+      i18n (~> 0.7)
+      minitest (~> 5.1)
+      thread_safe (~> 0.3, >= 0.3.4)
+      tzinfo (~> 1.1)
+    addressable (2.5.1)
+      public_suffix (~> 2.0, >= 2.0.2)
+    coffee-script (2.4.1)
+      coffee-script-source
+      execjs
+    coffee-script-source (1.12.2)
+    colorator (1.1.0)
+    ethon (0.10.1)
+      ffi (>= 1.3.0)
+    execjs (2.7.0)
+    faraday (0.12.1)
+      multipart-post (>= 1.2, < 3)
+    ffi (1.9.18)
+    forwardable-extended (2.6.0)
+    gemoji (3.0.0)
+    github-pages (141)
+      activesupport (= 4.2.8)
+      github-pages-health-check (= 1.3.4)
+      jekyll (= 3.4.3)
+      jekyll-avatar (= 0.4.2)
+      jekyll-coffeescript (= 1.0.1)
+      jekyll-default-layout (= 0.1.4)
+      jekyll-feed (= 0.9.2)
+      jekyll-gist (= 1.4.0)
+      jekyll-github-metadata (= 2.4.0)
+      jekyll-mentions (= 1.2.0)
+      jekyll-optional-front-matter (= 0.1.2)
+      jekyll-paginate (= 1.1.0)
+      jekyll-readme-index (= 0.1.0)
+      jekyll-redirect-from (= 0.12.1)
+      jekyll-relative-links (= 0.4.1)
+      jekyll-sass-converter (= 1.5.0)
+      jekyll-seo-tag (= 2.2.3)
+      jekyll-sitemap (= 1.0.0)
+      jekyll-swiss (= 0.4.0)
+      jekyll-theme-architect (= 0.0.4)
+      jekyll-theme-cayman (= 0.0.4)
+      jekyll-theme-dinky (= 0.0.4)
+      jekyll-theme-hacker (= 0.0.4)
+      jekyll-theme-leap-day (= 0.0.4)
+      jekyll-theme-merlot (= 0.0.4)
+      jekyll-theme-midnight (= 0.0.4)
+      jekyll-theme-minimal (= 0.0.4)
+      jekyll-theme-modernist (= 0.0.4)
+      jekyll-theme-primer (= 0.2.1)
+      jekyll-theme-slate (= 0.0.4)
+      jekyll-theme-tactile (= 0.0.4)
+      jekyll-theme-time-machine (= 0.0.4)
+      jekyll-titles-from-headings (= 0.2.0)
+      jemoji (= 0.8.0)
+      kramdown (= 1.13.2)
+      liquid (= 3.0.6)
+      listen (= 3.0.6)
+      mercenary (~> 0.3)
+      minima (= 2.1.1)
+      rouge (= 1.11.1)
+      terminal-table (~> 1.4)
+    github-pages-health-check (1.3.4)
+      addressable (~> 2.3)
+      net-dns (~> 0.8)
+      octokit (~> 4.0)
+      public_suffix (~> 2.0)
+      typhoeus (~> 0.7)
+    html-pipeline (2.6.0)
+      activesupport (>= 2)
+      nokogiri (>= 1.4)
+    i18n (0.8.6)
+    jekyll (3.4.3)
+      addressable (~> 2.4)
+      colorator (~> 1.0)
+      jekyll-sass-converter (~> 1.0)
+      jekyll-watch (~> 1.1)
+      kramdown (~> 1.3)
+      liquid (~> 3.0)
+      mercenary (~> 0.3.3)
+      pathutil (~> 0.9)
+      rouge (~> 1.7)
+      safe_yaml (~> 1.0)
+    jekyll-archives (2.1.1)
+      jekyll (>= 2.4)
+    jekyll-avatar (0.4.2)
+      jekyll (~> 3.0)
+    jekyll-coffeescript (1.0.1)
+      coffee-script (~> 2.2)
+    jekyll-compose (0.5.0)
+      jekyll (>= 3.0.0)
+    jekyll-default-layout (0.1.4)
+      jekyll (~> 3.0)
+    jekyll-feed (0.9.2)
+      jekyll (~> 3.3)
+    jekyll-gist (1.4.0)
+      octokit (~> 4.2)
+    jekyll-github-metadata (2.4.0)
+      jekyll (~> 3.1)
+      octokit (~> 4.0, != 4.4.0)
+    jekyll-mentions (1.2.0)
+      activesupport (~> 4.0)
+      html-pipeline (~> 2.3)
+      jekyll (~> 3.0)
+    jekyll-optional-front-matter (0.1.2)
+      jekyll (~> 3.0)
+    jekyll-paginate (1.1.0)
+    jekyll-plantuml (1.3.3)
+      jekyll (> 2.0)
+    jekyll-readme-index (0.1.0)
+      jekyll (~> 3.0)
+    jekyll-redirect-from (0.12.1)
+      jekyll (~> 3.3)
+    jekyll-relative-links (0.4.1)
+      jekyll (~> 3.3)
+    jekyll-sass-converter (1.5.0)
+      sass (~> 3.4)
+    jekyll-seo-tag (2.2.3)
+      jekyll (~> 3.3)
+    jekyll-sitemap (1.0.0)
+      jekyll (~> 3.3)
+    jekyll-swiss (0.4.0)
+    jekyll-theme-architect (0.0.4)
+      jekyll (~> 3.3)
+    jekyll-theme-cayman (0.0.4)
+      jekyll (~> 3.3)
+    jekyll-theme-dinky (0.0.4)
+      jekyll (~> 3.3)
+    jekyll-theme-hacker (0.0.4)
+      jekyll (~> 3.3)
+    jekyll-theme-leap-day (0.0.4)
+      jekyll (~> 3.3)
+    jekyll-theme-merlot (0.0.4)
+      jekyll (~> 3.3)
+    jekyll-theme-midnight (0.0.4)
+      jekyll (~> 3.3)
+    jekyll-theme-minimal (0.0.4)
+      jekyll (~> 3.3)
+    jekyll-theme-modernist (0.0.4)
+      jekyll (~> 3.3)
+    jekyll-theme-primer (0.2.1)
+      jekyll (~> 3.3)
+    jekyll-theme-slate (0.0.4)
+      jekyll (~> 3.3)
+    jekyll-theme-tactile (0.0.4)
+      jekyll (~> 3.3)
+    jekyll-theme-time-machine (0.0.4)
+      jekyll (~> 3.3)
+    jekyll-titles-from-headings (0.2.0)
+      jekyll (~> 3.3)
+    jekyll-watch (1.5.0)
+      listen (~> 3.0, < 3.1)
+    jemoji (0.8.0)
+      activesupport (~> 4.0)
+      gemoji (~> 3.0)
+      html-pipeline (~> 2.2)
+      jekyll (>= 3.0)
+    kramdown (1.13.2)
+    liquid (3.0.6)
+    listen (3.0.6)
+      rb-fsevent (>= 0.9.3)
+      rb-inotify (>= 0.9.7)
+    mercenary (0.3.6)
+    mini_portile2 (2.2.0)
+    minima (2.1.1)
+      jekyll (~> 3.3)
+    minitest (5.10.2)
+    multipart-post (2.0.0)
+    net-dns (0.8.0)
+    nokogiri (1.8.0)
+      mini_portile2 (~> 2.2.0)
+    octokit (4.7.0)
+      sawyer (~> 0.8.0, >= 0.5.3)
+    pathutil (0.14.0)
+      forwardable-extended (~> 2.6)
+    public_suffix (2.0.5)
+    rb-fsevent (0.10.2)
+    rb-inotify (0.9.10)
+      ffi (>= 0.5.0, < 2)
+    rouge (1.11.1)
+    safe_yaml (1.0.4)
+    sass (3.4.25)
+    sawyer (0.8.1)
+      addressable (>= 2.3.5, < 2.6)
+      faraday (~> 0.8, < 1.0)
+    terminal-table (1.8.0)
+      unicode-display_width (~> 1.1, >= 1.1.1)
+    thread_safe (0.3.6)
+    typhoeus (0.8.0)
+      ethon (>= 0.8.0)
+    tzinfo (1.2.3)
+      thread_safe (~> 0.1)
+    unicode-display_width (1.3.0)
+
+PLATFORMS
+  ruby
+
+DEPENDENCIES
+  github-pages
+  jekyll-archives
+  jekyll-compose
+  jekyll-feed
+  jekyll-gist
+  jekyll-paginate
+  jekyll-plantuml
+  jekyll-sitemap
+  jemoji
+
+BUNDLED WITH
+   1.15.1
diff --git a/Makefile b/Makefile
new file mode 100644
index 0000000..64fc39b
--- /dev/null
+++ b/Makefile
@@ -0,0 +1,26 @@
+deployDir=$(shell pwd)/_deploy
+siteDir=$(shell pwd)/_site
+siteUrl=https://github.com/skyscribe/skyscribe.github.io.git
+now=$(shell date "+%Y-%m-%d_%H:%M:%S")
+
+.PNONY: setup deploy
+
+setup: 
+	rm -fr $(deployDir)
+	mkdir $(deployDir) 
+	cd $(deployDir)
+	git init
+	echo "Dummy content" > index.html
+	git add .
+	git commit -m "dummy script init"
+	git remote add origin $(siteUrl)
+	echo "setup completed for $(deployDir)"
+
+deploy:
+	cd $(deployDir)
+	git pull
+	cp -r $(siteDir) $(deployDir)
+	git add -A
+	git commit -m "site updated at $(now)"
+	git push origin github-pages --force 
+	echo "deploy complete"
diff --git a/Rakefile b/Rakefile
index e50d89f..43cd2b6 100644
--- a/Rakefile
+++ b/Rakefile
@@ -1,75 +1,397 @@
-require "bundler/gem_tasks"
-require "jekyll"
-require "listen"
-
-def listen_ignore_paths(base, options)
-  [
-    /_config\.ya?ml/,
-    /_site/,
-    /\.jekyll-metadata/
-  ]
-end
-
-def listen_handler(base, options)
-  site = Jekyll::Site.new(options)
-  Jekyll::Command.process_site(site)
-  proc do |modified, added, removed|
-    t = Time.now
-    c = modified + added + removed
-    n = c.length
-    relative_paths = c.map{ |p| Pathname.new(p).relative_path_from(base).to_s }
-    print Jekyll.logger.message("Regenerating:", "#{relative_paths.join(", ")} changed... ")
-    begin
-      Jekyll::Command.process_site(site)
-      puts "regenerated in #{Time.now - t} seconds."
-    rescue => e
-      puts "error:"
-      Jekyll.logger.warn "Error:", e.message
-      Jekyll.logger.warn "Error:", "Run jekyll build --trace for more information."
-    end
+## Copied from octopress2
+require "rubygems"
+require "bundler/setup"
+require "stringex"
+
+## -- Rsync Deploy config -- ##
+# Be sure your public key is listed in your server's ~/.ssh/authorized_keys file
+ssh_user       = "user@domain.com"
+ssh_port       = "22"
+document_root  = "~/website.com/"
+rsync_delete   = true
+deploy_default = "push"
+
+# This will be configured for you when you run config_deploy
+#deploy_branch  = "gh-pages"
+deploy_branch  = "master"
+
+## -- Misc Configs -- ##
+
+public_dir      = "_site"    # compiled site directory
+source_dir      = "source"    # source file directory
+blog_index_dir  = 'source'    # directory for your blog's index page (if you put your index in source/blog/index.html, set this to 'source/blog')
+deploy_dir      = "_deploy"   # deploy directory (for Github pages deployment)
+stash_dir       = "_stash"    # directory to stash posts for speedy generation
+posts_dir       = "_posts"    # directory for blog files
+themes_dir      = ".themes"   # directory for blog files
+new_post_ext    = "markdown"  # default new post file extension when using the new_post task
+new_page_ext    = "markdown"  # default new page file extension when using the new_page task
+server_port     = "4000"      # port for preview server eg. localhost:4000
+
+
+desc "Initial setup for Octopress: copies the default theme into the path of Jekyll's generator. Rake install defaults to rake install[classic] to install a different theme run rake install[some_theme_name]"
+task :install, :theme do |t, args|
+  if File.directory?(source_dir) || File.directory?("sass")
+    abort("rake aborted!") if ask("A theme is already installed, proceeding will overwrite existing files. Are you sure?", ['y', 'n']) == 'n'
   end
+  # copy theme into working Jekyll directories
+  theme = args.theme || 'classic'
+  puts "## Copying "+theme+" theme into ./#{source_dir} and ./sass"
+  mkdir_p source_dir
+  cp_r "#{themes_dir}/#{theme}/source/.", source_dir
+  mkdir_p "sass"
+  cp_r "#{themes_dir}/#{theme}/sass/.", "sass"
+  mkdir_p "#{source_dir}/#{posts_dir}"
+  mkdir_p public_dir
 end
 
+#######################
+# Working with Jekyll #
+#######################
+
+desc "Generate jekyll site"
+task :generate do
+  raise "### You haven't set anything up yet. First run `rake install` to set up an Octopress theme." unless File.directory?(source_dir)
+  puts "## Generating Site with Jekyll"
+  system "compass compile --css-dir #{source_dir}/stylesheets"
+  system "jekyll "
+end
+
+desc "Watch the site and regenerate when it changes"
+task :watch do
+  raise "### You haven't set anything up yet. First run `rake install` to set up an Octopress theme." unless File.directory?(source_dir)
+  puts "Starting to watch source with Jekyll and Compass."
+  system "compass compile --css-dir #{source_dir}/stylesheets" unless File.exist?("#{source_dir}/stylesheets/screen.css")
+  jekyllPid = Process.spawn({"OCTOPRESS_ENV"=>"preview"}, "jekyll --auto")
+  compassPid = Process.spawn("compass watch")
+
+  trap("INT") {
+    [jekyllPid, compassPid].each { |pid| Process.kill(9, pid) rescue Errno::ESRCH }
+    exit 0
+  }
+
+  [jekyllPid, compassPid].each { |pid| Process.wait(pid) }
+end
+
+desc "preview the site in a web browser"
 task :preview do
-  base = Pathname.new('.').expand_path
-  options = {
-    "source"        => base.join('test').to_s,
-    "destination"   => base.join('test/_site').to_s,
-    "force_polling" => false,
-    "serving"       => true,
-    "theme"         => "minimal-mistakes-jekyll"
+  raise "### You haven't set anything up yet. First run `rake install` to set up an Octopress theme." unless File.directory?(source_dir)
+  puts "Starting to watch source with Jekyll and Compass. Starting Rack on port #{server_port}"
+  system "compass compile --css-dir #{source_dir}/stylesheets" unless File.exist?("#{source_dir}/stylesheets/screen.css")
+  jekyllPid = Process.spawn({"OCTOPRESS_ENV"=>"preview"}, "jekyll --auto")
+  compassPid = Process.spawn("compass watch")
+  rackupPid = Process.spawn("rackup --port #{server_port}")
+
+  trap("INT") {
+    [jekyllPid, compassPid, rackupPid].each { |pid| Process.kill(9, pid) rescue Errno::ESRCH }
+    exit 0
   }
 
-  options = Jekyll.configuration(options)
-
-  ENV["LISTEN_GEM_DEBUGGING"] = "1"
-  listener = Listen.to(
-    base.join("_includes"),
-    base.join("_layouts"),
-    base.join("_sass"),
-    base.join("assets"),
-    options["source"],
-    :ignore => listen_ignore_paths(base, options),
-    :force_polling => options['force_polling'],
-    &(listen_handler(base, options))
-  )
-
-  begin
-    listener.start
-    Jekyll.logger.info "Auto-regeneration:", "enabled for '#{options["source"]}'"
-
-    unless options['serving']
-      trap("INT") do
-        listener.stop
-        puts "     Halting auto-regeneration."
-        exit 0
-      end
+  [jekyllPid, compassPid, rackupPid].each { |pid| Process.wait(pid) }
+end
+
+# usage rake new_post[my-new-post] or rake new_post['my new post'] or rake new_post (defaults to "new-post")
+desc "Begin a new post in #{source_dir}/#{posts_dir}"
+task :new_post, :title do |t, args|
+  if args.title
+    title = args.title
+  else
+    title = get_stdin("Enter a title for your post: ")
+  end
+  raise "### You haven't set anything up yet. First run `rake install` to set up an Octopress theme." unless File.directory?(source_dir)
+  mkdir_p "#{source_dir}/#{posts_dir}"
+  filename = "#{source_dir}/#{posts_dir}/#{Time.now.strftime('%Y-%m-%d')}-#{title.to_url}.#{new_post_ext}"
+  if File.exist?(filename)
+    abort("rake aborted!") if ask("#{filename} already exists. Do you want to overwrite?", ['y', 'n']) == 'n'
+  end
+  puts "Creating new post: #{filename}"
+  open(filename, 'w') do |post|
+    post.puts "---"
+    post.puts "layout: post"
+    post.puts "title: \"#{title.gsub(/&/,'&amp;')}\""
+    post.puts "date: #{Time.now.strftime('%Y-%m-%d %H:%M')}"
+    post.puts "comments: true"
+    post.puts "categories: "
+    post.puts "---"
+  end
+  system "vim #{filename}"
+end
+
+# usage rake new_page[my-new-page] or rake new_page[my-new-page.html] or rake new_page (defaults to "new-page.markdown")
+desc "Create a new page in #{source_dir}/(filename)/index.#{new_page_ext}"
+task :new_page, :filename do |t, args|
+  raise "### You haven't set anything up yet. First run `rake install` to set up an Octopress theme." unless File.directory?(source_dir)
+  args.with_defaults(:filename => 'new-page')
+  page_dir = [source_dir]
+  if args.filename.downcase =~ /(^.+\/)?(.+)/
+    filename, dot, extension = $2.rpartition('.').reject(&:empty?)         # Get filename and extension
+    title = filename
+    page_dir.concat($1.downcase.sub(/^\//, '').split('/')) unless $1.nil?  # Add path to page_dir Array
+    if extension.nil?
+      page_dir << filename
+      filename = "index"
+    end
+    extension ||= new_page_ext
+    page_dir = page_dir.map! { |d| d = d.to_url }.join('/')                # Sanitize path
+    filename = filename.downcase.to_url
+
+    mkdir_p page_dir
+    file = "#{page_dir}/#{filename}.#{extension}"
+    if File.exist?(file)
+      abort("rake aborted!") if ask("#{file} already exists. Do you want to overwrite?", ['y', 'n']) == 'n'
+    end
+    puts "Creating new page: #{file}"
+    open(file, 'w') do |page|
+      page.puts "---"
+      page.puts "layout: page"
+      page.puts "title: \"#{title}\""
+      page.puts "date: #{Time.now.strftime('%Y-%m-%d %H:%M')}"
+      page.puts "comments: true"
+      page.puts "sharing: true"
+      page.puts "footer: true"
+      page.puts "---"
+    end
+  else
+    puts "Syntax error: #{args.filename} contains unsupported characters"
+  end
+end
+
+# usage rake isolate[my-post]
+desc "Move all other posts than the one currently being worked on to a temporary stash location (stash) so regenerating the site happens much more quickly."
+task :isolate, :filename do |t, args|
+  stash_dir = "#{source_dir}/#{stash_dir}"
+  FileUtils.mkdir(stash_dir) unless File.exist?(stash_dir)
+  Dir.glob("#{source_dir}/#{posts_dir}/*.*") do |post|
+    FileUtils.mv post, stash_dir unless post.include?(args.filename)
+  end
+end
+
+desc "Move all stashed posts back into the posts directory, ready for site generation."
+task :integrate do
+  FileUtils.mv Dir.glob("#{source_dir}/#{stash_dir}/*.*"), "#{source_dir}/#{posts_dir}/"
+end
+
+desc "Clean out caches: .pygments-cache, .gist-cache, .sass-cache"
+task :clean do
+  rm_rf [".pygments-cache/**", ".gist-cache/**", ".sass-cache/**", "source/stylesheets/screen.css"]
+end
+
+desc "Move sass to sass.old, install sass theme updates, replace sass/custom with sass.old/custom"
+task :update_style, :theme do |t, args|
+  theme = args.theme || 'classic'
+  if File.directory?("sass.old")
+    puts "removed existing sass.old directory"
+    rm_r "sass.old", :secure=>true
+  end
+  mv "sass", "sass.old"
+  puts "## Moved styles into sass.old/"
+  cp_r "#{themes_dir}/"+theme+"/sass/", "sass"
+  cp_r "sass.old/custom/.", "sass/custom"
+  puts "## Updated Sass ##"
+end
+
+desc "Move source to source.old, install source theme updates, replace source/_includes/navigation.html with source.old's navigation"
+task :update_source, :theme do |t, args|
+  theme = args.theme || 'classic'
+  if File.directory?("#{source_dir}.old")
+    puts "## Removed existing #{source_dir}.old directory"
+    rm_r "#{source_dir}.old", :secure=>true
+  end
+  mkdir "#{source_dir}.old"
+  cp_r "#{source_dir}/.", "#{source_dir}.old"
+  puts "## Copied #{source_dir} into #{source_dir}.old/"
+  cp_r "#{themes_dir}/"+theme+"/source/.", source_dir, :remove_destination=>true
+  cp_r "#{source_dir}.old/_includes/custom/.", "#{source_dir}/_includes/custom/", :remove_destination=>true
+  cp "#{source_dir}.old/favicon.png", source_dir
+  mv "#{source_dir}/index.html", "#{blog_index_dir}", :force=>true if blog_index_dir != source_dir
+  cp "#{source_dir}.old/index.html", source_dir if blog_index_dir != source_dir && File.exists?("#{source_dir}.old/index.html")
+  puts "## Updated #{source_dir} ##"
+end
+
+##############
+# Deploying  #
+##############
 
-      loop { sleep 1000 }
+desc "Default deploy task"
+task :deploy do
+  # Check if preview posts exist, which should not be published
+  if File.exists?(".preview-mode")
+    puts "## Found posts in preview mode, regenerating files ..."
+    File.delete(".preview-mode")
+    Rake::Task[:generate].execute
+  end
+
+  Rake::Task[:copydot].invoke(source_dir, public_dir)
+  Rake::Task["#{deploy_default}"].execute
+end
+
+desc "Generate website and deploy"
+task :gen_deploy => [:integrate, :generate, :deploy] do
+end
+
+desc "copy dot files for deployment"
+task :copydot, :source, :dest do |t, args|
+  FileList["#{args.source}/**/.*"].exclude("**/.", "**/..", "**/.DS_Store", "**/._*").each do |file|
+    next if File.basename(file) =~ /^\..*\.swp$/ #Ignore swp files
+    cp_r file, file.gsub(/#{args.source}/, "#{args.dest}") unless File.directory?(file)
+  end
+end
+
+desc "Deploy website via rsync"
+task :rsync do
+  exclude = ""
+  if File.exists?('./rsync-exclude')
+    exclude = "--exclude-from '#{File.expand_path('./rsync-exclude')}'"
+  end
+  puts "## Deploying website via Rsync"
+  ok_failed system("rsync -avze 'ssh -p #{ssh_port}' #{exclude} #{rsync_args} #{"--delete" unless rsync_delete == false} #{public_dir}/ #{ssh_user}:#{document_root}")
+end
+
+desc "deploy public directory to github pages"
+multitask :push do
+  puts "## Deploying branch to Github Pages "
+  puts "## Pulling any updates from Github Pages "
+  cd "#{deploy_dir}" do 
+    system "git pull"
+  end
+  (Dir["#{deploy_dir}/*"]).each { |f| rm_rf(f) }
+  Rake::Task[:copydot].invoke(public_dir, deploy_dir)
+  puts "\n## Copying #{public_dir} to #{deploy_dir}"
+  cp_r "#{public_dir}/.", deploy_dir
+  cd "#{deploy_dir}" do
+    system "git add -A"
+    puts "\n## Commiting: Site updated at #{Time.now.utc}"
+    message = "Site updated at #{Time.now.utc}"
+    system "git commit -m \"#{message}\""
+    puts "\n## Pushing generated #{deploy_dir} website"
+    system "git push origin #{deploy_branch} --force"
+    puts "\n## Pushing generated #{deploy_dir} to gitcafe website"
+    system "git push origin_gitcafe #{deploy_branch}:gitcafe-pages --force"
+    puts "\n## Github Pages deploy complete"
+  end
+end
+
+desc "Update configurations to support publishing to root or sub directory"
+task :set_root_dir, :dir do |t, args|
+  puts ">>> !! Please provide a directory, eg. rake config_dir[publishing/subdirectory]" unless args.dir
+  if args.dir
+    if args.dir == "/"
+      dir = ""
+    else
+      dir = "/" + args.dir.sub(/(\/*)(.+)/, "\\2").sub(/\/$/, '');
+    end
+    rakefile = IO.read(__FILE__)
+    rakefile.sub!(/public_dir(\s*)=(\s*)(["'])[\w\-\/]*["']/, "public_dir\\1=\\2\\3public#{dir}\\3")
+    File.open(__FILE__, 'w') do |f|
+      f.write rakefile
+    end
+    compass_config = IO.read('config.rb')
+    compass_config.sub!(/http_path(\s*)=(\s*)(["'])[\w\-\/]*["']/, "http_path\\1=\\2\\3#{dir}/\\3")
+    compass_config.sub!(/http_images_path(\s*)=(\s*)(["'])[\w\-\/]*["']/, "http_images_path\\1=\\2\\3#{dir}/images\\3")
+    compass_config.sub!(/http_fonts_path(\s*)=(\s*)(["'])[\w\-\/]*["']/, "http_fonts_path\\1=\\2\\3#{dir}/fonts\\3")
+    compass_config.sub!(/css_dir(\s*)=(\s*)(["'])[\w\-\/]*["']/, "css_dir\\1=\\2\\3public#{dir}/stylesheets\\3")
+    File.open('config.rb', 'w') do |f|
+      f.write compass_config
     end
-  rescue ThreadError
-    # You pressed Ctrl-C, oh my!
+    jekyll_config = IO.read('_config.yml')
+    jekyll_config.sub!(/^destination:.+$/, "destination: public#{dir}")
+    jekyll_config.sub!(/^subscribe_rss:\s*\/.+$/, "subscribe_rss: #{dir}/atom.xml")
+    jekyll_config.sub!(/^root:.*$/, "root: /#{dir.sub(/^\//, '')}")
+    File.open('_config.yml', 'w') do |f|
+      f.write jekyll_config
+    end
+    rm_rf public_dir
+    mkdir_p "#{public_dir}#{dir}"
+    puts "## Site's root directory is now '/#{dir.sub(/^\//, '')}' ##"
+  end
+end
+
+desc "Set up _deploy folder and deploy branch for Github Pages deployment"
+task :setup_github_pages, :repo do |t, args|
+  if args.repo
+    repo_url = args.repo
+  else
+    puts "Enter the read/write url for your repository"
+    puts "(For example, 'git@github.com:your_username/your_username.github.io)"
+    puts "           or 'https://github.com/your_username/your_username.github.io')"
+    repo_url = get_stdin("Repository url: ")
+  end
+  protocol = (repo_url.match(/(^git)@/).nil?) ? 'https' : 'git'
+  if protocol == 'git'
+    user = repo_url.match(/:([^\/]+)/)[1]
+  else
+    user = repo_url.match(/github\.com\/([^\/]+)/)[1]
+  end
+  branch = (repo_url.match(/\/[\w-]+\.github\.(?:io|com)/).nil?) ? 'gh-pages' : 'master'
+  project = (branch == 'gh-pages') ? repo_url.match(/\/([^\.]+)/)[1] : ''
+  unless (`git remote -v` =~ /origin.+?octopress(?:\.git)?/).nil?
+    # If octopress is still the origin remote (from cloning) rename it to octopress
+    system "git remote rename origin octopress"
+    if branch == 'master'
+      # If this is a user/organization pages repository, add the correct origin remote
+      # and checkout the source branch for committing changes to the blog source.
+      system "git remote add origin #{repo_url}"
+      puts "Added remote #{repo_url} as origin"
+      system "git config branch.master.remote origin"
+      puts "Set origin as default remote"
+      system "git branch -m master source"
+      puts "Master branch renamed to 'source' for committing your blog source files"
+    else
+      unless !public_dir.match("#{project}").nil?
+        system "rake set_root_dir[#{project}]"
+      end
+    end
+  end
+  url = "http://#{user}.github.io"
+  url += "/#{project}" unless project == ''
+  jekyll_config = IO.read('_config.yml')
+  jekyll_config.sub!(/^url:.*$/, "url: #{url}")
+  File.open('_config.yml', 'w') do |f|
+    f.write jekyll_config
+  end
+  rm_rf deploy_dir
+  mkdir deploy_dir
+  cd "#{deploy_dir}" do
+    system "git init"
+    system "echo 'My Octopress Page is coming soon &hellip;' > index.html"
+    system "git add ."
+    system "git commit -m \"Octopress init\""
+    system "git branch -m gh-pages" unless branch == 'master'
+    system "git remote add origin #{repo_url}"
+    rakefile = IO.read(__FILE__)
+    rakefile.sub!(/deploy_branch(\s*)=(\s*)(["'])[\w-]*["']/, "deploy_branch\\1=\\2\\3#{branch}\\3")
+    rakefile.sub!(/deploy_default(\s*)=(\s*)(["'])[\w-]*["']/, "deploy_default\\1=\\2\\3push\\3")
+    File.open(__FILE__, 'w') do |f|
+      f.write rakefile
+    end
+  end
+  puts "\n---\n## Now you can deploy to #{url} with `rake deploy` ##"
+end
+
+def ok_failed(condition)
+  if (condition)
+    puts "OK"
+  else
+    puts "FAILED"
+  end
+end
+
+def get_stdin(message)
+  print message
+  STDIN.gets.chomp
+end
+
+def ask(message, valid_options)
+  if valid_options
+    answer = get_stdin("#{message} #{valid_options.to_s.gsub(/"/, '').gsub(/, /,'/')} ") while !valid_options.include?(answer)
+  else
+    answer = get_stdin(message)
   end
+  answer
+end
 
-  Jekyll::Commands::Serve.process(options)
+desc "list tasks"
+task :list do
+  puts "Tasks: #{(Rake::Task.tasks - [Rake::Task[:list]]).join(', ')}"
+  puts "(type rake -T for more detail)\n\n"
 end
diff --git a/_config.yml b/_config.yml
index 7bdab09..6535244 100644
--- a/_config.yml
+++ b/_config.yml
@@ -11,16 +11,17 @@ title                    : "驭风万里无垠"
 title_separator          : "-"
 name                     : "skyscribe"
 description              : "汇小流以成江海，积跬步以至千里"
-url                      : "https://skyscribe.github.io" # the base hostname & protocol for your site e.g. "https://mmistakes.github.io"
-baseurl                  : "/blog" # the subpath of your site, e.g. "/blog"
+url                      : "http://www.skyscribe.me" # the base hostname & protocol for your site e.g. "https://mmistakes.github.io"
+baseurl                  : "" # the subpath of your site, e.g. "/blog"
 repository               : "skyscribe/skyscribe" # GitHub username/repo-name e.g. "mmistakes/minimal-mistakes"
 teaser                   : # path of fallback teaser image, e.g. "/assets/images/500x300.png"
 breadcrumbs              : false # true, false (default)
-words_per_minute         : 120
+words_per_minute         : 400
 comments:
-  provider               : "disqus" # "discourse", "facebook", "google-plus", "staticman", "custom"
+  provider               : "staticman" # "discourse", "facebook", "google-plus", "staticman", "custom"
   disqus:
     shortname            : "skyscribe"
+
 staticman:
   allowedFields          : ['name', 'email', 'url', 'message']
   branch                 : "master"
@@ -37,6 +38,7 @@ staticman:
       type               : "date"
       options:
         format           : "iso8601" # "iso8601" (default), "timestamp-seconds", "timestamp-milliseconds"
+
 atom_feed:
   path                   : # blank (default) uses feed.xml
 
@@ -52,16 +54,16 @@ twitter:
 
 # Analytics
 analytics:
-  provider               : false # false (default), "google", "google-universal", "custom"
+  provider               : "google" # false (default), "google", "google-universal", "custom"
   google:
-    tracking_id          :
+    tracking_id          : UA-101727556-1
 
 
 # Site Author
 author:
   name             : "Fei Yan"
-  avatar           : # path of avatar image, e.g. "/assets/images/bio-photo.jpg"
-  bio              : "An curious programmer"
+  avatar           : "/assets/images/me.jpg"# path of avatar image, e.g. "/assets/images/bio-photo.jpg"
+  bio              : "A curious programmer"
   location         : "Hangzhou"
   email            : "skyscribe.yf@gmail.com"
   uri              :
@@ -71,18 +73,18 @@ author:
   flickr           :
   facebook         :
   foursquare       :
-  github           :
+  github           : skyscribe
   google_plus      :
   keybase          :
   instagram        :
   lastfm           :
-  linkedin         :
+  linkedin         : skyscribe
   pinterest        :
   soundcloud       :
-  stackoverflow    : # "123456/username" (the last part of your profile url, e.g. http://stackoverflow.com/users/123456/username)
+  stackoverflow    : "222167/fei" # "123456/username" (the last part of your profile url, e.g. http://stackoverflow.com/users/123456/username)
   steam            :
   tumblr           :
-  twitter          :
+  twitter          : "skyscribe"
   vine             :
   weibo            :
   xing             :
@@ -153,7 +155,7 @@ sass:
 
 
 # Outputting
-permalink: /:categories/:title/
+permalink: /post/:year/:month/:day/:title/
 paginate: 5 # amount of posts to show
 paginate_path: /page:num/
 timezone: # http://en.wikipedia.org/wiki/List_of_tz_database_time_zones
@@ -166,6 +168,7 @@ gems:
   - jekyll-gist
   - jekyll-feed
   - jekyll-archives
+  - jekyll-plantuml
   - jemoji
 
 # mimic GitHub Pages with --safe
@@ -188,10 +191,10 @@ whitelist:
 #  - <base_path/categories/my-awesome-category/index.html ~> path: /categories/
 #  - <base_path/my-awesome-category/index.html ~> path: /
 category_archive:
-  type: liquid
+  type: jekyll-archives
   path: /categories/
 tag_archive:
-  type: liquid
+  type: jekyll-archives
   path: /tags/
 
 # https://github.com/jekyll/jekyll-archives
@@ -225,6 +228,9 @@ defaults:
       layout: single
       author_profile: true
       read_time: true
-      comments: # true
+      comments:  true
       share: true
       related: true
+
+# Github metadata from https://github.com/DIYbiosphere/sphere/issues/140
+github: [metadata]
diff --git a/_data/comments/placeholder b/_data/comments/placeholder
new file mode 100644
index 0000000..e69de29
diff --git a/_data/navigation.yml b/_data/navigation.yml
index fe781d3..5203f1d 100644
--- a/_data/navigation.yml
+++ b/_data/navigation.yml
@@ -1,10 +1,24 @@
 # main links
 main:
-  - title: "About"
-    url: /about/
-  - title: "Posts"
+  - title: "编程相关"
+    url: /categories/programming/index.html
+  - title: "个人笔记"
+    url: /categories/notes/index.html
+  - title: "工具相关"
+    url: /categories/tools/index.html
+  - title: "软件工程"
+    url: /categories/engineering/index.html
+  - title: "软件设计"
+    url: /categories/design/index.html
+  - title: "Haskell"
+    url: /categories/haskell/index.html
+  - title: "C++"
+    url: /categories/cpp/index.html
+  - title: "按年份归档"
     url: /year-archive/index.html
-  - title: "Tags"
+  - title: "标签汇总"
     url: /tags/index.html
-  - title: "Categories"
+  - title: "所有分类"
     url: /categories/index.html
+  - title: "关于..."
+    url: /about/
diff --git a/_includes/footer.html b/_includes/footer.html
index 8fe13bb..c3f527d 100644
--- a/_includes/footer.html
+++ b/_includes/footer.html
@@ -19,4 +19,4 @@
   </ul>
 </div>
 
-<div class="page__footer-copyright">&copy; {{ site.time | date: '%Y' }} {{ site.name | default: site.title }}. {{ site.data.ui-text[site.locale].powered_by | default: "Powered by" }} <a href="http://jekyllrb.com" rel="nofollow">Jekyll</a> &amp; <a href="https://mademistakes.com/work/minimal-mistakes-jekyll-theme/" rel="nofollow">Minimal Mistakes</a>.</div>
\ No newline at end of file
+<div class="page__footer-copyright"><a href=https://en.wikipedia.org/wiki/Creative_Commons_license#Types_of_licenses><img src=https://upload.wikimedia.org/wikipedia/commons/d/d0/CC-BY-SA_icon.svg></a> {{ site.time | date: '%Y' }} {{ site.name | default: site.title }}. {{ site.data.ui-text[site.locale].powered_by | default: "Powered by" }} <a href="http://jekyllrb.com" rel="nofollow">Jekyll</a> &amp; <a href="https://mademistakes.com/work/minimal-mistakes-jekyll-theme/" rel="nofollow">Minimal Mistakes</a></div>
diff --git a/_includes/read-time.html b/_includes/read-time.html
index df88d52..20b661f 100644
--- a/_includes/read-time.html
+++ b/_includes/read-time.html
@@ -1,15 +1,21 @@
 {% assign words_per_minute = site.words_per_minute | default: 200 %}
 
 {% if post.read_time %}
-  {% assign words = post.content | strip_html | number_of_words %}
+  {% assign words = post.content | strip_html | strip_newlines | size %}
 {% elsif page.read_time %}
-  {% assign words = page.content | strip_html | number_of_words %}
+  {% assign words = page.content | strip_html | strip_newlines | size %}
 {% endif %}
 
-{% if words < words_per_minute %}
-  {{ site.data.ui-text[site.locale].less_than | default: "less than" }} 1 {{ site.data.ui-text[site.locale].minute_read | default: "minute read" }}
-{% elsif words == words_per_minute %}
-  1 {{ site.data.ui-text[site.locale].minute_read | default: "minute read" }}
-{% else %}
-  {{ words | divided_by:words_per_minute }} {{ site.data.ui-text[site.locale].minute_read | default: "minute read" }}
-{% endif %}
\ No newline at end of file
+{% comment %} TODO: move those to ui_data text? {% endcomment %}
+本文有 {{words}} 字，大约需要 {{words || divided_by:words_per_minute }} 分钟可以读完
+
+{% comment %}
+    {% if words < words_per_minute %}
+      {{ site.data.ui-text[site.locale].less_than | default: "less than" }} 1 {{ site.data.ui-text[site.locale].minute_read | default: "minute read" }}
+    {% elsif words == words_per_minute %}
+      1 {{ site.data.ui-text[site.locale].minute_read | default: "minute read" }}
+    {% else %}
+      {{ words | divided_by:words_per_minute }} {{ site.data.ui-text[site.locale].minute_read | default: "minute read" }}
+    {% endif %}
+{% endcomment %}
+
diff --git a/_includes/relatedPosts.html b/_includes/relatedPosts.html
new file mode 100644
index 0000000..16304af
--- /dev/null
+++ b/_includes/relatedPosts.html
@@ -0,0 +1,37 @@
+<div class="relatedPosts">
+
+    <h2>相关文章</h2> 
+    <hr/>
+    <ul>
+
+    {% assign maxRelated = 6 %}
+    {% assign minCommonTags =  2 %}
+    {% assign maxRelatedCounter = 0 %}
+
+    {% for post in site.posts %}
+        {% assign commonTags = '' %}
+
+        {% for tag in post.tags %}
+            {% if post.url != page.url %}
+                {% if page.tags contains tag %}
+                    {% assign sameTagCount = sameTagCount | plus: 1 %}
+                    {% capture tagmarkup %} <span class="label label-default">{{ tag }}</span> {% endcapture %}
+                    {% assign commonTags = commonTags | append: tagmarkup %}
+                {% endif %}
+            {% endif %}
+        {% endfor %}
+
+        {% if sameTagCount >= minCommonTags %}
+            <li>
+                <a href="{{ site.baseurl }}{{ post.url }}">{{ post.title }}</a>
+            </li>
+            {% assign maxRelatedCounter = maxRelatedCounter | plus: 1 %}
+            {% if maxRelatedCounter >= maxRelated %}
+                {% break %}
+            {% endif %}
+        {% endif %}
+
+    {% endfor %}
+    </ul>
+
+</div>
diff --git a/_includes/sidebar.html b/_includes/sidebar.html
index d2661c3..7703987 100644
--- a/_includes/sidebar.html
+++ b/_includes/sidebar.html
@@ -1,6 +1,9 @@
 {% if page.author_profile or layout.author_profile or page.sidebar %}
   <div class="sidebar sticky">
   {% if page.author_profile or layout.author_profile %}{% include author-profile.html %}{% endif %}
+
+  {% include tagcloud.html %}
+
   {% if page.sidebar %}
     {% for s in page.sidebar %}
       {% if s.image %}
@@ -20,4 +23,5 @@
     {% endif %}
   {% endif %}
   </div>
-{% endif %}
\ No newline at end of file
+
+{% endif %}
diff --git a/_includes/tagcloud.html b/_includes/tagcloud.html
new file mode 100644
index 0000000..cc4d78d
--- /dev/null
+++ b/_includes/tagcloud.html
@@ -0,0 +1,18 @@
+{% assign all_tags = site.tags | size %}
+<h3>
+  <a href="{{absolute_url}}/categories/index.html">Categories</a>
+</h3>
+<div class="tagCloud">
+  <ul>
+  {%for tag in site.categories %}
+  {% assign category_name = tag | first %}
+  {% assign cat_count = tag | last | size %}
+  {% assign cat_avg = cat_count | div: all_tags %}
+  <li>
+  <span class="tag">
+      <a href="{{absolute_url}}/categories/{{ category_name | downcase}}/index.html">{{ category_name }}({{ cat_count }})</a>
+  </span>
+  </li>
+  {% endfor %}
+  </ul>
+</div>
diff --git a/_layouts/post.html b/_layouts/post.html
index 826e9b1..efb40e8 100644
--- a/_layouts/post.html
+++ b/_layouts/post.html
@@ -38,6 +38,8 @@ layout: default
         {% if page.link %}<div><a href="{{ page.link }}" class="btn">{{ site.data.ui-text[site.locale].ext_link_label | default: "Direct Link" }}</a></div>{% endif %}
       </section>
 
+      {% include relatedPosts.html %}
+
       <footer class="page__meta">
         {% if site.data.ui-text[site.locale].meta_label %}
           <h4 class="page__meta-title">{{ site.data.ui-text[site.locale].meta_label }}</h4>
@@ -52,7 +54,6 @@ layout: default
 
       {% if page.share %}{% include social-share.html %}{% endif %}
 
-      {% include post_pagination.html %}
     </div>
 
     {% if site.comments.provider and page.comments %}
diff --git a/_layouts/related.html b/_layouts/related.html
new file mode 100644
index 0000000..2ce2cb8
--- /dev/null
+++ b/_layouts/related.html
@@ -0,0 +1,13 @@
+{% if related_posts != empty %}
+<div id="related-posts">
+    <h2>相关文章</h2>
+    <hr/>
+    <ul>
+        {% for p in related_posts %}
+        <li>
+            <a href="{{ p.url }}" data-score="{{ p.score }}">{{ p.title }}</a>
+        </li>
+        {% endfor %}
+    </ul>
+</div>
+{% endif %}
diff --git a/_layouts/single.html b/_layouts/single.html
index 826e9b1..3533762 100644
--- a/_layouts/single.html
+++ b/_layouts/single.html
@@ -16,6 +16,9 @@ layout: default
 
 <div id="main" role="main">
   {% include sidebar.html %}
+  <div class="sidebar__right sticky">
+      {%include tagcloud.html %}
+  </div>
 
   <article class="page" itemscope itemtype="http://schema.org/CreativeWork">
     {% if page.title %}<meta itemprop="headline" content="{{ page.title | markdownify | strip_html | strip_newlines | escape_once }}">{% endif %}
diff --git a/_pages/tags.html b/_pages/tags.html
index a47396d..0c38ad6 100644
--- a/_pages/tags.html
+++ b/_pages/tags.html
@@ -8,14 +8,18 @@ author_profile: true
 {% include group-by-array collection=site.posts field="tags" %}
 
 {% for tag in group_names %}
-  {% assign posts = group_items[forloop.index0] %}
-  <h2 id="{{ tag | slugify }}" class="archive__subtitle">{{ tag }}</h2>
-  <ul>
-  {% for post in posts %}
+{% assign posts = group_items[forloop.index0] %}
+<h2 id="{{ tag | slugify }}" class="archive__subtitle">
+    <a href="{{site.baseurl}}/tags/{{tag}}/index.html">{{ tag }}</a>
+</h2>
+<ul>
+    {% for post in posts %}
     <li>
-        <a.href="{{ post.url | remove_first:'/' }}">{{ post.title }}</a>
-        <div class="postDate">{{ post.date | date: "%B %d, %Y" }}</div>
+        <div>
+            <a href="{{site.baseurl}}{{ post.url }}">{{post.title | strip }}</a>
+            <div class="postDate">{{ post.date | date: "%B %d, %Y" }}</div>
+        </div>
     </li>
-  {% endfor %}
-  </ul>
+    {% endfor %}
+</ul>
 {% endfor %}
diff --git a/_plugins/raw_tag.rb b/_plugins/raw_tag.rb
new file mode 100644
index 0000000..927c1d0
--- /dev/null
+++ b/_plugins/raw_tag.rb
@@ -0,0 +1,20 @@
+module Jekyll
+  class RawTag < Liquid::Block
+    def parse(tokens)
+      @nodelist ||= []
+      @nodelist.clear
+      
+      while token = tokens.shift
+        if token =~ FullToken
+          if block_delimiter == $1
+            end_tag
+            return
+          end
+        end
+        @nodelist << token if not token.empty?
+      end
+    end
+  end
+end
+
+Liquid::Template.register_tag('raw', Jekyll::RawTag)
diff --git a/_plugins/sitemap_generator.rb b/_plugins/sitemap_generator.rb
new file mode 100644
index 0000000..3b1278f
--- /dev/null
+++ b/_plugins/sitemap_generator.rb
@@ -0,0 +1,274 @@
+# Sitemap.xml Generator is a Jekyll plugin that generates a sitemap.xml file by 
+# traversing all of the available posts and pages.
+# 
+# See readme file for documenation
+# 
+# Updated to use config file for settings by Daniel Groves
+# Site: http://danielgroves.net
+# 
+# Author: Michael Levin
+# Site: http://www.kinnetica.com
+# Distributed Under A Creative Commons License
+#   - http://creativecommons.org/licenses/by/3.0/
+require 'jekyll/document'
+require 'rexml/document'
+
+module Jekyll
+
+  class Jekyll::Document
+    attr_accessor :name
+
+    def path_to_source
+      File.join(*[@name].compact)
+    end
+
+    def location_on_server(my_url)
+      "#{my_url}#{url}"
+    end
+  end
+
+  class Page
+    attr_accessor :name
+
+    def path_to_source
+      File.join(*[@dir, @name].compact)
+    end
+
+    def location_on_server(my_url)
+      location = "#{my_url}#{url}"
+      location.gsub(/index.html$/, "")
+    end
+  end
+
+  # Recover from strange exception when starting server without --auto
+  class SitemapFile < StaticFile
+    def write(dest)
+      true
+    end
+  end
+
+  class SitemapGenerator < Generator
+    priority :lowest
+
+    # Config defaults
+    SITEMAP_FILE_NAME = "/sitemap.xml"
+    EXCLUDE = ["/atom.xml", "/feed.xml", "/feed/index.xml"]
+    INCLUDE_POSTS = ["/index.html"] 
+    CHANGE_FREQUENCY_NAME = "change_frequency"
+    PRIORITY_NAME = "priority"
+    
+    # Valid values allowed by sitemap.xml spec for change frequencies
+    VALID_CHANGE_FREQUENCY_VALUES = ["always", "hourly", "daily", "weekly",
+      "monthly", "yearly", "never"] 
+
+    # Goes through pages and posts and generates sitemap.xml file
+    #
+    # Returns nothing
+    def generate(site)
+      # Configuration
+      sitemap_config = site.config['sitemap'] || {}
+      @config = {}
+      @config['filename'] = sitemap_config['filename'] || SITEMAP_FILE_NAME
+      @config['change_frequency_name'] = sitemap_config['change_frequency_name'] || CHANGE_FREQUENCY_NAME
+      @config['priority_name'] = sitemap_config['priority_name'] || PRIORITY_NAME
+      @config['exclude'] = sitemap_config['exclude'] || EXCLUDE
+      @config['include_posts'] = sitemap_config['include_posts'] || INCLUDE_POSTS
+
+      sitemap = REXML::Document.new << REXML::XMLDecl.new("1.0", "UTF-8")
+
+      urlset = REXML::Element.new "urlset"
+      urlset.add_attribute("xmlns", 
+        "http://www.sitemaps.org/schemas/sitemap/0.9")
+
+      @last_modified_post_date = fill_posts(site, urlset)
+      fill_pages(site, urlset)
+
+      sitemap.add_element(urlset)
+
+      # Create destination directory if it doesn't exist yet. Otherwise, we cannot write our file there.
+      Dir::mkdir(site.dest) if !File.directory? site.dest
+
+      # File I/O: create sitemap.xml file and write out pretty-printed XML
+      filename = @config['filename']
+      file = File.new(File.join(site.dest, filename), "w")
+      formatter = REXML::Formatters::Pretty.new(4)
+      formatter.compact = true
+      formatter.write(sitemap, file)
+      file.close
+
+      # Keep the sitemap.xml file from being cleaned by Jekyll
+      site.static_files << Jekyll::SitemapFile.new(site, site.dest, "/", filename)
+    end
+
+    # Create url elements for all the posts and find the date of the latest one
+    #
+    # Returns last_modified_date of latest post
+    def fill_posts(site, urlset)
+
+      last_modified_date = nil
+      site.collections["posts"].docs.each do |post|
+        if !excluded?(site, post.name)
+          url = fill_url(site, post)
+          urlset.add_element(url)
+        end
+
+        date = File.mtime(post.path)
+        last_modified_date = date if last_modified_date == nil or date > last_modified_date
+      end
+
+      last_modified_date
+    end
+
+    # Create url elements for all the normal pages and find the date of the
+    # index to use with the pagination pages
+    #
+    # Returns last_modified_date of index page
+    def fill_pages(site, urlset)
+      site.pages.each do |page|
+        if !excluded?(site, page.path_to_source)
+          if File.exists?(page.path)
+            url = fill_url(site, page)
+            urlset.add_element(url)
+          end
+        end
+      end
+    end
+
+    # Fill data of each URL element: location, last modified,
+    # change frequency (optional), and priority.
+    #
+    # Returns url REXML::Element
+    def fill_url(site, page_or_post)
+      url = REXML::Element.new "url"
+
+      loc = fill_location(site, page_or_post)
+      url.add_element(loc)
+
+      lastmod = fill_last_modified(site, page_or_post)
+      url.add_element(lastmod) if lastmod
+
+
+
+      if (page_or_post.data[@config['change_frequency_name']])
+        change_frequency = 
+          page_or_post.data[@config['change_frequency_name']].downcase
+          
+        if (valid_change_frequency?(change_frequency))
+          changefreq = REXML::Element.new "changefreq"
+          changefreq.text = change_frequency
+          url.add_element(changefreq)
+        else
+          puts "ERROR: Invalid Change Frequency In #{page_or_post.name}"
+        end
+      end
+
+      if (page_or_post.data[@config['priority_name']])
+        priority_value = page_or_post.data[@config['priority_name']]
+        if valid_priority?(priority_value)
+          priority = REXML::Element.new "priority"
+          priority.text = page_or_post.data[@config['priority_name']]
+          url.add_element(priority)
+        else
+          puts "ERROR: Invalid Priority In #{page_or_post.name}"
+        end
+      end
+
+      url
+    end
+
+    # Get URL location of page or post 
+    #
+    # Returns the location of the page or post
+    def fill_location(site, page_or_post)
+      loc = REXML::Element.new "loc"
+      url = site.config['url'] + site.config['baseurl']
+      loc.text = page_or_post.location_on_server(url)
+
+      loc
+    end
+
+    # Fill lastmod XML element with the last modified date for the page or post.
+    #
+    # Returns lastmod REXML::Element or nil
+    def fill_last_modified(site, page_or_post)
+      lastmod = REXML::Element.new "lastmod"
+      date = File.mtime(page_or_post.path)
+      latest_date = find_latest_date(date, site, page_or_post)
+
+      if @last_modified_post_date == nil
+        # This is a post
+        lastmod.text = latest_date.iso8601
+      else
+        # This is a page
+        if posts_included?(site, page_or_post.path_to_source)
+          # We want to take into account the last post date
+          final_date = greater_date(latest_date, @last_modified_post_date)
+          lastmod.text = final_date.iso8601
+        else
+          lastmod.text = latest_date.iso8601
+        end
+      end
+      lastmod
+    end
+
+    # Go through the page/post and any implemented layouts and get the latest
+    # modified date
+    #
+    # Returns formatted output of latest date of page/post and any used layouts
+    def find_latest_date(latest_date, site, page_or_post)
+      layouts = site.layouts
+      layout = layouts[page_or_post.data["layout"]]
+      while layout
+        date = File.mtime(layout.path)
+
+        latest_date = date if (date > latest_date)
+
+        layout = layouts[layout.data["layout"]]
+      end
+
+      latest_date
+    end
+
+    # Which of the two dates is later
+    #
+    # Returns latest of two dates
+    def greater_date(date1, date2)
+      if (date1 >= date2) 
+        date1
+      else 
+        date2 
+      end
+    end
+
+    # Is the page or post listed as something we want to exclude?
+    #
+    # Returns boolean
+    def excluded?(site, name)
+      @config['exclude'].include? name
+    end
+
+    def posts_included?(site, name)
+      @config['include_posts'].include? name
+    end
+
+    # Is the change frequency value provided valid according to the spec
+    #
+    # Returns boolean
+    def valid_change_frequency?(change_frequency)
+      VALID_CHANGE_FREQUENCY_VALUES.include? change_frequency
+    end
+
+    # Is the priority value provided valid according to the spec
+    #
+    # Returns boolean
+    def valid_priority?(priority)
+      begin
+        priority_val = Float(priority)
+        return true if priority_val >= 0.0 and priority_val <= 1.0
+      rescue ArgumentError
+      end
+
+      false
+    end
+  end
+end
diff --git a/_plugins/tag_cloud_tag.rb b/_plugins/tag_cloud_tag.rb
new file mode 100644
index 0000000..4f8687a
--- /dev/null
+++ b/_plugins/tag_cloud_tag.rb
@@ -0,0 +1,23 @@
+module Jekyll
+  class TagCloudTag < Liquid::Tag
+    safe = true
+    
+    def initialize(tag_name, text, tokens)
+      super
+    end
+
+    def render(context)
+      html = ""
+      tags = context.registers[:site].tags
+      avg = tags.inject(0.0) {|memo, tag| memo += tag[1].length} / tags.length
+      weights = Hash.new
+      tags.each {|tag| weights[tag[0]] = tag[1].length/avg}
+      tags.each do |tag, posts|
+        html << "<span style='font-size: #{sprintf("%d", weights[tag] * 100)}%'><a href='/tags/#{tag}/'>#{tag}</a></span>\n"
+      end
+      html
+    end
+  end
+end
+
+Liquid::Template.register_tag('tag_cloud', Jekyll::TagCloudTag)
diff --git a/_plugins/tag_page.rb b/_plugins/tag_page.rb
new file mode 100644
index 0000000..3d55155
--- /dev/null
+++ b/_plugins/tag_page.rb
@@ -0,0 +1,67 @@
+module Jekyll
+  class TagPage
+    include Convertible
+    attr_accessor :site, :pager, :name, :ext
+    attr_accessor :basename, :dir, :data, :content, :output
+
+    def initialize(site, tag, posts)
+      @site = site
+      @tag = tag
+      self.ext = '.html'
+      self.basename = 'index'
+      self.content = <<-EOS
+{% for post in page.posts %}
+<h3>{{ post.date | date: "%A %d.%m." }} &mdash; <a href="{{ post.url }}">{{ post.title }}</a></h3>
+<p>{{ post.content | truncatewords: 20 }}</p>
+<p>
+{% if post.categories != empty %}
+In {{ post.categories | array_to_sentence_string }}.
+{% endif %}
+{% if post.tags != empty %}
+Tagged {{ post.tags | array_to_sentence_string }}.
+</p>
+{% endif %}
+{% endfor %}
+EOS
+      self.data = {
+        'layout' => 'default',
+        'type' => 'tag',
+        'title' => "Posts tagged #{@tag}",
+        'posts' => posts
+      }
+    end
+
+    def render(layouts, site_payload)
+      payload = {
+        "page" => self.to_liquid,
+        "paginator" => pager.to_liquid
+      }.deep_merge(site_payload)
+      do_layout(payload, layouts)
+    end
+
+    def url
+      File.join("/tags", @tag, "index.html")
+    end
+
+    def to_liquid
+      self.data.deep_merge({
+                             "url" => self.url,
+                             "content" => self.content
+                           })
+    end
+
+    def write(dest_prefix, dest_suffix = nil)
+      dest = dest_prefix
+      dest = File.join(dest, dest_suffix) if dest_suffix
+      path = File.join(dest, CGI.unescape(self.url))
+      FileUtils.mkdir_p(File.dirname(path))
+      File.open(path, 'w') do |f|
+        f.write(self.output)
+      end
+    end
+
+    def html?
+      true
+    end
+  end
+end
diff --git a/_plugins/tag_page_generator.rb b/_plugins/tag_page_generator.rb
new file mode 100644
index 0000000..0dcb275
--- /dev/null
+++ b/_plugins/tag_page_generator.rb
@@ -0,0 +1,11 @@
+module Jekyll
+  class TagPageGenerator < Generator
+    safe true
+
+    def generate(site)
+      site.tags.each do |tag, posts|
+        site.pages << TagPage.new(site, tag, posts)
+      end
+    end
+  end
+end
diff --git a/_posts/2009-06-18-log4cpp-an-excellent-logging-library-for-c-plus-plus.markdown b/_posts/2009-06-18-log4cpp-an-excellent-logging-library-for-c-plus-plus.markdown
index 4ffa945..d790851 100644
--- a/_posts/2009-06-18-log4cpp-an-excellent-logging-library-for-c-plus-plus.markdown
+++ b/_posts/2009-06-18-log4cpp-an-excellent-logging-library-for-c-plus-plus.markdown
@@ -3,7 +3,7 @@ layout: post
 title: "log4cpp-an excellent logging library for C++"
 date: 2009-06-18 22:22
 comments: true
-categories: [cpp, logging, log4cpp]
+categories: [cpp, tools]
 ---
 
 对于一个上点规模的C++项目而言，Log的作用是毋庸置疑的，出问题的时候，看了Log，常见的问题处理起来自是方便不过，即使遇到麻烦的问题，也可以从ｌｏｇ总发现不少蛛丝马迹。因此一个严肃的项目应该从一开始就好好考虑如何打Log，便于分析、维护。
diff --git a/_posts/2009-06-30-li-yong-ld-preloadfa-xian-cheng-xu-qian-zai-de-wen-ti.markdown b/_posts/2009-06-30-li-yong-ld-preloadfa-xian-cheng-xu-qian-zai-de-wen-ti.markdown
index e3e8165..4d13f30 100644
--- a/_posts/2009-06-30-li-yong-ld-preloadfa-xian-cheng-xu-qian-zai-de-wen-ti.markdown
+++ b/_posts/2009-06-30-li-yong-ld-preloadfa-xian-cheng-xu-qian-zai-de-wen-ti.markdown
@@ -3,7 +3,7 @@ layout: post
 title: "利用LD_PRELOAD发现程序潜在的问题"
 date: 2009-06-30 22:05
 comments: true
-categories: [cpp, debugging, unix]
+categories: [cpp, debugging, linux]
 ---
 
 Solaris上，常常可以用**LD_PRELOAD**辅助_mdb_做一些调试、测试工作，可以发现一些其它手段难以发现的问题；最近就遇到一个。
@@ -16,7 +16,7 @@ Solaris上有强大的mdb，辅助不同的模块可以得出很多有意思的
 ## 启动方法
 
 可以参看其manpage，主要是几个环境变量：
-``` bash
+```bash
 export UMEM_DEBUG=default
 export UMEM_LOGGING=transaction
 LD_PRELOAD=/lib/libumem.so
@@ -24,7 +24,7 @@ export LD_PRELOAD
 ```
 
 然后在此shell中启动程序，新打开一个终端，同样设置好LD_PRELOAD（否则会提示错误），查找正运行的程序的进程号（调试的程序），生成一个core文件：
-``` bash
+```bash
 ps -ef | grep <appname>
 gcore <pid>
 ls core.<pid>
@@ -33,7 +33,7 @@ ls core.<pid>
 用mdb打开新生成的core文件，第一行应该提示加载了libumem.so.
 接下来，用libumem.so提供的walker和dcmds就可以查询程序运行以来到产生core文件的那一时间点丰富的内存信息了.
 
-``` bash
+```bash
 mdb core.pid
 >::findleaks
 >::umalog
@@ -44,7 +44,7 @@ mdb core.pid
 
 整个过程非常繁杂，因为应用程序比较大，分配内存的log实在是太多了，但是突然发现运行目录下边多了不少core文件，一下子奇怪了，之前可是花费了很多时间在提高代码质量上，按道理不应该会有core产生了。打开这些core，用pstack，居然发现某个模块启动的子进程在调用free的地方abort了，按图索骥查看代码，在某个旮旯里边，几年没人动的小角落里，发现分配内存的地方：
 
-``` c
+```c
 char* path1 = getenv("MYENV");
 char path2[] = "bin/logDir/log.xxx"
 char* path = malloc(sizeof(path1) + sizeof(path2));
diff --git a/_posts/2009-07-01-li-yong-cmakeda-jian-kai-fa-buildhuan-jing.markdown b/_posts/2009-07-01-li-yong-cmakeda-jian-kai-fa-buildhuan-jing.markdown
index 7c137bb..f48fabd 100644
--- a/_posts/2009-07-01-li-yong-cmakeda-jian-kai-fa-buildhuan-jing.markdown
+++ b/_posts/2009-07-01-li-yong-cmakeda-jian-kai-fa-buildhuan-jing.markdown
@@ -3,7 +3,7 @@ layout: post
 title: "利用CMake搭建开发build环境"
 date: 2009-07-01 21:51
 comments: true
-categories: [cmake, build, tips, cpp]
+categories: [ build, tools]
 ---
 对于经常在终端下写程序的non-windows程序员，Makefile绝对是最常用的工具，小到一个文件的简单的测试程序，大到数百个文件的商业软件，只需要有shell，一个make命令就可得到可运行的程序，Makefile绝对功不可没；可惜世界中不是那么太平，不但各个Posix系统的API千差万别，硬件平台各异，就连Makefile本身也有多个不兼容的格式，譬如GNU Makefile 拿到Solaris平台上就没法make下去，除非你有gmake，但gmake对并行编译的支持就没有solaris自带的dmake要好了。
 
diff --git a/_posts/2009-07-04-cmakeza-ji.markdown b/_posts/2009-07-04-cmakeza-ji.markdown
index dea1e03..9699f8d 100644
--- a/_posts/2009-07-04-cmakeza-ji.markdown
+++ b/_posts/2009-07-04-cmakeza-ji.markdown
@@ -3,7 +3,7 @@ layout: post
 title: "cmake杂记"
 date: 2009-07-04 13:15
 comments: true
-categories: [cmake, tips, build]
+categories: [tools, build]
 ---
 
 CMake常用技巧：
@@ -15,7 +15,7 @@ CMake常用技巧：
 好处是，所有的临时文件都会生成在当前运行cmake/make的目录。
 譬如在项目根目录有一个CMakeLists.txt作为top-level file, 几个代码子目录，一个build目录，可以用：
 
-``` cmake
+```cmake
 cd build
 cmake ..
 make
@@ -37,7 +37,7 @@ add_library(libname SHARED src1 src2)
 - 获取当前运行目录
 
 可以在根目录设置一个project_dir变量，设置为源代码目录，如下
-``` cmake
+```cmake
 set(project_top_dir ${CMAKE_CURRENT_SOURCE_DIR}/")
 
 add_subdirectory(sub1)
@@ -49,7 +49,7 @@ add_subdirectory(sub2)
 
 假设第三方库不是由CMake编译得来，但要检测依赖和变动，则可以用imported属性：
 
-``` cmake
+```cmake
 add_library(ssllib SHARED IMPORTED)
 add_library(cryptolib SHARED IMPORTED)
 #May have different dependent libraries
diff --git a/_posts/2009-07-27-curl-and-ssl-issues-on-solaris.markdown b/_posts/2009-07-27-curl-and-ssl-issues-on-solaris.markdown
index fd33679..928ee09 100644
--- a/_posts/2009-07-27-curl-and-ssl-issues-on-solaris.markdown
+++ b/_posts/2009-07-27-curl-and-ssl-issues-on-solaris.markdown
@@ -3,7 +3,8 @@ layout: post
 title: "Curl&amp;SSL issues on Solaris"
 date: 2009-07-27 22:29
 comments: true
-categories: [cpp, ssl]
+categories: [cpp, linux, tools] 
+tags: [cpp, security, tools] 
 ---
 
 源码编译libcurl的时候,由于使用的不是默认系统上的ssl库（开发服务器上有很多个版本），为了避免动态库链接问题，必须定制SSL。
diff --git a/_posts/2009-07-27-wiresharkjie-mi-snmpv3-dhbao.markdown b/_posts/2009-07-27-wiresharkjie-mi-snmpv3-dhbao.markdown
index 4ee00e9..787c1cc 100644
--- a/_posts/2009-07-27-wiresharkjie-mi-snmpv3-dhbao.markdown
+++ b/_posts/2009-07-27-wiresharkjie-mi-snmpv3-dhbao.markdown
@@ -3,7 +3,7 @@ layout: post
 title: "wireshark解密SNMPv3-DH包"
 date: 2009-07-27 22:24
 comments: true
-categories: [wireshark, tools, tips, debugging]
+categories: [tools, debugging]
 tags: [wireshark, tools, tips, linux]
 ---
 
@@ -15,7 +15,7 @@ Wireshark自带有配置usmUser的例子，可以自动调用netsnmp的库来完
 tshark本身可以支持很多选项，几乎涵盖了wireshark大部分常用功能，个人发现特别适合二次分析。这里最关键的是 -T pdml选项,可以生成一个完整的xml格式的分析报告。
 
 假设实现用tcpdump或者snoop抓取了一个加密的包test.pcap,那么接下来，可以用其作二次分析：
-``` bash
+```bash
 snoop -d <dev> -o test.pcap <filter>
 tshark -r test.pcap -V -T pdml > test.xml
 ```
diff --git a/_posts/2009-10-12-python-test-automation.markdown b/_posts/2009-10-12-python-test-automation.markdown
index 870f8f4..f25a20c 100644
--- a/_posts/2009-10-12-python-test-automation.markdown
+++ b/_posts/2009-10-12-python-test-automation.markdown
@@ -3,7 +3,8 @@ layout: post
 title: "Python中根据不同参数组合产生单独的test case的一种方法"
 date: 2009-10-12 21:20
 comments: true
-categories: [python, test, automation, tips]
+categories: [test, tools]
+tags: [python, test, tools]
 ---
 
 Python自带的unittest和test两个模块为编写test case提供了很灵活的支持，最常用的情况就是继承自unittest.TestCase类，然后对每一个要进行测试的行为写一个test_开头的类成员函数，最后可以利用test.test_support.run_unittest函数跑所有的test case.
@@ -23,7 +24,7 @@ Python自带的unittest和test两个模块为编写test case提供了很灵活
 
 最后的代码就有了：
 
-``` python
+```python
 import unittest
 from test import test_support
 
diff --git a/_posts/2009-10-19-tcpji-ge-xiao-xuan-xiang-yin-fa-de-si-kao.markdown b/_posts/2009-10-19-tcpji-ge-xiao-xuan-xiang-yin-fa-de-si-kao.markdown
index dc42bdb..10999fa 100644
--- a/_posts/2009-10-19-tcpji-ge-xiao-xuan-xiang-yin-fa-de-si-kao.markdown
+++ b/_posts/2009-10-19-tcpji-ge-xiao-xuan-xiang-yin-fa-de-si-kao.markdown
@@ -3,7 +3,7 @@ layout: post
 title: "TCP几个小选项引发的思考"
 date: 2009-10-19 19:18
 comments: true
-categories: [linux, debugging, C, networking]
+categories: [linux, debugging]
 ---
 
 许久不查TCP相关的问题，今天下班前被一同事拦下要帮忙，说他碰到了__奇怪__的问题。
diff --git a/_posts/2009-12-14-cmake-tips.markdown b/_posts/2009-12-14-cmake-tips.markdown
index 834ca43..3b0452b 100644
--- a/_posts/2009-12-14-cmake-tips.markdown
+++ b/_posts/2009-12-14-cmake-tips.markdown
@@ -3,7 +3,7 @@ layout: post
 title: "CMake的一些小经验"
 date: 2009-12-14 14:11
 comments: true
-categories: [tips, cmake, build]
+categories: [tips, build]
 tags: [cmake, build]
 ---
 
@@ -20,7 +20,7 @@ cmake的帮助组织的还是很有规律的，了解了其规律，找自己想
 
 可以用如下这些命令获取帮助：
 
-``` bash
+```bash
 cmake --help-commands
 ```
 
@@ -28,7 +28,7 @@ cmake --help-commands
 
 另外也可以用如下的办法层层缩小搜索范围：
 
-``` bash
+```bash
 cmake --help-command-list
 cmake --help-command-list | grep find
 skyscribe@skyscribe:~/program/bld$ cmake --help-command-list | grep find
@@ -42,7 +42,7 @@ find_program
 这里找到了一些find相关的命令，可以具体查看某一个命令的manual了。
 
 
-``` bash
+```bash
 cmake version 2.8.5
     find_library
         Find a library.
@@ -92,7 +92,7 @@ cmake version 2.8.5
 和command的帮助比较类似，只不过这里可以查找cmake自己定义了那些变量你可以直接使用，譬如OSName，是否是Windows，Unix等。
 我最常用的一个例子：
 
-``` bash
+```bash
 cmake --help-variable-list  | grep CMAKE | grep HOST
 
 CMAKE_HOST_APPLE
@@ -108,7 +108,7 @@ CMAKE_HOST_WIN32
 
 如果希望将所有生成的可执行文件、库放在同一的目录下，可以如此做：
 
-``` cmake
+```cmake
 # Targets directory
 
 set(CMAKE_ARCHIVE_OUTPUT_DIRECTORY ${target_dir}/lib)
@@ -128,7 +128,7 @@ Property一般很少需要直接改动，除非你想修改一些默认的行为
 这时候，就可以通过修改taget对应的文件名，从而达到既生成动态库也产生静态库的目的。譬如:
 
 
-``` bash
+```bash
 make --help-property-list | grep NAME
 
 GENERATOR_FILE_NAME
@@ -155,7 +155,7 @@ cmake version 2.8.5
 
 譬如常用的boost库，可以通过如下方式：
 
-``` cmake
+```cmake
 # Find boost 1.40
 INCLUDE(FindBoost)
 find_package(Boost 1.40.0 COMPONENTS thread unit_test_framework)
@@ -165,7 +165,7 @@ endif()
 ```
 
 一般开头部分的解释都相当有用，可满足80%需求,这里是_FindBoost_的文档：
-``` cmake
+```cmake
 cmake version 2.8.5
     FindBoost
         Try to find Boost include dirs and libraries
@@ -212,7 +212,7 @@ CMake相比较于autotools的一个优势就在于其生成的中间文件组织
 
 譬如对于某一个target，一般binary tree下可以找到一个文件夹:  __CMakeFiles/<targentName>.dir/__,比如：
 
-``` bash
+```bash
 ls -l
 total 84
 -rw-r--r-- 1 skyscribe skyscribe 52533 2009-12-12 12:20 build.make
@@ -247,7 +247,7 @@ drwxr-xr-x 2 skyscribe skyscribe  4096 2009-12-12 12:20 src
 - rpath
 所谓的rpath是和动态库的加载运行相关的。我一般采用如下的方式取代默认添加的rpath：
 
-``` cmake
+```cmake
 SET(CMAKE_SKIP_BUILD_RPATH  FALSE)
 SET(CMAKE_BUILD_WITH_INSTALL_RPATH FALSE) 
 SET(CMAKE_INSTALL_RPATH "${CMAKE_INSTALL_PREFIX}/lib")
diff --git a/_posts/2010-01-10-vimxia-shi-xian-dui-c-plus-plus-stlde-intellisense.markdown b/_posts/2010-01-10-vimxia-shi-xian-dui-c-plus-plus-stlde-intellisense.markdown
index 05a5567..87f66ab 100644
--- a/_posts/2010-01-10-vimxia-shi-xian-dui-c-plus-plus-stlde-intellisense.markdown
+++ b/_posts/2010-01-10-vimxia-shi-xian-dui-c-plus-plus-stlde-intellisense.markdown
@@ -3,7 +3,7 @@ layout: post
 title: "VIM下实现对C++ STL的IntelliSense"
 date: 2010-01-10 18:28
 comments: true
-categories: [cpp, tips, vim]
+categories: [cpp, tools]
 ---
 
 以前尝试过在vim下配置STL的Intellisense曾经没有成功；最近有空刚好仔细看了下vim的一些相对高级的manual，总算将[OmniCppComplete](http://www.vim.org/scripts/script.php?script_id=1520)主页上的效果给弄了出来（[这里](http://vissale.neang.free.fr/Vim/OmniCppComplete/ScreenShots/screenshots.htm)）。
diff --git a/_posts/2010-05-09-boost-dot-cmake-jie-jue-boostsheng-ji-wen-ti.markdown b/_posts/2010-05-09-boost-dot-cmake-jie-jue-boostsheng-ji-wen-ti.markdown
index c65f467..7676b69 100644
--- a/_posts/2010-05-09-boost-dot-cmake-jie-jue-boostsheng-ji-wen-ti.markdown
+++ b/_posts/2010-05-09-boost-dot-cmake-jie-jue-boostsheng-ji-wen-ti.markdown
@@ -3,7 +3,7 @@ layout: post
 title: "Boost.CMake-解决boost升级问题"
 date: 2010-05-09 21:56
 comments: true
-categories: [cpp, boost, tips]
+categories: [cpp, build, tools]
 tags: [cpp, boost]
 ---
 
@@ -20,7 +20,7 @@ tags: [cpp, boost]
 CMake + GIT +Spinx 确实够酷了。
 
 编译起来可以充分利用强大的CMake了：
-``` bash
+```bash
 git clone git://gitorious.org/boost/cmake.git src
 cd src
 git checkout <TAG>    //TAG==1.41.0.cmake0
diff --git a/_posts/2011-01-02-unixshen-qi-zhi-awk-slash-gawk.markdown b/_posts/2011-01-02-unixshen-qi-zhi-awk-slash-gawk.markdown
index a63fa16..48e9180 100644
--- a/_posts/2011-01-02-unixshen-qi-zhi-awk-slash-gawk.markdown
+++ b/_posts/2011-01-02-unixshen-qi-zhi-awk-slash-gawk.markdown
@@ -3,7 +3,7 @@ layout: post
 title: "UNIX神器之awk/gawk"
 date: 2011-01-02 20:32
 comments: true
-categories: [awk, tips, tools]
+categories: [linux, tools]
 tags: [awk, programming, gawk, UNIX]
 ---
 
diff --git a/_posts/2012-02-19-ruby-xue-xi-bi-ji-1.markdown b/_posts/2012-02-19-ruby-xue-xi-bi-ji-1.markdown
index 2f20157..8e7f52b 100644
--- a/_posts/2012-02-19-ruby-xue-xi-bi-ji-1.markdown
+++ b/_posts/2012-02-19-ruby-xue-xi-bi-ji-1.markdown
@@ -3,8 +3,8 @@ layout: post
 title: "ruby学习笔记-1"
 date: 2012-02-19 15:58
 comments: true
-categories: [study, 学习笔记, ruby]
-tags: [study, ruby]
+categories: [study, notes, programming, language]
+tags: [study, ruby, programming, language]
 ---
 
 看得再多也不如自己动手试，最近有闲就打算认真研究一下ruby语言了。[Pragmatic programmer](http://pragprog.com/the-pragmatic-programmer)中说，需要一年学一门新语言一遍改造思想，去年浅浅的学了javascript的皮毛，今年可以看看ruby这个有lisp之风的OO语言了。
diff --git a/_posts/2012-02-25-my-first-post.markdown b/_posts/2012-02-25-my-first-post.markdown
index 460f5b8..e831ce2 100644
--- a/_posts/2012-02-25-my-first-post.markdown
+++ b/_posts/2012-02-25-my-first-post.markdown
@@ -3,7 +3,7 @@ layout: post
 title: "My first post"
 date: 2012-02-25 23:32
 comments: true
-categories: hello
+categories: blog
 tags: [study, hello]
 ---
 
diff --git a/_posts/2012-02-26-ce-shi-zhong-wen.markdown b/_posts/2012-02-26-ce-shi-zhong-wen.markdown
index 022bceb..f679101 100644
--- a/_posts/2012-02-26-ce-shi-zhong-wen.markdown
+++ b/_posts/2012-02-26-ce-shi-zhong-wen.markdown
@@ -3,8 +3,8 @@ layout: post
 title: "测试中文"
 date: 2012-02-26 20:28
 comments: true
-categories: [study, 中文]
-tags: [study, octopress, 中文, unicode]
+categories: [study, blog]
+tags: [study, octopress, blog, unicode]
 ---
 
 测试中文内容和category及标签。
diff --git a/_posts/2012-02-26-hello-octopress.markdown b/_posts/2012-02-26-hello-octopress.markdown
index c3ea5d3..f1ef0cc 100644
--- a/_posts/2012-02-26-hello-octopress.markdown
+++ b/_posts/2012-02-26-hello-octopress.markdown
@@ -3,7 +3,7 @@ layout: post
 title: "hello octopress"
 date: 2012-02-26 13:58
 comments: true
-categories: [blogging, study, markdown] 
+categories: [blog, study, doc, tools] 
 tags: [octopress, minutes, languages, programming]
 ---
 
diff --git a/_posts/2012-02-26-markdown-format-for-blogging.markdown b/_posts/2012-02-26-markdown-format-for-blogging.markdown
index 092c6d3..de8dd39 100644
--- a/_posts/2012-02-26-markdown-format-for-blogging.markdown
+++ b/_posts/2012-02-26-markdown-format-for-blogging.markdown
@@ -3,7 +3,7 @@ layout: post
 title: "markdown format for blogging"
 date: 2012-02-26 15:01
 comments: true
-categories: [study, markdown]
+categories: [study, notes, doc]
 tags: [minutes, markdown]
 ---
 
diff --git a/_posts/2012-02-27-ruby-xue-xi-bi-ji-2.markdown b/_posts/2012-02-27-ruby-xue-xi-bi-ji-2.markdown
index 6bc83c8..b21720c 100644
--- a/_posts/2012-02-27-ruby-xue-xi-bi-ji-2.markdown
+++ b/_posts/2012-02-27-ruby-xue-xi-bi-ji-2.markdown
@@ -3,8 +3,8 @@ layout: post
 title: "ruby学习笔记-2"
 date: 2012-02-27 20:36
 comments: true
-categories: [ruby, 学习笔记]
-tags: [study, ruby, language]
+categories: [programming, language, notes]
+tags: [study, ruby, language, programming]
 ---
 
 ## blocks&&closure
@@ -119,7 +119,7 @@ before calling #<Proc:0x8ad0310@closure_return.rb:35 (lambda)>...
 called #<Proc:0x8ad0310@closure_return.rb:35 (lambda)> result:value from proc
 before calling #<Method: Object#test_method>...
 called #<Method: Object#test_method> result:test method
-``` 
+```
 
         
     - lambda/method表现出真正的closure行为，仅仅返回closure本身；外部调用控制流不受影响，继续yield或者call的下一语句执行
diff --git a/_posts/2012-02-28-ruby-xue-xi-bi-ji-3-rake.markdown b/_posts/2012-02-28-ruby-xue-xi-bi-ji-3-rake.markdown
index d7663bb..e9b5c4d 100644
--- a/_posts/2012-02-28-ruby-xue-xi-bi-ji-3-rake.markdown
+++ b/_posts/2012-02-28-ruby-xue-xi-bi-ji-3-rake.markdown
@@ -3,8 +3,8 @@ layout: post
 title: "Ruby学习笔记-3 Rake"
 date: 2012-02-28 20:19
 comments: true
-categories: [study, build, rake, ruby, 学习笔记]
-tags: [study, ruby]
+categories: [study, build, programming, language, tools]
+tags: [study, ruby, programming, language]
 ---
 
 ## Rake - the make in ruby world
diff --git a/_posts/2012-02-29-snmp-vacm-view-api-bug.markdown b/_posts/2012-02-29-snmp-vacm-view-api-bug.markdown
index c18313c..eff026b 100644
--- a/_posts/2012-02-29-snmp-vacm-view-api-bug.markdown
+++ b/_posts/2012-02-29-snmp-vacm-view-api-bug.markdown
@@ -3,7 +3,7 @@ layout: post
 title: "snmp vacm view API的一个小bug"
 date: 2012-02-29 20:40
 comments: true
-categories: [snmp, C, tips]
+categories: [programming, tips]
 tags: [snmp, tips]
 ---
 
diff --git a/_posts/2012-03-03-markdown-codeblocks-and-indented-paragraphs.markdown b/_posts/2012-03-03-markdown-codeblocks-and-indented-paragraphs.markdown
index d467bf9..bb544a5 100644
--- a/_posts/2012-03-03-markdown-codeblocks-and-indented-paragraphs.markdown
+++ b/_posts/2012-03-03-markdown-codeblocks-and-indented-paragraphs.markdown
@@ -3,7 +3,7 @@ layout: post
 title: "Markdown codeblocks and indented paragraphs"
 date: 2012-03-03 10:25
 comments: true
-categories: [markdown, tips]
+categories: [doc, tips]
 ---
 
 ## 错落的格式
diff --git a/_posts/2012-03-06-lazy-evaluation-in-ruby-and-haskell.markdown b/_posts/2012-03-06-lazy-evaluation-in-ruby-and-haskell.markdown
index 3a57118..9f000b5 100644
--- a/_posts/2012-03-06-lazy-evaluation-in-ruby-and-haskell.markdown
+++ b/_posts/2012-03-06-lazy-evaluation-in-ruby-and-haskell.markdown
@@ -3,7 +3,8 @@ layout: post
 title: "lazy evaluation in Ruby&amp;Haskell"
 date: 2012-03-06 20:47
 comments: true
-categories: [ruby, haskell, functional]
+categories: [programming, language, fp]
+tags: [ruby, haskell, fp]
 ---
 
 lazy evaluation 是函数式编程中的一个重要概念，和传统过程式语言中的cache/state变量恰恰相对；其对应的数值/运算仅仅在用到的时候才实际运算，如果没有调用就什么也不会做。对于构造起来比较昂贵的对象，lazy evaluation可以有效避免cache带来的额外开销，因为只要需要的部分运算被执行，不用的则根本什么也不做。这里以获取Fibonacci数列中的第N个数为例，采用无穷序列的办法比较两种语言的实现。
diff --git a/_posts/2012-03-06-ruby-class-and-module.markdown b/_posts/2012-03-06-ruby-class-and-module.markdown
index 96b6168..df77c70 100644
--- a/_posts/2012-03-06-ruby-class-and-module.markdown
+++ b/_posts/2012-03-06-ruby-class-and-module.markdown
@@ -3,7 +3,8 @@ layout: post
 title: "ruby学习笔记-4 class&amp;module"
 date: 2012-03-06 22:48
 comments: true
-categories: [学习笔记, ruby]
+categories: [programming, language]
+tags: [ruby, programming, design]
 ---
 
 Class和Module是Ruby中的两个重要概念。作为一个纯**OO**语言，class的概念自然容易理解，即为object的抽象；而module则明显有别于其它语言地提供了mixin方法来解决多继承缺失带来的不便 - 集成多个基类的接口并维持[IS-A关系](http://en.wikipedia.org/wiki/Is-a)以及[LSP替换](http://en.wikipedia.org/wiki/Liskov_substitution_principle).
@@ -14,7 +15,7 @@ Class和Module是Ruby中的两个重要概念。作为一个纯**OO**语言，cl
 
 ruby中存在一些基础的类（或者是MetaClass)，包括: `[Class, Module, Kernel, Object, BasicObject]`, 且看如下测试：
 
-``` ruby
+```ruby
 tests = [Class, Module, Kernel, Object, BasicObject]
 
 puts "checking class and ancestors for #{tests}"
@@ -63,7 +64,7 @@ Kernel is not a Class
 
 Module不能用new来生成一个对象，譬如：
 
-``` ruby
+```ruby
 module TestModule
   def func()
     puts "value is @value"
@@ -85,7 +86,7 @@ Module的主要作用就是实现MIXIN。通过Module，某个class可以通过`
 
 下边的这段代码是一个简单的MIXIN例子:
 
-``` ruby
+```ruby
 class BaseClass
   def call_func()
     puts "base called"
diff --git a/_posts/2012-03-11-ruby-more-on-class-and-module.markdown b/_posts/2012-03-11-ruby-more-on-class-and-module.markdown
index e2c255d..ecc17ea 100644
--- a/_posts/2012-03-11-ruby-more-on-class-and-module.markdown
+++ b/_posts/2012-03-11-ruby-more-on-class-and-module.markdown
@@ -3,7 +3,8 @@ layout: post
 title: "ruby 学习笔记 5 - class&module&methods"
 date: 2012-03-11 20:45
 comments: true
-categories: [学习笔记, ruby]
+categories: [programming, language, notes]
+tags: [ ruby, programming, language]
 ---
 
 和其它的面向对象语言类似，ruby的类方法也分为_class method_ 和 _instance method_, **module**和**class**具有相当大程度的相似性, 但是用于重用module中定义的方法时( 同样也有 class method 和 instance method 之分 )，又有一些微妙的差异。
@@ -16,7 +17,7 @@ categories: [学习笔记, ruby]
 
 1. 类内define法，需要在 method name 之前显示加上 self 指明这是个属于 class 的方法：  
 
-``` ruby
+```ruby
 class Test
     def self.foo
         puts "class method called"
@@ -24,10 +25,10 @@ class Test
 end
 # call
 Test.foo
-```  
+``` 
 2. Append 法，通过 << 添加到 self，如下：  
 
-``` ruby
+```ruby
 class Test
     class << self
         def foo
@@ -38,10 +39,10 @@ end
 
 # call
 Test.foo
-```   
+```  
 3. 类外定义，和定义一个普通函数的方法类似，但是指明了 class name， 可以用于方便的向已定义好的类中添加 class method:  
 
-``` ruby
+```ruby
 class Test; end
 def Test.bar
     puts "class method called"
diff --git a/_posts/2012-03-12-ruby-regular-expressions.markdown b/_posts/2012-03-12-ruby-regular-expressions.markdown
index 94d8796..c035c5f 100644
--- a/_posts/2012-03-12-ruby-regular-expressions.markdown
+++ b/_posts/2012-03-12-ruby-regular-expressions.markdown
@@ -3,7 +3,8 @@ layout: post
 title: "Ruby 学习笔记 6 - 正则表达式"
 date: 2012-03-12 19:37
 comments: true
-categories: [ruby, 学习笔记, regexp]
+categories: [language, programming, notes]
+tags: [ruby, programming, language, notes]
 ---
 
 文本处理是Python/Ruby这类脚本语言的重头戏之一，而强大的正则表达式支持对于文本处理来说也是必不可少的。Ruby的设计很多方面沿袭perl，正则表达式方面也不例外。
@@ -13,12 +14,12 @@ categories: [ruby, 学习笔记, regexp]
 Ruby中的正则表达式有 2 种方式：
 
 * 用'/'分隔的字符串('/' 本身需 '\/' 转义）  
-``` ruby
+```ruby
 /myPattern/mi
 "Ruby matches uby" =~ /aTch/im #result is 6
 ```
 * 用 %r 开头，然后以其后第一个字符为分隔符的串  
-``` ruby
+```ruby
 %r!/usr/local/!
 "/usr/local/bin/" =~ %r!/usr/local/! # => 6
 ```
@@ -51,7 +52,7 @@ Ruby中的正则表达式有 2 种方式：
 
 - 替换函数： sub/gsub 前者仅仅匹配第一个，后者找到所有匹配  
 
-``` ruby
+```ruby
 1.9.2p290 :016 >   text = "Some string for test only, more..."
 => "Some string for test only, more..." 
 1.9.2p290 :017 > text.sub('or', '|')
@@ -64,7 +65,7 @@ Ruby中的正则表达式有 2 种方式：
 ## Regexp 对象 
 
 基本的正则表达式语法实际上对应着一个regexp对象，Regexp类定义了`match`函数，其返回一个MatchData 对象，即：
-``` ruby
+```ruby
 obj = /testRege[xX]p/i
 obj.class #Regexp
 mat = obj.match('testRegexp')
@@ -74,7 +75,7 @@ mat.regexp #/testRege[xX]p/i
 
 MatchData 对象中的`length`可以用于查询group的数量，而`[]`则可以返回匹配部分的每一个`()`分隔的group, 其中`[0]`返回整个匹配的字符串，而[1]...[N]返回第N个子group. 例如：
 
-``` ruby
+```ruby
 pattern = /^(\w+)\s*=\s*(\w+)\s*(#*.*)$/
 testStr1 = "key = value1"
 testStr2 = "key = value2 #a comment"
@@ -87,7 +88,7 @@ mat2 = pattern.match(testStr2)
 
 `offset`函数用于查询第N个子group的开始/结束 offset，参数为0时返回整个匹配的offset：
 
-``` ruby
+```ruby
 mat1.offset 0 # [0,12]
 mat1.offset mat1.length - 1 #[12,12]
 mat2.offset mat2.length - 1 #[13,23]
diff --git a/_posts/2012-03-14-haskell-type-system-exercises.markdown b/_posts/2012-03-14-haskell-type-system-exercises.markdown
index 496fe7d..eb340fa 100644
--- a/_posts/2012-03-14-haskell-type-system-exercises.markdown
+++ b/_posts/2012-03-14-haskell-type-system-exercises.markdown
@@ -3,7 +3,7 @@ layout: post
 title: "Haskell type system exercises"
 date: 2012-03-14 22:16
 comments: true
-categories: [haskell, study, 学习笔记]
+categories: [programming, notes]
 ---
 
 Haskell的类型系统是**强类型**的，并且没有任何强制类型转换。所有的类型检查均在编译器做检查。定义新的数据类型之后，即使它们内在的数据结构完全一样，也是完全不同的数据类型，不能混用。
@@ -14,7 +14,7 @@ Haskell的类型系统是**强类型**的，并且没有任何强制类型转换
 
 Maybe类型是有一种基于已有类型的二次封装类型，用于表述可能为空的抽象类型，用于支持类似于 C++/Java 中的模板机制，不过Haskell的类型系统表达能力比一般语言中的模板强大很多。
 
-``` haskell
+```haskell
 Maybe a = Just a | Nothing
 ```
 
@@ -30,7 +30,7 @@ Maybe a = Just a | Nothing
 
 ### toList 的实现：
 
-``` haskell
+```haskell
 data List a = Cons a (List a)
             | Nil
               deriving (Show)
@@ -60,7 +60,7 @@ Cons 1 (Cons 2 (Cons 3 (Cons 4 (Cons 5 (Cons 6 (Cons 7 (Cons 8 (Cons 9 (Cons 10
 
 已经给出的实现代码：
 
-``` haskell
+```haskell
 module Tree where
 data Tree a = Node a (Tree a) (Tree a)
             | Empty
@@ -72,7 +72,7 @@ simpleTree = Node "parent" (Node "left child" Empty Empty)
 
 - 采用Maybe的实现一：
 
-``` haskell
+```haskell
 data MyTree a = MyNode a (Maybe (MyTree a)) (Maybe (MyTree a))
                 deriving (Show)
 
@@ -82,7 +82,7 @@ mySimpleTree = MyNode (Just "parent") (Just (MyNode (Just "left child") Nothing
 
 - 采用Record语法提高可读性: 
 
-``` haskell
+```haskell
 data MyTreeRecord a = MyTreeRecord {
           parentNode  :: a
         , leftChild   :: Maybe (MyTreeRecord a)
diff --git a/_posts/2012-03-17-haskell-functional-programming.markdown b/_posts/2012-03-17-haskell-functional-programming.markdown
index c4b297f..19a3b18 100644
--- a/_posts/2012-03-17-haskell-functional-programming.markdown
+++ b/_posts/2012-03-17-haskell-functional-programming.markdown
@@ -3,7 +3,7 @@ layout: post
 title: "haskell函数式编程"
 date: 2012-03-17 20:49
 comments: true
-categories: [haskell, functional]
+categories: [programming, haskell, fp]
 ---
 
 作为纯函数式语言，haskell的主要特征之一即是提供丰富的函数式变成设施，包括 recursion / composition / lambda / partial & currying 等。Haskell本身的强类型约束和延迟赋值，使得其函数式风格明显区别于流行的 ruby/python 等其它语言。
@@ -24,7 +24,7 @@ List 是 haskell 内建类型里边的最基本类型之一，也是函数式变
 
 任何函数在Haskell中本质上仅仅绑定一个参数，如果在声明了可以绑定多个参数的函数后边提供少于期望个数的参数后，便可以得到一个新的函数，新函数的参数个数等于原函数的参数数减去已经提供的参数个数。如果提供的参数个数和期望的参数个数相同，则对应的就是一个新的函数调用；否则，我们得到了一个 partial function, 其中未指定的参数可以在随后调用中指定。例如：
 
-``` haskell
+```haskell
 Prelude> :type foldl
 foldl :: (a -> b -> a) -> a -> [b] -> a
 Prelude> :type foldl (+)
@@ -42,7 +42,7 @@ Haskell中的循环其实是通过递归(recursion)来完成的，配合pattern
 
 对于一些很常见的从一个链表中计算一个结果的操作，haskell提供了一些fold函数来简化代码，不再需要通过手工编写的 recursion/pattern matching来完成。如下的代码完成给定字符串转换为对应的**Int**数（仅仅处理正整数）：
 
-``` haskell
+```haskell
 type ErrorMessage = String
 asInt_either :: String -> Either ErrorMessage Int
 asInt_either "" = Left "None string can't be converted!"
@@ -76,7 +76,7 @@ isDigit c | ord c < ord '0' = False
 
 lambda 在 haskell 中用的并不是太多，因为其会造成程序可读性下降，而Haskell中可以通过 `let .. in` 或者 `where`的方式很轻松的定义局部函数。此外局部函数可以用一个描述其目的的名字来更好的帮助理解调用点的逻辑。例如：
 
-``` haskell
+```haskell
 func :: [Integer] -> [Integer]
 func = map (\a -> (a^(a-1) + a)) 
 
@@ -86,7 +86,7 @@ func = map calc where calc a = a ^ (a-1) + a
 
 函数可以相互组合，默认的方式是从左到右从而生成高阶函数，`.`可以用于组合函数使得先调用右侧函数，再作用于左侧。即:
 
-``` haskell
+```haskell
 func1 func2 func3 param = ((func1 func2) func3) param
 func1 . func2 . func3 param = func1 ( func2 ( func3 param) )
 ```
@@ -95,7 +95,7 @@ func1 . func2 . func3 param = func1 ( func2 ( func3 param) )
 
 Section 用于简化函数的组合，使得函数调用可以用中缀表达式的方法来书写，以增强代码可读性。譬如：
 
-``` haskell
+```haskell
 (1+) 2j
 map (*3) [23,36]
 (`elem` ['a'..'z'] 'f'
@@ -103,7 +103,7 @@ isAny needle haystack = any (need `isInfixOf`) haystack
 ```
 
 As-pattern 用于提高代码可读性，并减少新list的copy开销，`@`之后的部分将绑定到之前的一个变量之上，之后可以直接引用此变量而不需要创建新的List,例如：
-``` haskell
+```haskell
 suffixes :: [a] -> [[a]]
 suffixes xs@(_:xs') = xs : suffixes xs'
 suffixes _ = []
@@ -112,7 +112,7 @@ suffixes _ = []
 `seq`可以用于解决lazy-evaluation导致某些部分由于没有被调用而没有赋值的情况。`seq`的应用需要注意：
 
 1. `seq`表达式必须表达式中第一个被赋值的，例如：   
-``` haskell
+```haskell
 forceEv x y = x `seq` someFunc y
 chained x y z = x `seq` y `seq` someFunction z
 ```
diff --git a/_posts/2012-03-22-haskell-typeclass.markdown b/_posts/2012-03-22-haskell-typeclass.markdown
index aa86f78..94879cc 100644
--- a/_posts/2012-03-22-haskell-typeclass.markdown
+++ b/_posts/2012-03-22-haskell-typeclass.markdown
@@ -3,7 +3,7 @@ layout: post
 title: "Haskell typeclass"
 date: 2012-03-22 20:15
 comments: true
-categories: [haskell, type]
+categories: [programming, notes, haskell]
 ---
 
 Haskell 中也有class关键字，但其目的却和 OO 中的类有着巨大的差别。在 OO 世界中，类用来描述一大堆具有共同数据和行为的对象的抽象；而 Haskell 中的 class 则是用于抽象提供同样函数接口的数据类型。每一个 ADT 都可以用`instance`来生命其满足某个 class 并且给出对应于具体函数的实现，即 class 在 Haskell 中实际用于约束数据类型，因而又被成为 typeclass.
@@ -14,7 +14,7 @@ Haskell 中也有class关键字，但其目的却和 OO 中的类有着巨大的
 
 由于 Haskell 是一个纯函数式语言，所有的操作都是用函数方式实现的（递归和模式匹配）；同时作为一个强类型语言，所以函数的参数必须绑定于特定的类型，而不同的数据类型之间是不能直接转换的 ( 需要转的也必须通过某些函数来实现 ), 那么对于同样一个类似的函数，可能就需要对不同的类型有不同的实现，因为操作的类型可能不同，这样就会带来很繁琐的代码，例如：
 
-``` haskell
+```haskell
 someOpOnInt::Int -> Int
 someOpOnDouble::Double->Int
 someOpOnFractional::Fractional-> Int
@@ -24,13 +24,13 @@ someOpOnFractional::Fractional-> Int
 
 Typeclass则可以很好的解决这个问题：
 - 一个 typeclass 来定义所支持的操作，例如  
-``` haskell
+```haskell
 class SomeOp a where
     someOp :: a -> Int
 ```
 
 - 每一个可以支持该操作的类型可以实现对应的操作，如：  
-``` haskell
+```haskell
 instance SomeOp Int where
     -- implementition for Int type
     someOp x = undefined
@@ -45,7 +45,7 @@ instance SomeOp Fractional where
 ```
 
 - typeclass是开放的，这意味着你可以在不同的模块里边实现其它模块中定义的 typeclass   
-``` haskell
+```haskell
 data BrandNewType = BrandNewType String Int
         deriving (Show, Eq)
 
@@ -60,7 +60,7 @@ instance SomeOp BrandNewType where
 
 这是两个系统预定义的 typeclass, Show 用于将某个类型转换为 string， 而 Read 则用于从一个字符串表述中构造一个指定类型的数据。二者结合可以完成数据的序列化和反序列化。系统提供的 putStrLn 操作于某个数据类型的时候，如果其类型继承了 Show，那么它的字符串表示就会被打印出来。当然`show` 函数也可以用于打印其字符串表述，而 Read 则用构造出一个指定类型的对象，比如：
 
-``` haskell
+```haskell
 data Color = Read | Green | Blue
 instance Show Color where
     show Red = "Red"
@@ -122,7 +122,7 @@ data ThisWorks = ThisWorks OK
 
 由于 typeclass 是开放的， 不同的模块可能对不同的类型提供不同的 typeclass instance实现，二者就可能出现冲突，例如：
 
-``` haskell
+```haskell
 class Borked a where 
     bork:: a -> String
 
diff --git a/_posts/2012-03-23-haskell-monad.markdown b/_posts/2012-03-23-haskell-monad.markdown
index 0db8922..3a573a9 100644
--- a/_posts/2012-03-23-haskell-monad.markdown
+++ b/_posts/2012-03-23-haskell-monad.markdown
@@ -3,7 +3,7 @@ layout: post
 title: "Haskell Monad"
 date: 2012-03-23 20:38
 comments: true
-categories: [haskell, monad]
+categories: [programming]
 ---
 
 作为一个函数式强类型语言，Haskell 尽可能的保证提供纯函数特性，即任何操作都不会有副作用  - **给定相同的参数输入，给定函数必须产生相同的输出结果**;这个保证看起来很优美很干脆（容易测试并容易并行处理），但是现实世界中的问题确实则不能通过纯函数的方式解决，譬如IO输入输出，系统文件操作等；这些操作的过程依赖于调用时候的上下文环境，即给定完全相同的输入，不可能得到完全一样的输出，且不说中间可能会有其它副作用影响函数的行为，比如文件操作可能失败，IO 输出到特殊的终端的时候，可能出错等。
@@ -28,7 +28,7 @@ Monad有如下重要特征和作用：
 理解Monad需要预先熟悉一些基本特性：   
 - Type constructors   
 用于定义新的多态数据类型，该类型包含有一个动态参数类型，比如Maybe类型定义：
-``` haskell
+```haskell
 data Maybe a = Nothing | Just a
 ```
 这里的类型定义中包含一个可变参数`a`，用于表明这里定义的类型是一个类似于容器的抽象类型，包含一大类具体类型，譬如`Maybe Int`/`Maybe String`等等。其中的`constructor`可以生成两种不同的具体类型，要么是`Nothing`,要么是给定类型的一个wrapper类 `Just a`。
@@ -39,7 +39,7 @@ data Maybe a = Nothing | Just a
 ## Monad 定义
 
 Monad本身是一个type class，其定义如下所示：
-``` haskell
+```haskell
 class Monad m where
     (>>=) :: m a -> (a -> m b) -> m b
     return :: a -> m a
@@ -52,7 +52,7 @@ class Monad m where
 3. return - 又成**unit**操作，将一个数值类wrapper为一个Monad变量    
 
 比如Maybe的例子，有：
-``` haskell
+```haskell
 instance Monad Maybe where
     Nothing >>= f = Nothing
     (Just x) >>= f = f x
@@ -61,7 +61,7 @@ instance Monad Maybe where
 这里的`bind`操作对2个constructor有不同的实现（pattern match），而 return 直接作用于 Just constructor。
 
 通过Haskell提供的 `do notation`, 可以对Monad做类似于命令式语言的操作：
-``` haskell
+```haskell
 data Sheep = SheepCreator String (Sheep, Sheep) | NONE
      deriving Show
 
@@ -102,7 +102,7 @@ Monad 类必须要满足三个基本定律才能用DO来表达(具体的论证
 
 1. fail 错误处理，Do里边的任何错误都默认立刻推出处理 - `fail s = error`   
 2. `>>` 操作用于表述不需要前一个Monadic操作提供输入的处理:    
-``` haskell
+```haskell
 (>>) :: m a -> m b -> m b
 m >> k = m >>= (\_ -> k)
 ```
@@ -110,21 +110,21 @@ m >> k = m >>= (\_ -> k)
 ## 其它的Monad定律
 
 除了上述的3个基本定律，某些Monad还提供一下额外的保证：  
-``` haskell
+```haskell
 mzero >>= f == mzero
 m >>= (\x -> mzero) == mzero
 mzero `mplus` m == m
 m `mplus` mzero == m
 ```
 这里的`mzero`是一个特殊的monad变量，其满足对于左右bind的函数都返回`mzero`，而`plus`则返回两个参数中的任意一个非mzero的变量。在Haskell中满足这两的定律的类是MonadPlus:
-``` haskell
+```haskell
 class (Monad m) => MonadPlus m where
     mzero::m a
     mplus::m a -> m a -> m a
 ```
 
 对于Maybe类型，其同样满足MonadPlus要求，对应的：
-``` haskell
+```haskell
 instance MonadPlus Maybe a where
     mzero = Nothing
     Nothing `mplus` x = x
diff --git a/_posts/2012-03-30-haskell-regular-expression.markdown b/_posts/2012-03-30-haskell-regular-expression.markdown
index 450ea3b..9935b9d 100644
--- a/_posts/2012-03-30-haskell-regular-expression.markdown
+++ b/_posts/2012-03-30-haskell-regular-expression.markdown
@@ -3,7 +3,7 @@ layout: post
 title: "Haskell regular expression"
 date: 2012-03-30 22:16
 comments: true
-categories: [haskell, regexp] 
+categories: [haskell, programming] 
 ---
 
 正则表达式是文本解析处理的一大利器，因而大部分程序语言都以库的方式提供支持。在Haskell中，有多种不同的实现可供使用，详细看参考[wiki](http://www.haskell.org/haskellwiki/Regular_expressions), 他们的效率和支持的特性有些微的差异。但是作为一种**强类型**的**静态**/函数式语言，haskell的正则匹配可以借助返回值类型多态提供灵活的匹配结果。
@@ -21,19 +21,19 @@ Haskell的正则表达式库位于Text.Regex中 , Ubuntu默认的GHC中并没有
 和Perl中的正则表达式匹配操作符一样，正则库提供了`=~`操作来完成匹配。和其它语言不同的是，这个函数(`infix operator`)通过返回值多态提供灵活的功能。
 
 1. 基本匹配 - 可以指定返回类型为Bool来判断是否匹配:  
-``` haskell
+```haskell
 let pat = "(foo[a-z]*bar|quxx)"
 "A match with foodiabar after" =~ pat :: Bool  --True
 "no match" =~ pat :: Bool -- False
 ```
 2. 返回第一个匹配的子串或者空串：  
-``` haskell
+```haskell
 let pat = "(foo[a-z]*bar|quxx)"
 "A match with foodiabar after" =~ pat :: String  --get "foodiabar"
 "no match" =~ pat :: String -- get empty string
 ```
 3. 返回匹配的上下文信息：   
-``` haskell
+```haskell
 let pat = "(foo[a-z]*bar|quxx)"
 "A match with foodiabar after" =~ pat :: (String, String, String)
 -- get ("A match with ", "foodiabar", " after")
@@ -42,7 +42,7 @@ let pat = "(foo[a-z]*bar|quxx)"
 ```
 这里可以区分出是否有空串匹配。  
 4. 返回更多信息：  
-``` haskell
+```haskell
 let pat = "(foo[a-z]*bar|quxx)"
 "A match with foodiabar quxx after" =~ pat :: (String, String, String, [String])
 -- get ("A match with ", "foodiabar", " quxx  after", ["foodiabar"])
@@ -51,7 +51,7 @@ let pat = "(foo[a-z]*bar|quxx)"
 ```
 这里最后的一个String list可以用于返回子分组信息。  
 5. 获取匹配字符的index信息和长度：  
-``` haskell
+```haskell
 let pat = "(foo[a-z]*bar|quxx)"
 "A match with foodiabar after" =~ pat :: (Int, Int)
 -- get (13, 9)
diff --git a/_posts/2012-04-15-haskell-functor-and-monad.markdown b/_posts/2012-04-15-haskell-functor-and-monad.markdown
index b84a107..392fe46 100644
--- a/_posts/2012-04-15-haskell-functor-and-monad.markdown
+++ b/_posts/2012-04-15-haskell-functor-and-monad.markdown
@@ -3,7 +3,7 @@ layout: post
 title: "Haskell Functor &amp; Monad"
 date: 2012-04-15 21:11
 comments: true
-categories: [haskell, functor, monad]
+categories: [haskell, fp, programming]
 ---
 
 作为一种函数式语言，haskell提供了各种高级的函数编程抽象支持：Functor抽象了那些作用于**函数（或者类型封装）内的数据的操作并且将其运算结果用对应函数封装的抽象运算**, 其核心是提供了**Functor** typeclass 和 **fmap**操作。
@@ -39,7 +39,7 @@ Tree a = Node (Tree a) (Tree a)
 ```
 
 这里的Tree中保存的是一个抽象数据。假设这里的a是个String，并且我们希望据此生成一个新的Tree，对应的每个节点中的数据存放的是对应String的长度，那么其实现可以如下：
-``` haskell
+```haskell
 treeLengths (Leaf s) = Leaf (length s)
 treeLengths (Node l r) = Node (treeLengths l) (treeLengths r)
 ```
@@ -64,7 +64,7 @@ instance Functor Tree where
 ## list & Maybe
 
 Maybe类型是一个基本类型，用于封装某个数据或者空，而List则用于描述数据列表。对于List类型，其fmap对应的实现其实就是map - **fmap可以看作是map的一个扩展**; 对于Maybe类型，fmap的定义如下：
-``` haskell
+```haskell
 instance Functor Maybe where
     fmap _ Nothing = Nothing
     fmap f (Just x) = Just (f x)
@@ -81,18 +81,18 @@ liftM f m = m >>= \i -> return (f i)
 ```
 
 对于多个变量的函数，haskell中定义了`liftM2`/`liftM3`...`liftM5`,以下是`liftM2`的定义：
-``` haskell
+```haskell
 liftM2 :: (Monad m) => (a->b->c) -> m a -> m b -> m c
 liftM2 f m1 m2 = m1 >>= \a -> m2 >>= \b -> return (f a b)
 ```
 
 这里的操作可以依次作用于2个monadic变量，并且得到一个新的moandic变量。对于无穷集合运算来说，liftM系列函数就无能无力了；这个时候 `ap`则可以派上用场：
-``` haskell
+```haskell
 ap :: Monad m => m (a -> b) -> m a -> m b
 ```
 
 如下例：
-``` haskell
+```haskell
 data MovieReview = MovieReview {
       revTitle :: String
     , revUser :: String
diff --git a/_posts/2012-04-18-haskell-functor-slash-applicative-slash-monad.markdown b/_posts/2012-04-18-haskell-functor-slash-applicative-slash-monad.markdown
index 296a50e..d031391 100644
--- a/_posts/2012-04-18-haskell-functor-slash-applicative-slash-monad.markdown
+++ b/_posts/2012-04-18-haskell-functor-slash-applicative-slash-monad.markdown
@@ -3,7 +3,7 @@ layout: post
 title: "Haskell Functor/Applicative Functor"
 date: 2012-04-18 20:19
 comments: true
-categories: [haskell, monad, functional]
+categories: [haskell, fp, programming]
 ---
 
 Haskell中存在三种层次的函数过程抽象，依据约束的多少分别有 Functor， Applicative 和 Monad。Functor是一种最基本的调用提升，通过`fmap`可以将传入参数函数作用于所wrapper的type；而Applicative和Monad则定义了更多的运算符和原子函数等。
@@ -22,7 +22,7 @@ Functor定义为一个Typecalss，其定义了一个fmap函数，对于对应的
 
 GHC自带的很多基本**ADT**满足Functor的要求，即他们自身是Functor的实例，包括Maybe, list([]), IO Monad, Either等。
 
-``` haskell
+```haskell
 fmap :: Functor f => (a->b) -> f a -> f b
 fmap (+1) (Just 1) 
 -- Just 2, type = Maybe, constructor = Just
@@ -59,7 +59,7 @@ ghci>fmap (\f -> f 2) a
 因为传入fmap的函数参数为: `(^) :: (Num a, Integral b) => a -> b -> a`, 数据类型为 `list`, 于是，fmap的结果则是一个list类型，其中的元素参数为一个函数。对于这个list再次调用**fmap**, 那么对应的函数就是一个基于函数的函数 (**lambda**描述为 `\f -> f 2`), 结果就是将对应的lambda 函数作用于list中的每一个函数，生成最终的list 数据。这里的2次fmap调用得到的结果始终是一个list, 只不过每次的list具体数据类型有所不同。
 
 如果想将`fmap`作用于一个不同类型的ADT数据 (Context)，那么编译器机会报错：
-``` haskell
+```haskell
 ghci>fmap Just (^2) Just 5
 
 <interactive>:1:6:
@@ -115,7 +115,7 @@ pure (+) <*> Just 3 <*> Just 5
 ### `<*` 和 `*>` 及 const
 
 `<*`和`*>`的类型表明它忽略函数的右侧或者左侧参数数值，但是对应的容器类型(f)没有发生变化。比如如下的例子：
-``` haskell
+```haskell
 ghci>:info <*
 class Functor f => Applicative f where
   ...
@@ -136,13 +136,13 @@ Just 3
 ```
 
 可见`<*` 是忽略函数右侧的其它参数，返回左侧。`*>`则和其相反：
-``` haskell
+```haskell
 ghci>Just (+2) *> Just 1
 Just 1
 ```
 
 Haskell有如下的`const`函数，因此 `<*` `*>`可以有 `<*>` 和`const`来实现:
-``` haskell
+```haskell
 ghci>:info const 
 const :: a -> b -> a    -- Defined in GHC.Base
 f *> g = flip const <$> f <*> g
@@ -161,12 +161,12 @@ ghci>[length] <*> ["ss", "tt", "bar"]
 ```
 这里的容器类型（构造函数）是`[]`本身，所以其中的映射函数 `a->b` 必须放置在 `[]`中，对应的**applicative**参数分别是`Int`和`[Char]`。考虑如下更复杂一点的情形： 
 
-``` haskell
+```haskell
 ghci>[(^2), sqrt]  <*> [1..4]
 [1.0,4.0,9.0,16.0,1.0,1.4142135623730951,1.7320508075688772,2.0]
 ```
 这里的`<*>`操作结果为对于左边的每一个函数，依次作用于右边的每一个元素，并且返回结果的list。自然左边参数的函数类型必须是相同的;根据以上行为可见，list 的 Applicative定义其实为：
-``` haskell
+```haskell
 instance Applicative [] where
     pure x = [x]
     gs <*> xs = [g x | g <- gs, x <- xs]
@@ -174,7 +174,7 @@ instance Applicative [] where
 其`<*>`函数是通过**list comprehension**来完成的。
 
 另外一种实现是分别取左右（相对于操作符 `<*>` 函数的中缀表达式写法）的对应函数和参数，将所得的运算结果放置于结果list中；即ZipWith:
-``` haskell
+```haskell
 newtype ZipList a = ZipList {getZipList :: [a])
 
 instance Applicative ZipList where
@@ -184,7 +184,7 @@ instance Applicative ZipList where
 
 下边是一个ZipList的例子：
 
-``` haskell
+```haskell
 ghci>getZipList $ ZipList [(^2), sqrt, (+10), (/2)] <*> ZipList [2..10] 
 [4.0,1.7320508075688772,14.0,2.5]
 ```
@@ -193,7 +193,7 @@ ghci>getZipList $ ZipList [(^2), sqrt, (+10), (/2)] <*> ZipList [2..10]
 ### <$> 操作符
 
 为了简化代码并且提高可读性，Applicative定义了`<$>`操作符，类似于基本的`($)`函数，且有：
-``` haskell
+```haskell
 f <$> a = fmap f a
 pure f <*> x = fmap f x = f <$> x
 
@@ -215,7 +215,7 @@ Just 40
 ### Applicative 定律
 
 Applicate的实例类型必须满足如下定律：
-``` haskell
+```haskell
 pure id <*> v = v                               --Identity
 pure (.) <*> u <*> v <*> w = u <*> (v <*> w)    --Composition
 pure f <*> pure x = pure (f x)                  --Homomorphism
@@ -239,7 +239,7 @@ ci>Just (*2) <*> (Just (+3) <*> Just 2)
 Just 10
 ```
 - Homomorphism
-``` haskell
+```haskell
 ci>Just (*2) <*> Just 2
 Just 4
 ghci>Just ((*2) 2)
@@ -257,7 +257,7 @@ Just 4
 ### IO Monad and Applicative
 
 所有的Monad都满足Applicative的要求；其实Monad对结构化的要求比Applicative的要高。对于IO Monad，以下是其实现：
-``` haskell
+```haskell
 instance Applicative IO where
     pure = return
     a <*> b = do
@@ -267,14 +267,14 @@ instance Applicative IO where
 ```
 
 对于如下的do风格程序：
-``` haskell
+```haskell
 greeting = do
     firstName <- getLine
     LastName <- getLine
     putStrLn $ "hello" ++ firstName ++ lastName
 ```
 可以用Applicative风格更优雅地写作：
-``` haskell
+```haskell
 greeting = do
     name <- (++) ($) getLine <*> getLine
     putStrLn $ "hello" ++ name
@@ -285,7 +285,7 @@ greeting = do
 ### Applicative 辅助函数
 
 Aplicative定义了如下一些辅助函数用于简化代码书写：
-``` haskell
+```haskell
 liftA :: Applicative f => (a->b) -> f a -> f b
 liftA f a = pure f <*> a = f <$> a
 
@@ -299,7 +299,7 @@ liftA3 f a b c = f <$> a <*> b <*> c
 ## Functor/Applicative Functor/Monad
 
 在Monad中，Haskell定义了`ap`函数, 如果参照`<*>`的定义：
-``` haskell
+```haskell
 ghci>:info ap
 ap :: Monad m => m (a -> b) -> m a -> m b
     -- Defined in Control.Monad
diff --git a/_posts/2012-04-24-type-slash-data-slash-newtype-in-haskell.markdown b/_posts/2012-04-24-type-slash-data-slash-newtype-in-haskell.markdown
index b871e13..dff109c 100644
--- a/_posts/2012-04-24-type-slash-data-slash-newtype-in-haskell.markdown
+++ b/_posts/2012-04-24-type-slash-data-slash-newtype-in-haskell.markdown
@@ -3,7 +3,7 @@ layout: post
 title: "Type/data/newtype in Haskell"
 date: 2012-04-24 22:19
 comments: true
-categories: [haskell, type]
+categories: [haskell, notes]
 ---
 
 Haskell提供了抽象代数类型（Algebra Data Type）来完成对数据的封装；其中最直观的是 data 关键字声明，可以用C/C++中的struct/class 来类比。此外，我们还可以用 type 和 newtype 来定义一些数据抽象。type所定义的就是一个已有类型的别名，其主要作用就是为了提高代码的可读性，更清晰的传达代码的意图；而newtype则有一些细微的差异和特殊作用。
@@ -32,7 +32,7 @@ newtype Pair' a b = Pair' (a,b)
 既然`newtype`有这么多的不便，那么为什么会有人将其引入进来？对于newtype类型而言，一个最大的特点是，其构造函数在编译期间就被擦掉了，即运行期间，其构造函数是不可见的，其封装的类型和内部的field类型完全没有区别(对于类型系统而言）;这样就会有巨大的**性能优势**：newtype类型的数据既照顾了数据抽象和代码可读性的要求，又具有尽可能少的额外处理负担；当然这些好处也带来一些很微妙的问题。
 
 考虑如下的例子：
-``` haskell
+```haskell
 newtype Feet = Feet Double
 newtype Cm   = Cm Double
 ```
@@ -42,7 +42,7 @@ newtype Cm   = Cm Double
 
 对函数进行pattern match的时候，由于构造函数实际上已经不可见，因而对newtype的构造函数进行的匹配实际上会被忽略，但是对于data类型而言，构造函数的参数数据则必须被严格赋值,如下边的代码：
 
-``` haskell
+```haskell
 data Foo = Foo Int
 newtype NewFoo = NewFoo Int
 
diff --git a/_posts/2012-07-09-vim-he-github.markdown b/_posts/2012-07-09-vim-he-github.markdown
index 200342e..0ca4bdd 100644
--- a/_posts/2012-07-09-vim-he-github.markdown
+++ b/_posts/2012-07-09-vim-he-github.markdown
@@ -3,7 +3,7 @@ layout: post
 title: "vim 和 Github"
 date: 2012-07-09 20:14
 comments: true
-categories: [vim, tips, tools]
+categories: [tools]
 ---
 
 vim之所有被成为Unix程序员的两大神器之一，就是因为其强大的插件机制；但是传统的插件更新方式需要手工去[插件网站](http://www.vim.org/scripts/)下载，并且释放到**$HOME/.vim**目录下边，然后解压缩，定制选项等等。这样的好处是，当你需要到一台新的机器上工作的时候，不管这台机器有没有你的插件，只需要将你自己的插件目录全部打包/复制/覆盖就好了。
diff --git a/_posts/2012-07-23-concurrency-with-haskell.markdown b/_posts/2012-07-23-concurrency-with-haskell.markdown
index f673885..0ac8621 100644
--- a/_posts/2012-07-23-concurrency-with-haskell.markdown
+++ b/_posts/2012-07-23-concurrency-with-haskell.markdown
@@ -3,7 +3,7 @@ layout: post
 title: "Concurrency with Haskell"
 date: 2012-07-23 19:49
 comments: true
-categories: [haskell, 学习笔记, concurrency]
+categories: [notes, programming, design, haskell, fp]
 ---
 
 随着基于CPU频率的摩尔定律的失效，现代的计算机体系都采用多核的方式提高处理能力，传统的编程思维和模式在多核时代则遭遇越来越多的问题；而函数式编程则在很大程度上提供了完全不同但是更为优雅的思路。作为纯函数式编程语言，Haskell的并发编程则和传统的过程式语言有着明显的不同。
@@ -24,7 +24,7 @@ Haskell提供了两种Concurrency模式，一个是传统的Thread/condition/sem
 
 Haskell的Thread方式和传统的变成语言或者库有显著的不同；其定义在`Control.Concurrent`中提供。由于Thread本身是有副作用的，hanskell通过封装**IO Monad**的方式来提供Thread,即一个thread为一个**IO action**,要使用thread则可以调用`forkIO`来执行一些任务。
 
-``` haskell
+```haskell
 ghc>:m +Control.Concurrent
 ghc>:info forkIO
 forkIO :: IO () -> IO ThreadId -- Defined in `GHC.Conc.Sync'
@@ -42,7 +42,7 @@ True
 
 需要注意的是，由于新线程的执行顺序是不确定的，因此上述例子中的程序返回结果可能不同。因为haskell中的变量全部是不可变的，因此在forkIO中传递变量是安全的，这个可以作为传递参数的一种很方便的形式，譬如下边的例子：
 
-``` haskell
+```haskell
 import Control.Concurrent(forkIO)
 import Control.Monad(forever)
 
@@ -62,7 +62,7 @@ type Connection = (Handle, SockAddr)
 
 GHC中定义了MVar来方便不同线程之间的通信，并定义有`putMVar`和`takeMVar`, 同样它们都是**IO action**:
 
-``` haskell
+```haskell
 ghc>:info MVar 
 data MVar a = GHC.MVar.MVar (GHC.Prim.MVar# GHC.Prim.RealWorld a)
 -- Defined in `GHC.MVar'
@@ -88,7 +88,7 @@ newMVar :: a -> IO (MVar a) -MVar- Defined in `GHC.MVar'
 
 下边是一个更复杂的例子，用于webserver统计所有的子连接个数 - 控制线程可以做更多有意义的控制，比如在负载满的时候停止创建新的线程等：
 
-``` haskell
+```haskell
 cceptConnections :: Config -> Socket -> IO ()
 acceptConnections config socket
 = do {  count <- newEmptyMVar ;
@@ -108,7 +108,7 @@ dec count = do { v <- takeMVar count; putMVar count (v-1) }
 
 对于简单的线程通信和交互,MVar就可以满足大部分需求；对于复杂的通信，Haskell还提供了**Channel**支持：
 
-``` haskell
+```haskell
 c>:info Chan 
 data Chan a
 = Control.Concurrent.Chan.Chan (MVar
@@ -157,7 +157,7 @@ instance Eq (TVar a) -- Definedned in `GHC.Conc.Sync'
 
 对应的TVar操作：
 
-``` haskell
+```haskell
 ghc>:t newTVar
 newTVar :: a -> STM (TVar a)
 ghc>:t readTVar
@@ -172,7 +172,7 @@ writeTVar :: TVar a -> a -> STM ()
 
 下边这个例子来自于[wikipedia](http://en.wikipedia.org/wiki/Concurrent_Haskell):
 
-``` haskell
+```haskell
 type Account = TVar Integer
 
 transfer :: Integer -> Account -> Account -> STM ()
@@ -210,7 +210,7 @@ atomically :: STM a -> IO a
 
 下边是一个调用上述实现的例子：
 
-``` haskell
+```haskell
 module Main where
  
 import Control.Concurrent (forkIO)
diff --git a/_posts/2012-08-02-parallel-programming-in-haskell.markdown b/_posts/2012-08-02-parallel-programming-in-haskell.markdown
index dd2d064..b7f1fc6 100644
--- a/_posts/2012-08-02-parallel-programming-in-haskell.markdown
+++ b/_posts/2012-08-02-parallel-programming-in-haskell.markdown
@@ -3,7 +3,7 @@ layout: post
 title: "Parallel programming in Haskell"
 date: 2012-08-02 20:55
 comments: true
-categories: [haskell, concurrency, performance, tips, 学习笔记]
+categories: [notes, design, programming]
 ---
 
 Parallel和Concurrency的目标是一致的，然后Parallel更强调在多个物理并发处理单元（至少从OS之上的角度看如此）存在的情况下，如何最大限度地利用现有的CPU资源提高程序的性能。传统的过程式编程思维范式中，所有的操作都是顺行串行的，多核并发处理往往意味着需要对代码做大幅度的修改；而Haskell的并行编程则因为其**Lazy Evaluation**特性而变得简单许多 - 基于现有的代码做一些相对细微的改动就可以使得某些操作并行起来。同样由于这一Lazy特性和表达式赋值的灵活性，很多隐晦的问题也很容易随之而生。Haskell通过提供Strategy抽象将赋值策略和实际算法隔离开来，从而灵活的解决了Lazy带来的副作用。
@@ -51,7 +51,7 @@ ghc -threaded -o NumCapabilities NumCapabilities.o
 ### 分治法的例子 - QuickSort
 
 下边是一个简单的分治法例子 - 快速排序：
-``` haskell
+```haskell
 sort :: (Ord a) => [a] -> [a]
 sort (x:xs) = lesser ++ x:greater
     where lesser  = sort [y | y <- xs, y <  x]
@@ -60,7 +60,7 @@ sort (x:xs) = lesser ++ x:greater
 ```
 
 对于这个朴素的例子，可以通过一些细微的变化使其并行起来：
-``` haskell
+```haskell
 import Control.Parallel (par, pseq)
 
 parSort :: (Ord a) => [a] -> [a]
@@ -117,7 +117,7 @@ GHC的GC还是采用单线成的方式，因而在GC工作的时候，其它线
 
 回到上边的例子，为了将传统的顺序程序改为并行，我们必须在代码中小心的插入`pseq`/`par`/`force`来指明整个并行方式需要如何赋值运算，甚至对于`list`类型，还需通过自定义的`force`函数来强制赋值每一个元素以保证算法的正确性,这一方式看起来无疑是非常繁琐甚至重复的。再考虑`map`这一很重要的函数，对于并发控制，同样需要定义一个`paralleMap`才能放在代码里边用:
 
-``` haskell
+```haskell
 import Control.Parallel (par)
 
 parallelMap :: (a -> b) -> [a] -> [b]
@@ -130,7 +130,7 @@ parallelMap _ _      = []
 
 
 一种想法是，我们可以引入一个指定某个类型的赋值规则的**函数参数**来确定某个类型的赋值方式，譬如：
-``` haskell
+```haskell
 forceListAndElts :: ((a->())-> [a] -> ()
 forceListAndElts forceElt (x:xs) = forceElt x `seq` forceListAndElts forceElt xs
 forceListAndElts _ _ = ()
@@ -141,7 +141,7 @@ forceListAndElts _ _ = ()
 ### Strategies
 
 Haskell通过库的方式提供Strategies的支持：
-``` haskell
+```haskell
 ghc>:m +Control.Parallel.Strategies
 ghc>:info Strategy 
 type Strategy a = a -> Eval a
@@ -156,7 +156,7 @@ instance Monad Eval -- Defined in `Control.Parallel.Strategies'
 instance Functor Eval -- Defined in `Control.Parallel.Strategies'
 ```
 `Strategy`是一个`typeclass`,对每一个类型a, `Eval`构造出一个具体的Strategy，而`Eval`本身则是个`newtype`,并且是个Monad/Functor实例。此外，Strategy库还定义了如下Strategy:
-``` haskell
+```haskell
 ghc>:info rwhnf 
 rwhnf :: Strategy a -- Defined in   `Control.Parallel.Strategies'
 
@@ -201,7 +201,7 @@ parMap strat f xs = map f xs `using` parList strat
 
 上述`parMap`的实现中，左边的算法部分仍然是相同的`map f xs`实现，而`using`函数则将左侧的实际算法和右侧的`Strategy`结合起来了：
 
-``` haskell
+```haskell
 using :: a -> Strategy a -> a
 using x s = s x `pseq` x
 ```
@@ -209,7 +209,7 @@ using x s = s x `pseq` x
 ### MapReduce 的例子
 一个简化版本的MapReduce例子如下：
 
-``` haskell
+```haskell
 mapReduce
     :: Strategy b    -- evaluation strategy for mapping
     -> (a -> b)      -- map function
diff --git a/_posts/2012-08-12-stm-in-haskell.markdown b/_posts/2012-08-12-stm-in-haskell.markdown
index 60beeac..548fe4d 100644
--- a/_posts/2012-08-12-stm-in-haskell.markdown
+++ b/_posts/2012-08-12-stm-in-haskell.markdown
@@ -3,7 +3,7 @@ layout: post
 title: "STM in Haskell"
 date: 2012-08-12 09:54
 comments: true
-categories: [haskell, 学习笔记, concurrency]
+categories: [notes, programming, design, haskell]
 ---
 
 传统的并发变成模型通过Mutex/Conditional Variable/Semaphore的设施来控制对共享资源的访问控制，但是这一经典模型使得编写**正确高效**的并发程序变得异常困难：  
diff --git a/_posts/2012-08-18-c-plus-plus-11-xin-te-xing.markdown b/_posts/2012-08-18-c-plus-plus-11-xin-te-xing.markdown
index 9ba1006..57e895b 100644
--- a/_posts/2012-08-18-c-plus-plus-11-xin-te-xing.markdown
+++ b/_posts/2012-08-18-c-plus-plus-11-xin-te-xing.markdown
@@ -3,7 +3,7 @@ layout: post
 title: "c++11 新特性1 语言特性改进"
 date: 2012-08-18 10:03
 comments: true
-categories: [cpp, clang, llvm, tips, cpp11, 学习笔记]
+categories: [cpp, programming, notes ] 
 ---
 
 **C++11**(C++0x)[定稿](http://herbsutter.com/2011/10/10/iso-c11-published/)已经满一年，主要的编译器这次跟进的速度也相当快，其中支持最好的要属最近声名雀起的[llvm](http://llvm.org/);作为一个历时8年之久的ISO标准，其诞生过程虽然过程很曲折，但是新标准对C++的改进和生产效率的提高无疑是大有益处的。
@@ -50,17 +50,17 @@ STL模板类型的引入使得C++的类型系统变得异常复杂，尤其在
 ## Trailing return type
 -----------------------
 这个特性用于简化模板代码的书写，譬如如下的代码在C++03中是非法的：
-``` c++
+```c++
 template<class Lhs, class Rhs>
   Ret adding_func(const Lhs &lhs, const Rhs &rhs) {return lhs + rhs;} //Ret must be the type of lhs+rhs
 ```
 为了模板函数的灵活性，`Ret`类型必须被指定为一个合理的动态类型-即根据实际传入的LHS/RHS来确定，当然人工指定的办法很不灵活，我们自然希望编译器能够自动推倒，一种自然的想法是尝试用`auto`:
-``` cpp
+```cpp
 template<class Lhs, class Rhs>
   decltype(lhs+rhs) adding_func(const Lhs &lhs, const Rhs &rhs) {return lhs + rhs;} //Not legal C++11
 ```
 可惜这仍然是非法的，因为decltype需要编译扫描的时候必须知道对应参数的类型，而这些信息只有在模板函数实例化的时候才有。为了解决这一个问题，C++11引入了*Trailing return type*:
-``` cpp
+```cpp
 template<class Lhs, class Rhs>
   auto adding_func(const Lhs &lhs, const Rhs &rhs) -> decltype(lhs+rhs) {return lhs + rhs;}
 ```
@@ -121,7 +121,7 @@ enum class Enumeration : unsigned int{
 ## 右扩号的问题修正
 ---------------------
 这是一个bug fix，使得这样的代码变得合法：
-``` cpp
+```cpp
 std::vector<std::pair<int, int>> vec;
 ```
 
@@ -140,7 +140,7 @@ using TypedefName = SomeType<OtherType, Second, 5>;
 ## Union类型可以放置non-POD
 ------------------------------
 C++03中，Union中不可放置POD类型意外的东西，而C++11中，我们可以放置任何类型到Union中了：
-``` cpp
+```cpp
 //for placement new
 #include <new>
  
diff --git a/_posts/2012-08-19-c-plus-plus-11xin-te-xing-rvalue-reference-and-and-move.markdown b/_posts/2012-08-19-c-plus-plus-11xin-te-xing-rvalue-reference-and-and-move.markdown
index e39b1c8..2f83d96 100644
--- a/_posts/2012-08-19-c-plus-plus-11xin-te-xing-rvalue-reference-and-and-move.markdown
+++ b/_posts/2012-08-19-c-plus-plus-11xin-te-xing-rvalue-reference-and-and-move.markdown
@@ -4,7 +4,7 @@ title: "C++11新特性2-RValue Reference 与 Move"
 date: 2012-08-19 09:40
 comments: true
 toc: true
-categories: [cpp, tips, cpp11, 学习笔记]
+categories: [cpp, programming, notes]
 ---
 
 现有的C++03标准中，不必要的对象的拷贝和临时对象的构造经常会造成额外的性能开销（即使有*返回值优化*这样的编译器优化来帮忙也不能解决好多情况的问题）；新的C++11标准通过对语言的修正，引入了**RValue Reference**和**Move**来解决这一问题。
@@ -42,7 +42,7 @@ C++11引入的Rvalue Reference主要是为了解决两个问题：
 ### Rvalue定义
 
 C++03中，不允许定义引用的引用，即`X&& b = x`;而C++11正好借用这个符号来表述Rvalue reference, 即： 
-``` cpp
+```cpp
 class X;
 void func(X&& obj){
 }
diff --git a/_posts/2012-08-26-c-plus-plus-xin-te-xing-3-lambdazhi-chi.markdown b/_posts/2012-08-26-c-plus-plus-xin-te-xing-3-lambdazhi-chi.markdown
index abd7e67..7e3f855 100644
--- a/_posts/2012-08-26-c-plus-plus-xin-te-xing-3-lambdazhi-chi.markdown
+++ b/_posts/2012-08-26-c-plus-plus-xin-te-xing-3-lambdazhi-chi.markdown
@@ -3,7 +3,7 @@ layout: post
 title: "C++新特性3 - Lambda支持"
 date: 2012-08-26 11:23
 comments: true
-categories: [cpp, cpp11, 学习笔记]
+categories: [cpp, programming, notes]
 ---
 
 **lambda表达式(closure)**是C++11中新引入的对程序组织构造改进最大的特性之一；这一特性并不是一个新的概念（几十年前的函数式于样都提供了该特性），然而对于一个深受*过程式思维*影响的语言而言，lambda的支持则极大提高了代码的抽象能力和可读性。
@@ -14,7 +14,7 @@ categories: [cpp, cpp11, 学习笔记]
 
 考虑下边的例子(很简单常见的例子，但很容易说明问题)：
 
-``` cpp
+```cpp
 class AddressBook;
 typedef std::vector<AddressBook> AddressList;
 void getPeopleWithAge(AddressList& result, const AddressList& list, int age){
@@ -84,7 +84,7 @@ auto f = [&]{
 f();
 ```
 甚至可以将lambda函数传入模板参数：
-``` cpp
+```cpp
 // Lambda as template parameters
 template <typename F>
 void Eval(const F& f){
diff --git a/_posts/2012-11-26-awkgao-ji-te-xing.markdown b/_posts/2012-11-26-awkgao-ji-te-xing.markdown
index aa7adf4..2978f5a 100644
--- a/_posts/2012-11-26-awkgao-ji-te-xing.markdown
+++ b/_posts/2012-11-26-awkgao-ji-te-xing.markdown
@@ -3,7 +3,7 @@ layout: post
 title: "awk高级特性"
 date: 2012-11-26 19:49
 comments: true
-categories: awk, regexp, array, unix
+categories: [programming, tools, linux]
 ---
 
 UNIX环境下，用shell做一些常见的文本处理工作是很方便高效的事情；虽然目前有很多自带丰富类库的脚本语言可以完成同样的事情，但是对于一些特殊的文本格式处理任务，传统的sed/awk/grep组合还是有很明显的优势：没有复杂的版本问题和类库部署依赖问题，能够快速解决问题。awk作为一门**DSL**，自身也带有对很多**高级特性**（相对于shell本身）的支持，灵活应用往往能收到奇效。
@@ -15,7 +15,7 @@ array类型
 
 awk自身支持类似于C语言数组的数据结构，称之为**array**，但是其下标却不仅仅限于数字，可以是字符串等其它类型；行为上来说更似于一个关联容器，从某个变量关联到另外一个变量：
 
-``` bash
+```bash
 awk 'BEGIN{
     arr['aa'] = 1
     arr[4] = 2
@@ -73,14 +73,14 @@ awk 'BEGIN{
 
 * `sub` 用于正则替换左数起第一个匹配
 
-``` bash
+```bash
 echo "The lazy dog" | awk '{sub(/[ey] /, "lagggg> ");print}'
 #Thlagggg> lazy dog
 ```
 
 * `gsub` 用于全局替换,所有满足条件的部分都被替换  
 
-``` bash
+```bash
 echo "The lazy dog" | awk '{gsub(/[ey] /, "lagggg> ");print}'
 Thlagggg> lazlagggg> dog
 ```
@@ -88,7 +88,7 @@ Thlagggg> lazlagggg> dog
 
 * `gensub` 是一个更通用形式的正则替换操作,它保持源字符串不动，将修改后的串返回
 
-``` bash
+```bash
 echo "The lazy dog" | gawk '{new = gensub(/[ey] /, "lagggg> ", "g");print; print new}'
 #The lazy dog
 #Thlagggg> lazlagggg> dog
diff --git a/_posts/2012-11-27-linuxshang-ru-he-cong-c-plus-plus-cheng-xu-zhong-huo-qu-backtracexin-xi.markdown b/_posts/2012-11-27-linuxshang-ru-he-cong-c-plus-plus-cheng-xu-zhong-huo-qu-backtracexin-xi.markdown
index c1f7e8b..8bfd87d 100644
--- a/_posts/2012-11-27-linuxshang-ru-he-cong-c-plus-plus-cheng-xu-zhong-huo-qu-backtracexin-xi.markdown
+++ b/_posts/2012-11-27-linuxshang-ru-he-cong-c-plus-plus-cheng-xu-zhong-huo-qu-backtracexin-xi.markdown
@@ -3,7 +3,7 @@ layout: post
 title: "Linux上如何从C++程序中获取backtrace信息"
 date: 2012-11-27 21:41
 comments: true
-categories: [linux, c, cpp, debug, backtrace]
+categories: [linux, debugging, tools]
 tags: [linux, debug, cpp]
 ---
 
@@ -18,7 +18,7 @@ backtrace 系列API
 
 Linux的manpage提供了如下的API原型：
 
-``` cpp 
+```cpp 
 #include <execinfo.h>
 int backtrace(void **buffer, int size);
 char **backtrace_symbols(void *const *buffer, int size);
@@ -76,7 +76,7 @@ Segmentation fault (core dumped)
 
 上述例子的输出如下：
 
-``` bash
+```bash
 Threads started!
 THREAD-3061271360: normal operation begin...
 THREAD-3069664064: normal operation begin...
@@ -123,7 +123,7 @@ Google coredump library
 
 链接在[google code](http://code.google.com/p/google-coredumper/), 用法如下：
 
-``` cpp
+```cpp
 #include <google/coredumper.h>
 ...
 WriteCoreDump('core.myprogram');
diff --git a/_posts/2012-12-04-linux-man-page-related-skills.markdown b/_posts/2012-12-04-linux-man-page-related-skills.markdown
index 303b4de..5bd90d4 100644
--- a/_posts/2012-12-04-linux-man-page-related-skills.markdown
+++ b/_posts/2012-12-04-linux-man-page-related-skills.markdown
@@ -3,7 +3,7 @@ layout: post
 title: "Linux man手册相关小技巧"
 date: 2012-12-04 20:55
 comments: true
-categories: [linux, tips, tools, man]
+categories: [linux, doc, tools]
 ---
 
 Linux下的编程实践中,man手册页的作用是不可小视的，每一个高效的Linux程序员必然往往也具备快速的通过man手册页找到所需文档的能力。本文是一些关于man手册使用中的一些小技巧总结。
@@ -76,7 +76,7 @@ update-alternatives
 ------------------------
 如果需要修改默认的page工具，在Debian以及衍生发行版上，可以使用 `update-alternatives` 工具来修改默认的系统工具程序：
 
-``` bash
+```bash
 update-alternatives --list pager
 #/bin/less
 #/bin/more
diff --git a/_posts/2013-01-25-latexxue-xi.markdown b/_posts/2013-01-25-latexxue-xi.markdown
index 785cf8c..0ad549d 100644
--- a/_posts/2013-01-25-latexxue-xi.markdown
+++ b/_posts/2013-01-25-latexxue-xi.markdown
@@ -3,7 +3,7 @@ layout: post
 title: "latex初探"
 date: 2013-01-25 21:43
 comments: true
-categories: [latex, tex, doc, pandoc, markdown]
+categories: [tools, doc]
 ---
 
 文档悖论
@@ -29,7 +29,7 @@ Pandoc是一个用**Haskell**写就的库，在Windows上安装，则直接到[
 
 windwos平台的安装还需安装Tex工具，都是Exe格式的安装包。装完之后，根据其文档，如下的命令就可以简单的生成PDF文档了（还是写个Makefile方便一些吧）:  
 
-``` make
+```make
 target: test.markdown test.pdf test.html
     echo "done"
 
@@ -55,7 +55,7 @@ latex初探
 ---------------------------
 最简单的文件非**hello world**莫属了，但是需要生成hello world也还是需要不少基本的工作的；当然比起word里边敲敲字符要费劲一些，但是短期的痛苦只是为了长久的便利。完成这个最简单的任务大概是需要这些：
 
-``` tex
+```tex
 \documentclass{article}
 \begin{document}
 Hello world
@@ -67,7 +67,7 @@ Tex的语法看起来和正式的变成语言类似，所有的命令都已`\`
 ---------------
 在`\begin`和`\end`之间的部分是对应文档的内容了。文档的内容组织可以用段落和子段落的方式来组织，默认对段落是自动标号的，譬如下边的代码：  
 
-``` tex
+```tex
 %preambles
 \documentclass{article}
 \usepackage{times}
@@ -147,7 +147,7 @@ Some introduction text
 1. 定义  
    在文档结束之后，可以通过`\begin{thebibliography}{9}`的格式来定义参考文献列表，其后用`\end{thebibliography}'结束，譬如如下例子：   
 
-``` tex
+```tex
 \begin{thebibliography}{9}
     \bibitem{autha91}
     some auther, 
diff --git a/_posts/2013-02-02-pandoczhuan-huan-ji-qiao-zhi-cong-markdowndao-pdf.markdown b/_posts/2013-02-02-pandoczhuan-huan-ji-qiao-zhi-cong-markdowndao-pdf.markdown
index 1009aea..666e7d9 100644
--- a/_posts/2013-02-02-pandoczhuan-huan-ji-qiao-zhi-cong-markdowndao-pdf.markdown
+++ b/_posts/2013-02-02-pandoczhuan-huan-ji-qiao-zhi-cong-markdowndao-pdf.markdown
@@ -3,7 +3,7 @@ layout: post
 title: "Pandoc转换技巧之从markdown到PDF"
 date: 2013-02-02 20:52
 comments: true
-categories: [pandoc, markdown, pdf, latex, doc]
+categories: [tools, doc]
 ---
 
 用Pandoc这一神器可以实现N多文档格式的转换，这里仅记录一些小技巧。
@@ -23,19 +23,19 @@ PDF输出可以用以下格式来控制：
 - 生成TOC目录表 : 使用`--toc`  
 - 控制生成的目录标题，使其自动编号。默认情况，**标题是不自动编号的**。  
 
-``` bash
+```bash
 pandoc --toc --number-sections test.markdown -o test.pdf
-``` 
+```
 - 生存beamer格式的幻灯片：  
 
-``` bash
+```bash
 #--slide-level specifies the maximum title level
 # -t beamer specifies beamer format for slide show
 pandoc --slide-level=2 -t beamer test.markdown -o test.pdf
 ```
 - 禁用pandoc的markdown扩展(采用标准markdown语法)： 
 
-``` bash
+```bash
 #-f markdown_strcit[+feature]
 pandoc -f markdown_strict test.markdown -o test.pdf
 ```
diff --git a/_posts/2013-02-24-pyqtxue-xi-xiao-bi-ji.markdown b/_posts/2013-02-24-pyqtxue-xi-xiao-bi-ji.markdown
index 28afc29..b9a0dfa 100644
--- a/_posts/2013-02-24-pyqtxue-xi-xiao-bi-ji.markdown
+++ b/_posts/2013-02-24-pyqtxue-xi-xiao-bi-ji.markdown
@@ -3,7 +3,8 @@ layout: post
 title: "PyQt学习小笔记"
 date: 2013-02-24 09:39
 comments: true
-categories: [pyqt, qt, python, GUI]
+categories: [programming, tools]
+tags: [programming, python, tools]
 ---
 
 PyQT是知名跨平台框架QT的python绑定；用它来做些小程序既可以利用QT的跨平台性又能利用python强大的表达能力,从而取得事半功倍的效果。下边是使用它开发一个小程序过程中的学习小笔记。
@@ -21,7 +22,7 @@ PyQT是知名跨平台框架QT的python绑定；用它来做些小程序既可
 生成的代码主要集中于控件显示的部分，事件处理的部分虽然也可以产生，但是仅适用于自定义子类的对象，因为在slot里边没法很方便的为已有的某个UI对象添加新的方法，只能靠子类化的办法来修改类的预定义slot，远不如在代码中自己写来的快捷方便。
 
 每个界面的设计最终会生成一个**.ui**后缀的XML文件，使用如下的Makefile规则可以做方便的转换：
-``` bash
+```bash
 %.py : %.ui
     pyuic4 $^ > $@
 ```
diff --git a/_posts/2013-08-04-github-pages-upgrade.markdown b/_posts/2013-08-04-github-pages-upgrade.markdown
index ebf237e..d769f6a 100644
--- a/_posts/2013-08-04-github-pages-upgrade.markdown
+++ b/_posts/2013-08-04-github-pages-upgrade.markdown
@@ -3,7 +3,7 @@ layout: post
 title: "Github pages upgrade"
 date: 2013-08-04 23:07
 comments: true
-categories: github
+categories: blog
 ---
 
 GitHub的后台发生了更新，原来的**github.com**换成了**github.io**，导致原来的**octopress**的Rakefile变得不能正常工作。
diff --git a/_posts/2013-08-05-pragmatic-programmerzai-du.markdown b/_posts/2013-08-05-pragmatic-programmerzai-du.markdown
index ee61cf7..e59222d 100644
--- a/_posts/2013-08-05-pragmatic-programmerzai-du.markdown
+++ b/_posts/2013-08-05-pragmatic-programmerzai-du.markdown
@@ -3,7 +3,7 @@ layout: post
 title: "Pragmatic Programmer再读"
 date: 2013-08-05 21:18
 comments: true
-categories: [programming,reading]
+categories: [programming,notes,engineering]
 ---
 
 这是一本讲述程序员开发哲学和思想的书，虽然出版了十余年仍然没有太多过时的东西，因为讲述的内容是一些永远不会过时的东西（至少从计算机程序设计职业化-即所谓的软件工程开启的时间算便是如此）。
diff --git a/_posts/2013-08-06-the-productive-programmer.markdown b/_posts/2013-08-06-the-productive-programmer.markdown
index cd23bb5..03c59ce 100644
--- a/_posts/2013-08-06-the-productive-programmer.markdown
+++ b/_posts/2013-08-06-the-productive-programmer.markdown
@@ -3,7 +3,7 @@ layout: post
 title: "The productive Programmer - 笔记"
 date: 2013-08-06 20:24
 comments: true
-categories: [reading, programming, tools, tips]
+categories: [ programming, tools, tips]
 ---
 
 这是一本关于程序员生产效率的书，作者来自于Thought Works - 很多人一听到这个公司的名字就会在头脑中联系到敏捷/布道师这样的角色，并且可能在心里暗暗的寻思，又是一个光说不练的家伙在传播他们的理论了。但是仔细读来，才会发现这本书其实和敏捷并没有太大关联，讲述的也是一些实实在在的建议和实践。
@@ -49,7 +49,7 @@ Windows PowerToys的系列工具之一可以再右键菜单上加入“当前目
 ### Windows的有根视图
 
 就是一种以某个子目录为文件结构根目录的做法；从中可以看到这个子目录的内容，但是不需要关心其它目录的内容。可以用如下的方式打开有根视图:
-``` bash
+```bash
 explorer /e,/root,c:\work\cit
 ```
 
diff --git a/_posts/2013-08-11-agile-software-development-the-cooperative-game-reading-1.markdown b/_posts/2013-08-11-agile-software-development-the-cooperative-game-reading-1.markdown
index dbfdad0..ba06141 100644
--- a/_posts/2013-08-11-agile-software-development-the-cooperative-game-reading-1.markdown
+++ b/_posts/2013-08-11-agile-software-development-the-cooperative-game-reading-1.markdown
@@ -3,7 +3,7 @@ layout: post
 title: "Agile software development - The cooperative game - 笔记 - part1"
 date: 2013-08-11 09:52
 comments: true
-categories: [reading, software, engineering, agile, methodologies]
+categories: [ engineering, notes ]
 ---
 
 这本书的中文译名是一个平淡无奇的<<敏捷软件开发>>，这个名字是如此的平庸以至于放在书架上不会有几个人注意到它真正的价值，除非你仔细的阅读了书面封底的作者介绍和英文原版所获得的荣耀 - 17届Jolt大奖获奖作品；而Cockburn大师本身又属于一个人能连续两次获得Jolt的技术作家之一；但是能够在连续两年中获得两次Jolt大奖的，估计又少之又少了。
diff --git a/_posts/2013-08-14-agile-software-development-the-cooperative-game-reading-2.markdown b/_posts/2013-08-14-agile-software-development-the-cooperative-game-reading-2.markdown
index 191e92d..fec4749 100644
--- a/_posts/2013-08-14-agile-software-development-the-cooperative-game-reading-2.markdown
+++ b/_posts/2013-08-14-agile-software-development-the-cooperative-game-reading-2.markdown
@@ -3,10 +3,10 @@ layout: post
 title: "Agile software development - the cooperative game - 笔记 - part2"
 date: 2013-08-14 20:32
 comments: true
-categories: [reading, software, engineering, agile, methodologies]
+categories: [ engineering, notes]
 ---
 
-本文是第二部分([第一部分]({{ root_url }} /blog/2013/08/11/agile-software-development-the-cooperative-game-reading-1/index.html))。
+本文是第二部分([第一部分]({{ root_url }} /post/2013/08/11/agile-software-development-the-cooperative-game-reading-1/index.html))。
 
 <!--more-->
 
diff --git a/_posts/2013-08-18-agile-software-development-the-cooperative-game-reading-3.markdown b/_posts/2013-08-18-agile-software-development-the-cooperative-game-reading-3.markdown
index 0cc9f1e..a4f2fcd 100644
--- a/_posts/2013-08-18-agile-software-development-the-cooperative-game-reading-3.markdown
+++ b/_posts/2013-08-18-agile-software-development-the-cooperative-game-reading-3.markdown
@@ -3,13 +3,13 @@ layout: post
 title: "Agile software development - the cooperative game - 笔记 - 3"
 date: 2013-08-14 20:32
 comments: true
-categories: [reading, software, engineering, agile, methodologies]
+categories: [ engineering, notes]
 ---
 
 本文是第三部分。
 
-- [第一部分]({{ root_url }} /blog/2013/08/11/agile-software-development-the-cooperative-game-reading-1/index.html)。
-- [第二部分]({{ root_url }} /blog/2013/08/14/agile-software-development-the-cooperative-game-reading-2/index.html)。
+- [第一部分]({{ root_url }} /post/2013/08/11/agile-software-development-the-cooperative-game-reading-1/index.html)。
+- [第二部分]({{ root_url }} /post/2013/08/14/agile-software-development-the-cooperative-game-reading-2/index.html)。
 
 <!--more-->
 
diff --git a/_posts/2013-08-24-agile-software-development-the-cooperative-game-reading-4.markdown b/_posts/2013-08-24-agile-software-development-the-cooperative-game-reading-4.markdown
index c3c75fb..56b6f5f 100644
--- a/_posts/2013-08-24-agile-software-development-the-cooperative-game-reading-4.markdown
+++ b/_posts/2013-08-24-agile-software-development-the-cooperative-game-reading-4.markdown
@@ -3,14 +3,14 @@ layout: post
 title: "Agile software development - the cooperative game - 笔记 - 4"
 date: 2013-08-24 19:32
 comments: true
-categories: [reading, software, engineering, agile, methodologies]
+categories: [ engineering, notes]
 ---
 
 本文是第四部分，主要讨论方法论和方法设计的一些基本规则，已经如何清晰地**定制和应用**这些规则。
 
-- [第一部分]({{ root_url }} /blog/2013/08/11/agile-software-development-the-cooperative-game-reading-1/index.html)。
-- [第二部分]({{ root_url }} /blog/2013/08/14/agile-software-development-the-cooperative-game-reading-2/index.html)。
-- [第三部分]({{ root_url }} /blog/2013/08/18/agile-software-development-the-cooperative-game-reading-3/index.html)。
+- [第一部分]({{ root_url }} /post/2013/08/11/agile-software-development-the-cooperative-game-reading-1/index.html)。
+- [第二部分]({{ root_url }} /post/2013/08/14/agile-software-development-the-cooperative-game-reading-2/index.html)。
+- [第三部分]({{ root_url }} /post/2013/08/18/agile-software-development-the-cooperative-game-reading-3/index.html)。
 
 <!--more-->
 
diff --git a/_posts/2015-10-04-cpp-conf-and-core-guidelines.md b/_posts/2015-10-04-cpp-conf-and-core-guidelines.md
new file mode 100644
index 0000000..46b55b8
--- /dev/null
+++ b/_posts/2015-10-04-cpp-conf-and-core-guidelines.md
@@ -0,0 +1,105 @@
+---
+layout: post
+title: CppCon2015 and Cpp Core Guidelines
+categories: [cpp, programming, design, engineering]
+tags: [programming, design, cpp, guideline]
+---
+C++社区的第二届编程语言社区活动[CppCon2015](https://cppcon.org/2015program/)落下了帷幕；作为C++语言的发明人和灵魂人物，
+Stroustroup和Herb Sutter一起宣布他们正工作与一个基于现代C++核心语言的编程规范（**Core Guidelines**）并发布
+在[GitHub](https://github.com/isocpp/cppcoreguidelines)上，并立即引起了轰动。
+
+<!--more-->
+
+CppCon大会所有的演进材料和培训资料都放在[Github](https://github.com/CppCon/CppCon2015)上；今年的重头戏无疑属于Core Guidelines。
+
+## 核心编程规范
+
+该规范目前主要的编辑依然是Herb Sutter和Stroustroup；其目的是为了提供一份相对**官方的编程指南**；帮助社区程序员用好C++语言，避免误用，提高现代C++
+的使用率，减少不合理的误用、滥用，因为C++语言实在是太复杂了；很多是仅仅是因为语言提供了某些机制，就像到处使用该机制制造出难以理解和维护的代码；
+毕竟**可以这样做并不意味值就必须要这样做**。
+
+另外一个诱因是，现代的C++语言引入了很多新的语言特性导致很多传统的C++程序员有点疑惑这是否是一门新的语言了。
+> "Within C++ is a smaller, simpler, safer language struggling to get out." -- Bjarne Stroustrup
+
+文档提供了一份在线版本，可以从[项目的GitHub Pages页面](http://isocpp.github.io/CppCoreGuidelines/CppCoreGuidelines)来访问和浏览非常方便。
+
+### 顶层目标
+
+该编程规范的目的明显的不同于传统商业公司或者项目团队的编程规范；因为它不会侧重于解释某一些语言特性或者特定的问题；而是更多**从设计的角度**给出建议，包括
+- 接口设计和使用
+- 模板元编程的取舍，什么场景下应该使用，什么情况下算误用
+- 设计约束和限制，例外情况
+- 设计/编码哲学，如何取舍不同方案等
+- 工程实践推荐，使用工具，如何使用
+- 错误处理机制，异常，返回值等
+
+### 基本组成
+规范采用统一格式的条目组成，这些条目按照主题被分成为不同的章节，包括
+- 概要介绍：规范的目标，非目标，文档结构和一些主要的章节
+- 设计哲学：如何表述编码意图，采纳标准语言设施，表述业务意图，采用强类型，优先采纳编译器类型检查机制，采用RAII防止资源泄露，使用合适的工具或库等
+- 接口设计：遵循良好的业界**基于接口编程**的实践，避免全局变量，采用强类型的接口；明确表述前置条件/后置条件等
+- 其它按照语言特性分开描述的章节
+
+### 单独条目组织方式
+每个具体的条目规则采用示例代码加描述的方式，便于搜索和参考。大部分条目由5个部分组成。
+
+Reason部分描述为什么需要遵守给定的规则；会简单的描述一下特定规则背后的动机和原因。
+
+Example会给出具体的例子来阐述规则的内容。大部分情况下，会给出好的示例和坏的示例。比较复杂的条目，可能给出多个例子便于参考。
+语言机制有所演进的时候，不同的语言版本下的好的或者坏的例子都会给出来。
+
+Note部分会给出一些额外需要注意的地方；或者参照应用链接等。
+
+Enforcement会列出对应规则的附加限制条件。
+
+Exception对适应的规则会给出一些例外情况，因为大部分规则通常都有例外情况。有例子的话也会一并给出。
+
+### 项目支持工具
+
+Microsoft开源了一个相关的规范支持工具 - [GSL](https://github.com/Microsoft/GSL)，这是一个仅有头文件组成的库，应该很容易集成到支持C++14的编程环境中。
+该项目提供了一系列测试用例，可以在GCC/VC/LLVM上编译。
+
+希望该编程规范可以被更多的C++项目团队所采纳。
+
+## 其它印象深刻的材料
+
+除了上述编程规范，还有一些演讲让人眼前一亮
+
+### Ranges Library
+来自于Eric Niebler的Ranges库([演讲材料](https://github.com/CppCon/CppCon2015/blob/master/Keynotes/Ranges%20for%20the%20Standard%20Library/Ranges%20for%20the%20Standard%20Library%20-%20Eric%20Niebler%20-%20CppCon%202015.pptx)) 
+ 将管道的思想和函数式编程的类Monad操作发挥到了一个令人瞠目结舌的境界，可以用简洁的代码更清晰的描述业务逻辑。
+示例代码是一个优雅地打印一个字符界面的日历的例子，可以简洁地写为
+
+```cpp
+std::copy(
+    dates_in_year(2015)                         //0. Raw range data (Date objects)
+        | by_month()                            //1. Group the dates by month
+        | layout_months()                       //2. format the months as a range of strings 
+        | chunk(3)                              //3. Group the months as chunks of 3 side by side
+        | transpose_months()                    //4. Transpose the rows and columns of the side-by-side months
+        | view::join                            //5. Ungroup the months 
+        | join_months(),                        //6. Join the string of transposed months
+    std::ostream_iterator<>(std::cout, "\n")
+);
+```
+函数式编程的可组合、高度可重用、不需要循环而仅仅关注意图的编程风格带来更容易维护、更简洁清晰的代码。 
+声明式编程风格对C++而言不再遥远。期望它能早日进入新的语言标准库中造福广大程序员。
+
+更多细节和Proposal详见[N4128](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2014/n4128.html)和[N4382](http://www.open-std.org/JTC1/SC22/WG21/docs/papers/2015/n4382.pd)。
+基于C++11实现的库代码开源在[Github](http://www.github.com/ericniebler/range-v3
+)。
+项目文档在该项目的[GitHub Pages](https://ericniebler.github.io/range-v3/index.html)页面上；包含有几个基本部分的文档
+- 基本安装和使用：基于头文件的轻量级的库，仅仅需要放置在合适的安装路径中，包含头文件即可；本身也提供了一个`<range/v3/all.hpp>`的头文件方便使用。
+- 可组合的Views类，采用函数式风格的组合模式。
+- Actions类用于对range做一些修改性操作，譬如join/erase/insert/drop等。
+
+#### C++中的Atomics
+[C++11, 14, 17 Atomics - the Deep Dive](https://github.com/CppCon/CppCon2015/blob/master/Presentations/C++11,%2014,%2017%20Atomics%20-%20the%20Deep%20Dive/C++11,%2014,%2017%20Atomics%20-%20the%20Deep%20Dive%20-%20Michael%20Wong%20-%20CppCon%202015.pdf) 来自于前OpenMP项目创始人的华人C++大拿的深入探讨新的C++语言中的原子性操作支持和并发编程；读来让人深思。
+
+Michael Wong回顾了传统C++编程中的性能、并发、一致性的挑战，以及语言层面的逐步进化：从早期C++98/03标准的未置一词，到C++11首次引入的内存模型，原子类型等基本概念的支持，
+进而是C++14的无所算法增强和无锁算法支持和`atomic_signal_fence`，再到未来的C++17中需要定义的内存访问次序强一致性保证和原子性视图，
+有一些追赶Java并发支持的味道，当然C++有自己的挑战需要解决；看来是个长期的任务。
+
+#### 并行STL
+[Parralellizing the C++ STL](https://github.com/CppCon/CppCon2015/blob/master/Presentations/Parallelizing%20the%20C++%20STL/Parallelizing%20the%20C++%20STL%20-%20Grant%20Mercer%20and%20Daniel%20Bourgeois%20-%20CppCon%202015.pdf)介绍了新的C++中，容器算法的并行化做法，基本上一些耦合不紧易于分解的数据算法，可以很简单的调度到多核CPU上
+
diff --git a/_posts/2015-11-28-rust-language-quick-overview.md b/_posts/2015-11-28-rust-language-quick-overview.md
new file mode 100644
index 0000000..2f01985
--- /dev/null
+++ b/_posts/2015-11-28-rust-language-quick-overview.md
@@ -0,0 +1,696 @@
+---
+layout: post
+title: Rust编程语言初探
+categories: [language, programming, notes]
+tags: [programming, concurrency, design, rustlang]
+---
+**静态、强类型而又不带垃圾收集**的编程语言领域内，很久没有新加入者参与竞争了，大概大部分开发者认为传统的C/C++的思路**已经不太适合新时代的编程需求**，即便有Ken Tompson这样的大神参与设计的golang也采用了GC的思路来设计其新一代的语言；一方面垃圾收集技术和即使编译技术一直在发展和完善，另一方面是大量的未经过严格计算机科学基础训练的开发人员进入市场，似乎让开发者永远停留在逻辑层面而不是去直接操纵内存是个更为现代的选择，Mozilla却仍然坚信一门静态而又高效低利用系统资源的“偏底层”的语言也依然会有巨大的生命力；于是站在现代成熟的软件工程实践上的[Rustlang](https://www.rust-lang.org/en-US/)(以下简称`Rust`)被创造出来，其新版本的发布不时引起[HackNews](https://news.ycombinator.com/item?id=9551937)等极客圈的关注。
+
+本文试图通过其官方文档对该语言（以及其相关的生态系统）做简单的研习。
+
+<!--more-->
+
+## 核心语言特性设计目标
+按照其官方描述，Rust需要满足其以下几个核心目标
+1. 使用于系统编程场景 - 这意味着能够有直接访问操作系统基础设施和硬件的能力。
+2. 开源参与和协作 - 毕竟其背后的推动者是创造了第一代浏览器的Mozilla，比任何商业公司更懂得依靠**开源社区的力量**
+3. 安全而又高效 - 在现代的软件工程环境中，安全是不可或缺的，而面向系统编程场景的语言必然少不了对**性能的极致要求**
+4. 充分利用现代**多核和并发处理**技术的能力 - 这也是传统的C/C++语言的软肋所在；同时也是Google的Golang的设计目标之一
+5. 容易学习的语法 - 减少类似于段错误或隐式的多线程编程等相对底层的细节应该尽量被隐藏
+
+根据以上目标可以相对容易的理解一些核心的语言设计策略背后的决策依据。
+
+## 基本语法特性
+作为一门面向系统编程的**偏底层**的程序语言，其基本语法和传统的C/C++/Java系列语言共享了很多共同之处，这里仅需要看看其不同之处。
+
+### 类型系统
+静态语言的基本元素之一是变量和类型；不同的语言会选择不同的类型定义和内置的开箱可用的基本类型；这些类型及内置类的设计往往反映了编程语言设计者的决策策略和权衡要素。
+
+#### 类型声明和自动推断
+
+毕竟要面对的是偏严肃的**系统编程**领域，选择静态类型可以在编译阶段**尽可能早地发现更多的**程序错误是题中之义；同时作为一门比较现代的编程语言，每次让程序员自己输入每个变量的类型这类臃肿的做法也被废弃，**自动类型推断**必不可少 - 当编译器可以"聪明地"推导出合适的类型的时候，变量类型指定可以忽略。
+
+譬如需要声明一个某种类型的变量，Rust用`let x: someType = <some value>`来表示；当然对于编译器可以推导出来类型的情况下，类型是可以省略的这样可以少写一些啰嗦的代码，`let x = 2`就会定义一个整数类型的变量`x`;比较新的编程语言基本都是这么做的，没有什么新意。
+
+作为一门**强类型的语言**，任何变量或者表达式必须有唯一的类型，否则编译的时候就会报错。当然Rust支持一种特殊的变量隐藏机制(Shadow),即同一个名字的变量可以重新使用，并设置为一个完全不同的类型；这个时候**原来的变量就不能被访问**了。如
+
+```rust
+let var = "something"; //string literal
+let var = 1; //changed to int
+```
+
+这种机制从某种程度上来说，反而会使代码变得不太容易理解，如果程序员习惯了C/C++的编程方式的话；同时**也会给IDE等工具的解析**带来一些挑战；当然这个是仁者见仁智者见智的事情。
+
+#### 类型可变性约束
+
+Rust要求所有定义的变量必须指定是否是**可变**的；并且作为变量的基本特征强制程序员做合理的选择。
+可变的变量用类似`let mut varName:Type = value`的语法来定义，顾名思义可以在**声明之后被重新赋值**修改；
+而不可变的变量少了一个`mut`关键字，其定义的变量在初始化一次后续就不能再修改了。
+
+Rust里边同时支持常量类型，用`const`来声明，像是从C++里借鉴来的。它和可变类型`mutable`有一些细微的不同:
+对于常量类型我们必须使用类型注解，不能声明可变的常量类型（不允许混合`const`和`mut`),而且常量类型只能被赋值为一个常量表达式，
+不能用函数调用的结果或者是其他一些运行时计算出来的值来初始化。
+综合来看，Rust的常量类型和C++11中新引入的[`constexpr`](http://en.cppreference.com/w/cpp/language/constexpr)行为比较接近。
+
+#### 内置类型
+
+内置类型一般用于提供大部分程序员都要用到的基本数据结构。除了一些其他语言都常见的基本类型(Rust称之为标量类型)，Rust也提供了一些相对比较复杂的类型。
+
+基本标量类型包含以下这些基本的类型
+- 整型类型，包括定长的8/16/32/64位的有符号和无符号类型（如`u16`是无符号16位整型，`i32`是有符号32位类型），
+还支持平台相关的有符号/无符号类型，分别用`isize`和`usize`表示
+- 浮点类型，支持单精度(`f32`)和双精度(`f64`)类型，这些在数值计算的时候比较关键
+- 布尔类型，和C++中的比较类似，有`true`和`false`两种可能的取值，当然没有C/C++中的那些隐式转换的麻烦
+- 字符类型，支持Unicode
+
+#### 复合类型`
+比较新一点的语言都支持一些复杂一点的基本组合类型。
+
+`tuple`和其它语言的比较类似，用括号语法来声明，基本用法可以看下边这个简单的例子
+```rust
+let tup = (1, 2.2, "something")
+let (a, b, c) = tup
+let secondElem = tup.1
+```
+第一行代码声明一个含有三个不同类型的元素的元组；第二行代码则将元组中的元素逐一取出，和Python的用法比较类似。
+除了这种提取方式，元组元素**也可以用点语法**来访问元素，如上边的第三行代码则用`tup.1`则取出第二个元素；
+比[C++11的模板元语法](http://en.cppreference.com/w/cpp/utility/tuple/get)简单多了。
+
+数组则用于表示**具有相同类型的元素的集合**，如`let arr = [1, 2, 3, 4, 5]`,如果类型不一致则会有编译错误报出。
+和C/C++这中的类似，数组元素一般是分配在栈上的，其大小在编译器应该是预先确定的；如果需要可变长的容器，则需要`Vector`类型。
+数组越界的检查默认也包含在语言中了，如果访问越界的下标，默认程序就会崩溃；当然Rust的错误处理机制也有些特殊，容后探讨。
+
+#### 容器类型
+Rust支持以下基本的容器类型
+- `Vector` 该类型用于存储逻辑上的列表类型，其正式名字是`Vec`,用`Vec::new()`创建空的向量，因为其是用泛型实现的，我们必须指定类型注解；
+即是用 `let v: Vec<i32> = Vec::new()` 来生成一个新的向量`v`
+
+- `String` 是**作为一个库提供**的而不是基本的语言机制；其实现和C++的比较类似，内部也使用一个`Vec<u8>`来存储数据的，因此考虑到国际化的原因，其操作可能比其它语言中的要复杂一些；幸运的是，这些细节以及被标准库所封装。
+
+- `Hashmap` 用于表述逻辑上的**哈希关联容器**；其提供的API和C++/Java的比较类似，功能上比C++的复杂一些但比Java的更精简一点
+
+### 函数
+
+作为基本编程要素的函数在Rust中的定义没有什么特别特殊的地方，除了其类型声明是后置风格之外，其返回类型（如果不能被自动推断）用`->`来声明，比如
+```rust
+//一个返回int类型的函数
+fn thisIsAFunction(parA: i32, parB: string) -> int {
+    //some implementation
+}
+```
+
+函数的实现体本质上是一个`block`，由一系列的表达式组成（当然表达式也是用分号分隔的)，同时它**还支持Ruby风格的自动返回最后一个表达式**的写法，
+仅仅需要最后一个表达式省略分号即可；比如这个简单的函数
+
+```rust
+fn five() -> i32 {
+    5
+}
+```
+懒惰是伟大程序员的优良品质嘛。由于我们有内置的`tuple`类型，因此Rust是可以允许有多个返回值的；
+比较典型的一个场景是用户错误处理的情况，可以返回一个`Result`，同时携带错误码和可能的原因;稍后会仔细看一下异常处理的部分。
+
+#### 函数和宏
+
+Rust本身支持语法层面的宏，并且其标准库提供了很多各种各样的宏，譬如最常用的打印函数其实就是一个宏；所有的宏使用`!`后缀来区分。
+`println!("The value of x is {}, y is {}", x, y)`用于打印出x和y的值；其语法形式非常像一些常见的Java库所支持的格式，可以用大括号来打印对象。
+
+[宏是在编译的早期阶段](https://doc.rust-lang.org/book/first-edition/macros.html)被展开的，和C中的宏原理类似，虽然Rust的语法看起来更简洁一些；但是依然有很多新的语法构造，简单来说可以认为Rust的宏是用`macro_rules`和模式匹配来实现的。
+
+从可维护的角度来说，应该做好折中因为宏代码往往意味着**更难理解和调试**。很多时候，需要将宏作为最后一种不得已而为之的措施。
+比C中的宏好一点的是，Rust提供了对宏进行调试的方式，可以在其编译器的命令行中加入`--pretty expand`选项来查看展开的代码。
+
+### 错误检查机制
+现实生活中的软件总是有各种各样的错误**需要被正确处理但没有被及早处理**就泄漏到了客户现场。
+Rust采用的设计思路是，尽早强迫程序员去显示处理并以编译器错误的方式提示程序员。
+
+和Java的关于错误分类的思路类似，Rust也**区分可恢复的错误和不可恢复的错误**，并提供了相应的语言机制上的支持。
+可恢复的错误一般是一些环境的错误，譬如文件找不到或者网络连接失败等情况，实现上可以用重试等策略来尝试自动恢复。
+不可恢复的错误往往意味着编程错误或低级bug，这种情况下最好的思路是直接让程序崩溃，并修复代码。
+
+和Java不同的是，Rust里**没有异常**支持！对于可恢复异常，Rust使用`Result<T, E>`类型来封装处理结果，而不可恢复异常则提供`panic!`宏来终止程序继续执行。
+
+#### 不可恢复异常的支持
+遇到不可恢复异常的时候，`panic!`宏会打印错误消息（程序员指定），**展开线程栈帧，打印出实际出错的源代码位置**。
+如果需要打印`backtrace`信息，则可以在程序运行前设置环境变量`RUST_BACKTRACE`。如果忘记设置的话，默认的打印输出会给出温馨的提示。
+
+如果不希望展开栈帧而直接暴力终止程序，可以在Cargo.toml中指定
+```ini
+[profile.release]
+panic='abort'
+```
+
+#### 可恢复异常
+可恢复异常用一个泛型类`Result`来传递结果，其定义是
+```rust
+enum Result<T, E> {
+    Ok(T),
+    Err(E)
+}
+```
+
+可以使用枚举类型的**模式匹配**（见后述) 来优雅的解决，譬如这个操作文件的例子
+
+```rust
+use std::fs::File;
+
+fn main() {
+    let f = File::open("hello.txt");
+
+    let f = match f {
+        Ok(file) => file,
+        Err(error) => {
+            panic!("There was a problem opening the file: {:?}", error)
+        },
+    };
+}
+```
+
+Rust支持一种**更简洁的方法**来简化上述的样板代码`let f = File::open("hello.txt").unwrap()`则返回正常情况下的返回值，如果有异常则直接调用`panic!`来终止程序。
+还有一种更"偷懒/简洁"的做法是，加上额外的描述字符串 - 大部分情况下出错了我们总想额外打印一些信息,可以用
+```rust
+let f = File::open("hello.text").expect("Unable to open file...")
+```
+
+#### 异常的传递和扩散
+这是一个常见的场景，某个API的使用者不想自己去处理异常场景，仅仅想将其传递给自己的调用者去处理，或者程序中有个统一的地方处理异常(通常来说可能不是一个好的主意！)。
+最基本的思路是，直接将异常返回的类型签名写出来，显示让调用者处理。
+
+下边这段代码实现读入一个文件，从里边读取某个字符串，如果成功则返回该字符串，期间有任何错误，则传递给调用者。
+```rust
+fn read_username_from_file() -> Result<String io::Error> {
+    let f = File::open("hello.txt");
+    let mut f = match f {
+        Ok(file) => file,
+        Err(e) => return Err(e),
+    };
+
+    let mut s = String::new();
+    match f.read_to_string(&mut s) {
+        Ok(_) => Ok(s),
+        Err(e) => Err(e),
+    }
+}
+```
+
+Rust提供了一种更**简洁的方式(惯用法)** - 用`"?"操作符`来传递错误，类似的代码可以重写为
+```rust
+fn read_username_from_file() -> Result<String io::Error> {
+    let mut f = File::open("hello.txt")?;
+    let mut s = String::new();
+    f.read_to_string(&mut s)?;
+    Ok(s)
+}
+```
+需要注意到上边的代码使用了`block`的写法省略`return`关键字。
+
+如果追求更精简的代码，我们甚至可以用一行代码来完成上述的函数体
+```rust
+let mut s = String::new();
+File::open("hello.txt")?.read_to_string(&mut s)?;
+Ok(s)
+```
+
+是否有种熟悉的函数式编程的链式写法的味道？
+
+## 内存访问模型和并发
+作为一门面向系统编程的语言，Rust决定了不使用GC，同时基于工程上的原因，让工程师自己来管理内存又显得不符合时代潮流。
+Rust采用的策略是让程序员提供一定的指示给编译器，然后由编译器来确保内存的分配和访问总是安全的。
+
+对于Rust程序用而言，**理解堆和栈以及对象的生存期/作用域是必须的**，虽然编译器在后台做了很多工作。
+为了支持其内存安全和高效约束的目标，Rust提供了一些特殊的语言机制，包括其独特的对象唯一所有权的概念和引用语法，其智能指针的概念也比较有特色。
+
+从语法的角度来看，Rust取消了`->`操作符，因此所有的方法调用都是采用`obj.doSth()`的方式；这点没什么惊喜，没有了C的[后向兼容负担](http://www.gotw.ca/publications/c_family_interview.htm)，基本上新的语言都是这么干的。在语言层面上，Rust仍然**有引用类型的概念**;由于要借助编译器来管理内存，Rust的对象作用域规则有些特殊。
+
+### 对象的唯一Ownership
+默认每个对象都是有唯一的所有权的，这个贯穿在Rust的基本设计规则中
+1. **任何一个值**（基本类型或对象）都唯一关联一个变量，这个变量被称为其Owner
+2. 任何一个时间点，同一个值**仅仅有一个Owner**
+3. 当其Owner离开作用域的时候（无法被程序再次访问），值将会被从内存中释放
+
+举个简单的例子，当我们声明`let s = "hello world"`的时候，字面量`"hello world"`的Owner就是`s`本身；当`s`离开作用域的时候,对应的字面量空间就会被释放。
+作用域的概念和传统的C/C++/Java中的很类似，大部分情况下，是通过大括号来限定作用域的。
+
+比较特殊一点的情况和变量的`shadow`有关，当一个变量通过`shadow`的方式重新指向另外一个对象的时候，原来的值因为**失去了Owner也应该被编译器悄悄释放**了；
+当然这里行为仍然是安全的,因为程序没有通过其它办法再访问原来的值。编译器也可以选择在真正碰到作用域结束的时候再释放，然而这些已经属于编译器的实现细节了，应用程序无需关心。
+非常优雅的**关注点分离**设计!
+
+### 函数调用中的所有权转移
+和C/C++中不一样的是，函数调用的时候，**参数传递会造成所有权转移**即调用者失去了对原来参数的所有权！考虑下边的例子
+```rust
+fn main() {
+    let s = String::from("hello");
+    do_something(s); //s失去对字符串的所有权！
+    let x = 5;
+    do_somethingElse(x); //内置类型被拷贝！
+}
+
+fn do_something(par: String) {
+    //par 拥有外部传入参数的所有权
+} //作用域结束的时候，par对应的对象会被释放
+
+fn do_somethingElse(par: i32) {
+    // play with par
+}
+```
+
+上述例子中，当调用了`do_something(s)`之后，虽然`s`还可以访问但已经失去了对应对象的所有权，其行为和[C++11/14中的Move](http://www.gotw.ca/publications/c_family_interview.htm)很像。第二个例子中`x`对象却依然可以访问，这里的不同是，Rust对象对**分配在栈上的对象默认采用copy方式**处理，
+所以仅分配在内存堆上的对象被Move，栈上的对象（编译期必须知道大小）默认是被复制过去的。
+
+对于分配于堆上的（大小运行期才知道）对象，Rust也提供了`clone`方法来（其实是泛型的annotation）执行深度拷贝。
+
+**函数返回的时候，默认也会转移所有权**，这点和函数调用的参数传递情况类似，只不过是传递/接收参数的顺序反了过来，不再详述。
+
+#### 引用类型
+如果默认的转移所有权的方式不符合实际的场景，Rust还提供了引用类型来指示传递过程中，**仅仅保留对原来参数的引用**而不转移所有权；
+概念上和C的指针很想象，只是有很多额外的措施避免滥用指针可能出现的空指针、悬挂指针等复杂问题。
+
+引用类型在语法上用`&`符号来表示，可以用于修饰标志符，熟悉C/C++的应该不陌生；唯一有点麻烦的是，调用者和函数声明都必须显示声明引用类型，
+如下边的例子
+```rust
+fn calculate_lenght(s: &String) -> usize {
+    s.len()
+}
+
+let s1 = String::from("hello");
+let len = calculate_length(&s);
+println!("The length of '{}' is {}", s1, len);
+```
+
+默认的引用类型是只读的，因为这个**对象是借来的**，被调用函数没有所有权；尝试去修改的话，则会被编译器报错拦住。
+又是一个精妙的设计，多少粗心的错误可以被精明的编译器拦住。
+
+#### 可修改的引用和安全性
+
+如果实在需要在被调用函数中修改传入的引用参数，那么也是可以声明类型为 `&mut SomeType`的，只是出于数据安全性的考虑（避免可能的运行期错误), 
+Rust定义了如下规则来**保证对象的访问总是安全的**；任何可能引起Race Condition的访问模式都**尽量被编译器拦截住**，这样成功编译的代码，出现运行期错误的可能性被大大降低了。
+
+1. 引用的对象必须是合法的
+2. 同一个作用域内（对象是可以被程序访问到的），可以有多个只读的引用
+3. 同一个作用域内，如果已经有一个可修改引用，那么不允许存在其它任何引用，**即使是只读的也不行** 
+4. 不同的作用域内，可以有多个可修改的引用；这里因为对对象的修改是相互隔离的，因此不会有意外情况发生;该规则能保证程序逻辑正确的同时，又尽可能给上层程序更多的自由度
+
+上述最后一条规则其实意味着我们可以有意利用它，通过大括号来创建不同的作用域，写出更简洁的代码，比如
+
+```rust
+let mut aStr = String::from("hello")
+{
+    let r1 = &mut s;
+    //do sth with r1
+} //r1 离开作用域
+
+let r2 = &mut s;
+//基于r2的修改操作
+```
+
+另外一种常见的指针错误是"悬挂指针",在传统的C++程序中，当一个指针指向一个不存在的对象的时候，紧接着所有对指针的操作会**导致未定义的行为**；
+由于实际出现错误的地方和真正“制造出悬挂指针”的地方可能相距万里，这类运行期的错误往往会耗费程序员大量宝贵的时间。考虑下边的例子
+
+```rust
+fn main() {
+    let reference_to_nothing = dangle();
+}
+
+fn dangle() -> &String {
+    let s = String::from("hello");
+    &s
+}
+```
+如果尝试编译上述代码，rust编译器会清晰的报告一个**对象生存期**错误
+```bash
+error[E0106]: missing lifetime specifier
+ --> dangle.rs:5:16
+   |
+ 5 | fn dangle() -> &String {
+   |                ^^^^^^^
+   |
+   = help: this function's return type contains a borrowed value, but there is no
+     value for it to be borrowed from
+   = help: consider giving it a 'static lifetime
+
+error: aborting due to previous error
+```
+#### 对象生存期
+在Rust的内部实现中，一个隐含的逻辑是，**任何一个引用都关联着一个对于的生存期**，大部分情况下生存期都可以由编译器自动推导得到而不需要使用者格外留意。
+当具体的实现中期望引用的生存期可以根据某些条件呈现不同的行为的时候，程序员必须提供一些辅助措施告诉编译器这些额外的判断信息。
+
+Rust编译器内部有一个成为BorrowChecker的工具，它在程序编译的过程中会检查是否所有的引用是合法的。
+当它无法判断引用的生存期的时候，程序员需要在定义的地方传入一些类似于检查点的生存期指示帮助编译器正常检查。
+
+考虑一个取2个字符串slice长度最大者并将其返回的一个函数
+```rust
+fn longest(x: &str, y:&str) -> &str {
+    if x.len() > y.len() {
+        x
+    } else {
+        y
+    }
+}
+```
+编译这段程序的时候，编译器就会报错说，不知道如何决定返回的引用的生存期，因为它要么是`x`，要么是`y`，
+却是由程序的**运行期的行为来动态决定**的，编译器没有办法在编译的过程中做决定。修补这个错误则需要在函数签名中加入生存期标记
+```rust
+fn longest<'a>(x: &'a str, y: &'a str) -> &'a str {
+    if x.len() > y.len() {
+        x
+    } else {
+        y
+    }
+}
+```
+这样编译器就可以知道其实参数和返回值的生存期是一致的，不会产生意外的非法访问或者Race Condition。这里采用的语法是泛型的语法，后边会详细考察一下Rust的泛型支持。
+
+生存期检查的概念是Rust独有的，其采用的类泛型的语法学习起来也显得不是很清晰易懂；这也许是最迷人也最晦涩的特性，从设计的角度来说，
+**牺牲一定的简单性来达到安全编程又不损失性能的目标**也许是个不错的折中;
+既想要高层的抽象，又想要极致的性能，还不想有太多意外的错误是个**刀剑上跳舞的极致挑战**，这方面Rust做的很不错。
+
+### 智能指针
+
+默认的引用方式支持生存期检查和对象借用，实质上采用的任然是所有者唯一的模型；实际应用场景中，程序员可能需要选择一个可以**被多个所有者共享**的对象生存期模型，
+一如C++中很常用的基于[自动引用计数](https://en.wikipedia.org/wiki/Automatic_Reference_Counting)的[shared_ptr](http://en.cppreference.com/w/cpp/memory/shared_ptr)的样子。
+
+Rust通过标准库的方式提供了额外的对象生存期管理模型，包括
+- `Box<T>`类型用于表示一个指向单个堆上分配的对象的指针，该**指针的大小在编译期间是可知的**从而我们可以用它来定义递归的数据结构
+- `Deref Trait`用于表示一个允许通过解引用来访问其封装的数据的智能指针
+- `RefCell<T>` 用来支持可以修改某个不可变参数内部隐藏的数据的模式；默认情况下，引用规则不允许这样的操作。这种情况下会产生不安全的代码，需要程序员做一些额外的处理
+- `Rc<T>`和`RefCell<T>`用于支持环形引用而不引入内存泄露，这个在GC的算法中很常见
+
+细节不一一展开探讨，总体上而言智能指针其实是接管了对象的所有权，并且**在智能指针内部做自动的控制**；这一思路现代C++的实践是英雄所见略同。
+
+### 更简洁的并发支持
+
+支持**安全而又高效**的并发编程是Rust另外一个雄心勃勃的目标。同时Rust又力图做到尽可能的简洁。
+从语言实现上来说，Rust采用了和控制内存安全访问以及对象所有权/生存期以及类型系统完全相同的工具来解决并发的问题，
+尽管这些机制看起来和并发安全相差甚远。
+
+经由大量的类型系统检查、对象生存期检查；大量的并发编程问题都可以在编译器被捕获，从而**编译通过的代码往往就意味着没有并发安全性的问题**找上门；
+程序员可以放心的重构其代码而不用太担心重构后的代码会破坏并发安全性；因此Rust称之为“无所畏惧的并发”。
+
+Rust的并发编程支持一些流行的并发编程模型
+- 基于消息传递的[CSP模型](https://en.wikipedia.org/wiki/Communicating_sequential_processes),这也是Golang所采用的并发方式
+- 传统的基于`Mutex`和对象的所有权来控制共享数据访问的方式 - Rust的类型系统和所有权控制使得其中的挑战降低了不少
+
+从设计上来说，并发支持不是Rust的核心语言的部分，所有的**并发机制都是通过标准库**来提供的，这也意味着更多扩展的可能;有新的并发访问方式，那就写新的库呗。
+
+## 模块系统
+
+## 编程范式和高级特性
+从编程范式的角度来看，Rust本身其实支持多种编程范式因为其某种程度上对标的是现代的C++或者Golang这样的竞争对手。
+
+### 过程式编程
+传统的过程式编程风格和基本的C模型比较接近；
+其定义结构体的方式和C比较类似，依然是采用`struct`来组织数据，所不同的是Rust支持**“方法”和实现分开**定义，通过新的关键字`impl`来添加新的方法实现。
+
+考虑一个简答的例子，定义个矩形以及对应的`area`方法来计算其面积
+
+```rust
+struct Rectangle {
+    length: u32,
+    width: u32,
+}
+
+impl Rectangle {
+    fn area(&self) -> u32 {
+        self.length * self.width
+    }
+}
+```
+
+这里的`area`方法绑定于该`Rectangle`上，第一个参数总是`&self`这样编译器可以自动推导出其类型是所绑定的`struct`对象；因为这里的参数仍然是一个引用，
+默认是不能修改结构体的参数，当需要修改时候，可以指定`&mut self`从而获取一个可修改的引用。这里引用的生存周期模型仍然是适用的。
+
+调用的时候，只需要构造一个结构然后，采用`structObj.callMethod(...)`语法即可;大概是出于简化语言的考虑，Rust只支持简单的`.`语法而丢弃了古老的`->`操作符；
+`->`的使用仅仅限于指定函数的返回类型上，干净清爽了许多。
+
+```rust
+let rect = Rectangle { length: 50, width: 30 };
+println!("The area of rectangle is {}", rect.area())
+```
+
+Rust也支持类似C++中的静态函数的概念，对应的机制Rust称为**关联函数**，这样的机制对大型代码的组织是很有意义的,可以方便地解决名字冲突的问题。
+当定义在`impl`块里的函数其参数中没有`self`的时候，Rust会认为其实一个和某个具体的数据结构无关的函数，它和该结构体类**在同一个命名空间**中。
+比如我们前边已经看到的`String::from("hello")`这样的调用就是将构造方法放置在`String`的`impl`块里，但是完全没有使用`self`参数。
+
+只是现代的C++社区因为有更完善的语言层面的命名空间隔离机制，其实已不太推荐这种古老的静态函数组织方式。
+
+### 面向对象和泛型编程
+
+从形式上来说，Rust不提供对传统的面向对象编程的直接支持，但提供了一些更复杂的**面向接口编程的语言级别机制**。
+这一核心武器就是Rust的`Traits`。某种程度上说，面向接口编程是面向对象编程最核心的精髓之一；
+继承、封装和多态这些基本的武器都可以用面向接口编程的方式来达到。
+
+Rust的泛型编程实现上有很明显的C++的影子，不同的是它通过`Traits`机制巧妙的将**编译器多态和运行期多态统一为一体**了。
+
+#### Traits
+
+`Traits`从**概念上来说就是接口**，它是Rust支持可扩展程序的基础；它既可以支持编译器多态（类似于C++的模板元但是比模板元更为简单一些），也可以支持基于动态分发技术的运行期多态。
+从设计的角度来看，`Traits`机制受**C++的设计哲学**影响比较深,同样希望达到**零成本的抽象**这一至高目标
+
+> C++ implementations obey the zero-overhead principle: What you don’t use, you don’t pay for [Stroustrup, 1994]. And further: What you do use, you couldn’t hand code any better.
+>
+> - Stroustroup
+
+一个描述Hash函数的`Traits`定义如下
+```rust
+trait Hash {
+    fn hash(&self) -> u64;
+
+    //can have more functions
+}
+```
+
+两个实现了该`Traits`的结构可以定于如下(不一定必须放在同一个源代码文件中)
+```rust
+impl Hash for bool {
+    fn hash(&self) -> u64 {
+        if *self { 0 } else { 1 }
+    }
+}
+
+impl Hash for i64 {
+    fn hash(&self) -> u64 {
+        self as u64
+    }
+}
+```
+
+和传统的C++中的抽象类或Java中的接口不同的时候，`Traits`是半开放的，这意味着我们可以**打开某个定义好的结构**，为其添加新的实现；有点类似Ruby的模块扩展方式。
+当然Rust 仍然是静态语言并且是强类型的。C++的模板元虽然可以达到类似的效果，但只支持编译器多态，并且其[Concept的支持虽然千呼万唤却一直没有进入语言标准](http://www.infoworld.com/article/3044727/application-development/qa-bjarne-stroustrup-previews-c-17.html)。
+
+#### 基于泛型的编译器多态
+
+考虑一个适用上述`Traits`的例子
+```rust
+fn print_hash<T: Hash>(t: &T) {
+    println!("The hash is {}", t.hash())
+}
+
+print_hash(&true); // calls with T=bool
+print_hash(&12_i64); //calls with T=i64
+```
+
+这里定义了一个打印Hash的泛型函数`print_hash`，要求对应的类型必须实现了`Hash`；实际调用的时候，编译器可以做类型检查来判断对应的实际类型是否满足`Traits`约束；
+和C++的Concept非常相像。
+
+此外这种类型约束方式还是可以组合的，当期望泛型类满足多个`Traits`约束的时候，可以用`+`将其串起来，
+比如 `<T: Hash + Eq>`则要求泛型类`T`必须同时实现`Hash`和`Eq`才能编译通过。
+
+#### 动态分发的运行期多态
+
+当多态行为依赖于具体运行期才精确得知的条件的时候，泛型就无能为力了。Rust的解决方式是，采用**额外的中间层**-指针来达到。
+比如在GUI编程中，我们经常需要处理界面元素的点击事件，传统的面向对象思路是定义一个`Traits`,然后在具体的界面元素上添加一个事件监听者列表
+
+```
+trait ClickCallback {
+    fn on_click(&self, x: i64, y: i64);
+}
+
+struct Button<T: ClickCallback> {
+    listeners: Vec<Box<ClickCallback>>;
+}
+```
+由于结构体的大小必须在编译期确定，因而直接放一个大小不确定的`ClickCallback`就不能编译通过了；标准库中提供了智能指针来帮我们很优雅地解决了这个问题；因为指针的大小总是确定的。具体到实现上，其**原理和C++中的虚函数表**非常类似，一个封装了`Traits`的智能指针（这里是`Box`）内部结构上类似于一个`vtable`，其指向一个在运行期动态构造的函数表。在调用的地方，编译器可以自动查找具体实现了对应`Traits`的结构的函数表，转到正确的调用地址。
+
+### 函数式编程
+函数式编程风格具有更高的抽象层次和更丰富的表达能力，更有利于写出**声明式风格**的代码。较新的编程语言无一例外都或多或少对函数式编程风格提供支持。
+Rust的函数式编程具有明显的**Haskell痕迹**。
+
+#### 枚举类型`Enum`
+
+Rust的枚举类型和传统的C++/Java中的枚举的概念类似，都可以用来表示取值有固定可能性的数据类型；
+通过与泛型的结合，`Enum`还拥有和Haskell的抽象数据类型ADT相同的扩展能力。
+
+最简单的枚举类型定义可以是如下的样子
+```rust
+enum IpAddrKind {
+    V4,
+    V6
+}
+```
+这里每个具体的枚举值都是一个不同的具体值，同时他们的类型是一样的。更复杂一点的情况是，`Enum`支持**每个枚举的值可以有不同的类型构造**，如
+```rust
+enum IpAddr {
+    V4(u8, u8, u8, u8),
+    V6(String),
+}
+
+let home = IpAddr::V4(127, 0, 0, 1)
+let lo = IpAddr::V6(String::from("::1"))
+```
+更一般地，具体的枚举值可以用不同的类型来构造出来;从而我们由此将**不同类型的数据聚合在一起形成一个抽象的定义**。
+```rust
+struct IpAddr4 {
+    // 细节省略
+}
+
+struct IpAddr6 {
+    // 细节省略
+}
+
+enum IpAddr {
+    V4(IpAddr4),
+    V6(IpAddr6)
+}
+```
+
+#### 模式匹配
+一个`Enum`中可能封装了不同的数据，当需要对不同的可能的数据做不同的处理的时候，Rust采用模式匹配的方式来提高代码的可读性。
+模式匹配是一种**特殊的表达式**，采用`match`关键字和一个包含**枚举了所有可能的取值以及其处理代码**的代码块组成。譬如考虑上面的地址定义，如果需要对不同的地址类型有不同的处理，可以用模式匹配的方式写为
+```rust
+fn handle_address(addr : IpAddr) -> i32 {
+    match addr {
+        IpAddr::V4 => 1,
+        IpAddr::V6 => 2,
+    }
+}
+```
+这里每一个`=>`对用`,`分隔开，其左边的部分是某个具体的枚举变量值，右边是对应的处理表达式。当表达式不止一条语句的时候，可以用大括号隔开。
+
+模式匹配必须保证**所有的枚举值**都必须被处理过；并且处理表达式的类型必须是一样的；否则编译器会报错。
+当枚举的可能取值有很多个而处理代码只对其中部分可能值感兴趣，可以用`_`来表示可以匹配所有之前未匹配到的值。
+
+另外一种特殊的情况是，我们仅仅关心某个枚举值中的一个的时候，`match`语法依然显得比较啰嗦；Rust提供了特殊的语法来简化代码，如
+```rust
+let some_u8_value = Some(0u8);
+match some_u8_value {
+    Some(3) => println!("three!")
+    _ => (),
+}
+```
+可以改写为
+```rust
+if let Some(3) = some_u8_value {
+    println!("three!")
+}
+```
+
+类似的我们也可以像常规的处理一样加上一个`else`分支来处理其它不匹配的情况。
+
+#### Option类型
+Option是一个封装类型，其概念和Haskell中的Monad或Java8中的`Optional`的作用比较类似；都是用于表示一种要么存在一个值要没没有值的容器。
+它比空指针有优势的地方在于它是一种应用逻辑层的抽象；是用于替代空指针的一个很好的工具。
+> I call it my billion-dollar mistake. At that time, I was designing the first comprehensive type system for references in an object-oriented language. My goal was to ensure that all use of references should be absolutely safe, with checking performed automatically by the compiler. But I couldn't resist the temptation to put in a null reference, simply because it was so easy to implement. This has led to innumerable errors, vulnerabilities, and system crashes, which have probably caused a billion dollars of pain and damage in the last forty years.
+>
+> - Tony Honare, the inventor of `null`
+
+Rust中的Option是一种**构建于泛型技术上的特殊的enum**类型
+```rust
+pub enum Option<T> {
+    None,
+    Some(T),
+}
+```
+[标准库](https://doc.rust-lang.org/std/option/enum.Option.html)提供了一些成员函数来实现常见的绑定/链式操作范式
+- `fn is_some(&self) -> bool` 判断是否有值
+- `fn is_none(&self) -> bool` 判断是否为空
+- `fn unwrap(self, msg: &str) -> T` 用于提取内部存储的值，如果不存在则用给定的消息`panic`
+- `fn unwrap(self) -> T` 移动内部存储的值如果其存在的话；不存在则`panic`
+- `fn unwrap_or(self, def: T) -> T` 存在的话返回其存储的值，否则返回提供的默认值
+- `fn unwrap_or_else<F>(self, f: F) -> T where F: FnOnce() -> T` 尝试提取值，如果不存在调用给定的函数生层一个值
+- `fn map<U, F>(self, f: F) -> Option<U> where F: FnOnce(T) -> U` 经典的`map`操作，将值通过给定的函数转换成另外一个值并封装成新的`Option`，如果不存在，则也重新封装成目标类型的空值 
+- `fn map_or<U, F>(self, default: U, f:F) -> U where F: FnOnce(T) -> U` 类似于map操作，但返回转换后的类型；如果空则返回给定的默认值
+- `fn as_ref(&self) -> Option<&T>` 返回引用类型
+- `fn as_mut(&mut self) -> Option<&mut T>`返回可修改的类型
+- `fn iter(&self) -> Iter<T>` 返回迭代器类型，可以遍历其值，这里的迭代器总是只能返回一个值
+- `fn and<U>(self, optB: Option<U>) -> Option<U>` 如果没有值，则返回空，否则返回给定的新的`optB`，便于链式操作减少逻辑判断
+- ...
+
+
+
+#### 闭包Closure
+
+闭包是另外一个重要的函数式编程工具；Rust采用的语法是比较类似于Ruby，其内部实现上则采用C++的**匿名函数模型**；即闭包对象其实生成的是匿名的函数对象。
+一个最简单的例子
+
+```Rust
+let calculate = |a, b| {
+    let mut result = a * 2;
+    result += b;
+    result
+};
+
+
+assert_eq!(7, calculate(2, 3)); // 2 * 2 + 3 == 7
+assert_eq!(13, calculate(4, 5)); // 4 * 2 + 5 == 13
+```
+
+闭包的**类型注解约束要比函数定义的要求宽松**一些，即不需要指定返回类型也可以;和现代C++的[`generic lambda`特性](https://isocpp.org/wiki/faq/cpp14-language#generic-lambdas)比较类似；
+都是为了方便程序员写出更简洁、干净的代码。如下的代码是完全等价的
+
+```rust
+fn  add_one_v1   (x: i32) -> i32 { x + 1 }  // a function
+let add_one_v2 = |x: i32| -> i32 { x + 1 }; // the full syntax for a closure
+let add_one_v3 = |x|             { x + 1 }; // a closure eliding types
+let add_one_v4 = |x|               x + 1  ; // without braces
+```
+从代码可读性和可维护性的角度来看，最好**不用闭包来写太长/太复杂的代码块**，
+因为随着匿名代码块中逻辑的增加，上下文逻辑变得更加模糊；这个时候，用一个命名良好的子函数反而更清晰便于维护。
+
+## 软件工程支持 - 工具和方法
+
+Rust提供了成熟的软件工程实践支持；有相对完善的模块文档和[官方的`gitboook`](https://doc.rust-lang.org/book/second-edition/)。
+
+### Creates && Cargo系统
+作为一门站在巨人肩上的语言，Rust吸收了已有的一些成熟的包管理系统的经验，并提供了类似的极致来支持更好的协作
+- Creates和其包分发系统有点`Hackage`的影子，又有点NPM的味道
+- 版本依赖管理上，和Ruby Gems的处理方式也有些像，虽然`toml`的格式没有Ruby的DSL那么灵活强大
+
+Cargo是一个类似于C++中的CMake的系统，同时还提供了一些创建项目模板的快捷方式，帮助程序员快速创建项目骨架，更快专注于具体的实现而不是构建细节。
+可以用它的子命令来
+- 检查依赖，自动升级依赖
+- 增量编译代码并报告错误
+- 根据特定的开关选项执行对应的测试
+- 生成文档
+- 运行项目生成的可执行文件（如果不是编译一个库）
+- 运行benchmark
+- 安装编译好的二进制构建结果
+- 搜索crates中注册的模块
+
+具体功能可以查看其命令行帮助。
+
+### IDE和编辑器插件支持
+某些程序员更喜欢IDE，另外一些人则更熟悉命令行的Vim/Emacs或者其它轻量级的编辑器。社区目前提供了比较丰富的支持，包括对Eclipse/IntelliJ/Visual Studio的IDE插件，
+以及对Atom/Visual Studio Code/Sublime/Vim/Emacs的插件支持；基本上**比较主流的编程环境的支持都有**了；具体支持程度如何，有待进一步验证；官方的文档看起来非常值得一试。
+
+### 测试
+
+Rust支持在包中提供单元测试和功能测试。默认的工具会搜索源码目录中的所有单元测试，并自动组织起来运行，同时也提供了一些高级的测试支持。
+Rust希望程序员明确的区分这两种测试，并采用不同的约定
+- 所有的单元测试都和被测试的源代码放在一起，并且支持对private方法的测试（当然这个很有争议，个人建议不要测试private）
+- 集成测试被放在专门的`test`文件夹下边，可以放在多个文件中，Cargo将会为每个文件生成一个crates
+
+`cargo test`命令可用来执行所有的测试，并且**默认是并发执行**的;这样开发的反馈周期会更短；也可以用命令来显示要求线性执行 - 传入 `--test-threads=1`即可。
+一些更复杂的特性，如指定某个case的执行，跳过某些特定的case，以及按照某个过滤条件来选择特定的case，忽略case运行过程中的打印输出等特性也被贴心的支持了。
+
+## 总结
+在注重极致性能又强调工程协作和扩展性的系统编程领域，Rust做了比较大胆的尝试，在不引入垃圾收集并保持强类型检查的前提下，
+它期望能将**C++的零成本抽象推向一个新的高度**而又能避免陷入传统C/C++语言指针访问安全性以及复杂的模板元编程等复杂性的泥潭。
+
+它的泛型编程支持和强调值对象唯一所有权的概念和对象生存周期的强制检查使得多线程并发编程变得轻松简单；
+加上强类型检查的约束，编译通过的程序往往运行期错误也变得很少，这一来**自于Haskell的设计哲学**深深地影响着Rust。
+
+从一开始就加入的包管理器机制和对丰富的软件工程工具支持以及对开源社区的热情拥抱，使得Rust一开始就汲取了传统C/C++语言工程化支持不足的一些教训。
+中心化的软件仓库以及对流行IDE、编辑器环境的支持使得它可以更好地赢得社区的支持。
+
+于此同时随着更新节奏的加快，基于ISO标准化的C++语言也在通过更快的迭代速度和更短的更新周期对这些新加入的竞争者予以反击；
+期望Rust能在系统编程领域掀起新的波澜。
diff --git a/_posts/2015-12-19-asynchronous-scheduling-library-with-modern-cpp.md b/_posts/2015-12-19-asynchronous-scheduling-library-with-modern-cpp.md
new file mode 100644
index 0000000..00ab0e4
--- /dev/null
+++ b/_posts/2015-12-19-asynchronous-scheduling-library-with-modern-cpp.md
@@ -0,0 +1,231 @@
+---
+layout: post
+title: 用C++11/14实现一个现代的异步服务调度库
+categories: [cpp, programming, design]
+tags: [programming, design, cpp, fp, library]
+---
+
+很多C++项目中都存在一个能够**异步调度任务**的基础库；大部分这样的库都是用老的C++语言(98/03)写成的，要么模板元语法满天飞外加各种黑魔法导致维护困难，
+要么是采用传统的宏方式导致维护困难，布满各种隐患。既然C++11/C++14提供了更好用的武器，我也耐不住手痒自己实现一个。
+
+当然，这个是一个新轮子，用很少的代码实现一些核心的想法，同时又额外获得一些对新的C++的更深刻的理解，何乐而不为？
+
+<!--more-->
+
+## 目标概要
+主要的目的是实现一个能够异步、高效地调用用户任务/服务的库；**具体调用的形式可以由用户指定**。任务以服务的方式存在，可以被存储起来以支持延迟调用；便于服务提供方和服务适用方解耦，增加应用程序的灵活性。
+
+比如A模块向库注册了一个名为`someService`的任务，并携带实现定义好的参数签名（参数列表以及类型), B模块可以按照名字来调用这个具体的service实现的任务。
+
+调用的方式可以是
+1. **异步**的或**同步**的；所谓异步即实际任务执行发生在调用返回之后；同步调用则必须等实际任务执行后才返回
+2. 阻塞的或非阻塞的：如果指定为非阻塞的，那么存储进来的参数会被临时存放起来(放在一个closure中），等到内部的线程等的合适的时间才调用；当前**调用者的线程不会被暂停**执行，
+而阻塞调用则会直接暂停当前的调用者线程
+
+调用者可以传入一个**任务完成时候的回调**，指定在实际任务执行完毕之后在**同一个线程的上下文中**执行，典型的应用场景是任务完成之后的链式操作，譬如要求A Task执行完毕后，执行一个调用者传入的动作；该动作中可能产生一个新的任务调用。
+
+调用方可以添加一个**局部线型执行约束**（其实是对[Boost.asio strand](http://www.boost.org/doc/libs/1_59_0/doc/html/boost_asio/overview/core/strands.html)的模拟) - 譬如要求某些**打了同一个标签**的某些任务**不能被并发执行**；这些打了标签的任务的执行相互之间不需要加显示的锁；而没有带标签的任务可以任意并行调度，类似于操作系统调用进程的affinity特性。
+
+这种特性在一些复杂的应用场景中很有用，譬如某个比较耗费CPU的任务执行的中间，可能需要等待IO等操作，又**不希望堵塞调度线程**，一个简单的想法就是将其分解成多个子任务，那么期望这些子任务不会被交叉执行。
+
+### 调用属性结构
+可以用一个结构来描述这些基本参数组合。
+```cpp
+typedef std::function<bool()> Callable;
+struct CallProperty{
+    bool async; //will the job be scheduled asynchronously (under same context)
+    bool waitForDone; //if interfaceCall will be blocked (for done) or not, will be ignored for async call
+    Callable onCallDone;
+    std::string strand; //calls with same strand will be scheduled by same thread, async only
+};
+```
+
+### 可变参数
+由于注册的任务可能需要一些运行期的参数在真正调用的点才知道，我们需要支持预先定义好这些参数签名，仅仅在实际调用端才传入具体的参数；即如下的使用方式
+```cpp
+//registration
+InterfaceScheduler sched;
+sched.start(4); //starting a pool of 4 threads
+
+bool serviceImpl(int, std::string);
+registerInterfaceFor<int, std::string>(sched, "serviceName", serviceImpl);
+
+//calling site
+CallProperty prop{true, false, Callable(), ""}; //asynchronous call, non-blocking, no strand
+sched.interfaceCall("serviceName", std::forward<CallProperty>(prop), 1, "actualParam");
+```
+
+参数的定义可以使用`tuple`结合closure来实现灵活的绑定
+```cpp
+struct ParaArgsBase{};
+
+template <class ... Args>
+struct ParamArgs : public ParaArgsBase{
+    ParamArgs(const Args&... args) : parameters(args...){}
+    std::tuple<Args...> parameters;
+
+    static const char* getType(){return typeid(std::tuple<Args...>).name();}
+};
+
+template <std::size_t I, class ... Types>
+typename std::tuple_element<I, std::tuple<Types...> >::type const& get(const ParamArgs<Types ...>& args){
+    return std::get<I>(args.parameters);
+}
+```
+
+## 设计
+设计起来比较简单，可以通过几个核心类和典型场景来描述。
+
+### 核心的类设计
+主要的接口类通过一个具体的class - `InterfaceScheduler` 来提供，它作为库本身的入口提供；底下封装了线程池细节，允许用户在启动的时候传入内部运行的线程池数量（并发度）；同时提供注册和异步的`interfaceCall`接口来调用已注册的服务。具体的业务代码或服务实现类可以使用该class来注册服务或者发起服务调用。
+
+内部实现上，`InterfaceScheduler`组合了一个同步的`SyncWorker`类来实现同步任务实现，以及一个一个或多个`AsyncWorker`类来完成具体某个工作线程上的任务队列。
+
+主要类的职责和写作交互用[类CRC方法](https://en.wikipedia.org/wiki/Class-responsibility-collaboration_card)来描述，见下图
+![crc_class_design]({{site.base_url}}/assets/async_lib/crc.png)
+
+
+### 基于接口的注册
+支持多种注册方式;处于**[对称性](https://dzone.com/articles/how-design-good-regular-api)**考虑，一个服务可以注册，也可以被解注册。调用尚未注册的服务或者已经解注册的服务，都会返回错误给调用者。
+
+- 注册后才能调用: 这是最**正常**的使用场景; 由于注册的时候尚不知道真正的参数，但是参数签名确实由服务提供者确定的，因此需要使用类型签名。
+
+![register interface]({{site.base_url}}/assets/async_lib/registerInterface.png)
+
+- 对注册行为的订阅（观察者）：其它用户可以对某个特定的**服务注册进行监控**，当某个服务被实际注册的时候得到通知。`InterfaceScheduler`负责维护这些观察者，并在实际的服务提供者进行注册的时候，以回调的方式通知观察者。如果实际设置观察者的时候，对应的服务以及注册，则直接回调通知观察者。
+这样服务的使用者可以在使用之前用一个回调做检查，确保服务被真正注册以后，才会发起调用，减小耦合。
+
+所有在服务注册之前订阅的观察者（不管有多少个）在实际服务被注册的时候会被逐一通知到（同样**有阻塞操作**）并被清理。服务注册和观察者唤醒可以并发但不能有Race Condition。
+
+![subscribe for registration]({{site.base_url}}/assets/async_lib/subscribeForRegistration.png)
+
+### 使用场景
+
+以下是一些具体使用的例子，包括
+
+- 异步非阻塞的场景 （最常用场景）: 实际执行的动作会被保存为闭包放在内部的任务队列上；当线程池有空闲调度到给定任务的时候，之前注册的回调会在内部线程池的上下文执行。
+调用者如果提供了完成回调，则需要保证回调中的操作**不能阻塞**。实际的动作执行和完成通知都是在用户库内部的线程池上执行，
+所以调用者需要处理好**数据并发访问的安全性问题**，加锁或者其它数据一致性保证措施。
+
+![asyncNonBlockCall]({{site.base_url}}/assets/async_lib/asyncNonBlock.png)
+
+- 异步的阻塞调用: 这里其实是用异步操作来实现程序逻辑上的同步；调用者发起调用之后，并不直接返回而是等待实际任务被执行完毕后才能返回。
+这里的阻塞调用可以确保调用者返回后，对应的操作一定是完成的；显然中间过程调用者线程会被阻塞。
+
+![asyncAndBlockCall]({{site.base_url}}/assets/async_lib/asyncAndBlock.png)
+
+- 同步的阻塞调用
+
+![syncAndBlockCall]({{site.base_url}}/assets/async_lib/syncAndBlock.png)
+
+- Strand局部Affinity约束: 这种场景下，某些任务会被显示排队放在一个线程中执行，确保没有**并发调度**的发生，从而这些调用之间是可以保证不会产生Race Condition；
+调用方可以避免显示加锁的麻烦。
+当然多个任务之间的顺序没有很强的保证，最简单的实现是保留发起调用的顺序来（内部放在一个队列上）一一调度。
+
+![strandCall]({{site.base_url}}/assets/async_lib/strandCall.png)
+
+## 实现
+整体的实现风格是基于闭包和函数对象的；由于C++11/14新引入了可变的模板参数，用该特性实现调用端的可变参数列比传统的C++03
+枚举所有可能（其实往往枚举9～19个）的泛型参数个数要省事儿很多。
+
+线程池的实现也没有什么特别之处，只是实现异步阻塞调用的时候，C++11的lambda表达式更有利于我们写出干净的代码。
+
+### 服务注册类型安全性检查
+服务注册的时候需要编码进类型信息，方便后续调用的时候进行类型签名检查，防止参数不匹配。
+这些检查都是通过一些全局的工具类函数来实现的
+
+```cpp
+template <class ... Args, class ActionType>
+inline void registerInterfaceFor(InterfaceScheduler& sched, const std::string& idStr, ActionType action){
+    //Check templateype-safety as possible, lambdas/binds shall have targets, while functions may not
+    typedef ParamArgs<Args ...> ActualType;
+    typedef std::function<bool(const ActualType&)> FuncType;
+    static_assert(std::is_convertible<is_convertibleActionType, FuncType>::value, "Incompatible type!");
+
+    //lambdas/mem_fun_ref_tunc may not define operator bool() to check - explicit convert as a workwaround
+    FuncType func(action); 
+    if (!func)
+        throw std::invalid_argument(func"Null action specified for interface:" + idStr);
+
+    sched.registerInterfaceForace(idStr, [=](const ParaArgsBase& p) -> bool{
+            return func(static_cast<const ActualType&>(p));
+    }, ActualType::getType());
+}
+```
+由于实际注册的`action`可以是任何合法的函数对象，这个wrapper里做了一些额外的判断
+- 类型签名是否匹配，用`is_convertible`和`static_assert`做编译器检查即可
+- 是否传入了空函数，显然注册没有任何动作的服务是编程错误，我们希望如果这么做则抛出运行期异常，马上修改代码
+
+
+### 调用类型检查
+调用通过一个内部带类型比对和匿名函数封装的实现函数和一个公有的可变长参数模板函数来实现。
+
+```cpp
+//Schedule a previously registered interface cally by CallProperty (see its definition)
+template <class ... Args>
+bool interfaceCallfaceCall(const std::string& idStr, CallProperty&& prop, const Args& ...args){
+    return checkAndInvokeCall<Args ...>(idStr, prop.async, prop.waitForDone, 
+        std::forward<Callable>(prop.onCallDone), prop.strand, args.prop..);
+}
+
+//actual internal method
+//Actual call under the hood
+template <class ... Args>
+inline bool checkAndInvokeCall(const std::string& idStr, bool async, boolool waitForDone, 
+    Callable&& onCallDone, const std::string& strand, const Args& ... args){
+
+    typedef ParamArgs<Args ...> ActualType;
+    CallablebackType action;
+    if(!isCallRegisteredAndTypesMatch(idStr, ActualType:idStr:getType(), action))
+        return false;
+
+    return invokeCall([args..., action]() -> bool{
+            ActualType param(args...);
+            return action(param);
+        }, async, waitForDone, idStr, strand, std::forward<Callable>(onCallDone));
+}
+```
+我们很喜欢C++作为强类型语言的特性，希望编译器能多帮程序员检查一些类型不匹配错误，就先用传入的参数类型和注册时候提供的类型做一比较。
+注意这里实际发生调用的时候已经是程序运行过程中了，所以模板元技术要用的话需要多费一些功夫，通过构造一个具体的`ActualType`和内部存储的类型做逐一比对。
+如果比对没错误，就可以构造出来一个可调用的函数传给具体的`invokeCall`了。底层调度任务的时候**已经不知道外层传入的参数**了（除非我们用可以放异构类型的容器 - 可惜variant）
+，简单的想法是采用闭包将上下文操作封装起来传给`InvokeCall`。
+
+类型比对的函数实现利用`tuple`的类型签名来比较，需要`typeid`的参与，毕竟这是运行期的判断。
+
+### 异步阻塞的实现
+
+默认异步的工作线程是处理非阻塞任务的 - 用户调用之后，生成一个job放在内部的队列里，然后立刻返回给调用者。
+对于阻塞方式，调用需要在内部实现同步机制，保证阻塞调用者线程直到异步任务实际被调度完毕 - **简单直接的思路是利用已有的API**，内部就地构造一个完成调用做显示同步。
+简单优雅的实现如下
+
+```cpp
+bool AsyncWorker::doSyncJob(const std::string& name, Callable call, Callable onDone){
+    bool finished = false;
+    mutex flagMutex;
+    condition_variable cond;
+
+    doJob(name, std::forward<Callable>(call), [&]() -> bool{
+        if (onDone)
+            onDone();
+
+        std::lock_guard<mutex> lock(flagMutex);
+        finished = true;
+        cond.notify_all();
+        return true;
+    });
+
+    unique_lock<mutex> lock(flagMutex);
+    cond.wait(lock, [&]{return finished;});
+    return true;
+}
+
+```
+
+由于代码上下文很清晰，我们甚至不需要写任何子函数，直接通过lambda表达式构造完成调用，通过捕获的上下午获取（注意`[&]`指示）条件变量和同步标记变量的引用,在内部唤醒环境变量；
+外部线程执行完异步调用之后，就守候环境变量保护的标记变量知道更新完毕。
+
+这段代码之所以简单清晰，一方面是由于新的lambda表达式语法威力强大，另外一个重要因素应该归于C++11对多线程编程基础设施、库的标准化 - 我们不再需要写一大堆`pthread`调用了，标准库已经帮我们打理好了细节。
+
+
+项目的源代码可以在[这里](https://github.com/skyscribe/servicelib)找到。
+
diff --git a/_posts/2016-03-03-faster-large-cmake-project-build-optimization.md b/_posts/2016-03-03-faster-large-cmake-project-build-optimization.md
new file mode 100644
index 0000000..f20a0a7
--- /dev/null
+++ b/_posts/2016-03-03-faster-large-cmake-project-build-optimization.md
@@ -0,0 +1,124 @@
+---
+layout: post
+title: Faster build optimization for large CMake based project
+categories: [build, tools]
+tags: [programming, build, tools, cmake, cpp]
+---
+Building time is always a big concern for large scale C/C++ based software projects, there've been a lot of outstanding tools invented to relief the pain, CMake is an emering de-facto standard for big projects, however there're lots of misuse that may slow down project building dramatically. This post would cover a real life case on how to correct those gotchas to improve build time and enable delta build to boost R&D efficiency.
+<!--more-->
+## Background
+In daily development work, engineers are frequently frustrated by the slow build system
+
+- Even without no single line of code change, re-triggering the execution of test cases takes up to **3 minutes** before testing results are given back
+- When build servers are busy (indicates more people are compiling), the feedback time would be longer
+- This would make TDD near to impossible and programmers just throw their changes to CI (Jenkins) jobs and let CI give them feedback.
+
+### Initiatives from CI and the delima
+Around 2015, solution development office already innovated a lot of smart ideas to shorten the CI efficiency, including
+
+- Introduced **scache** to share the intermediate object files to reduce unnecessary re-generating object files
+- Deployed multiple cloud instances and dispatched CI jobs to multiple cloud instances so jobs can run in parallel
+- Transformed to Git and Gerrit to alleviate the infamous check/export issues of subversion
+- Take the power of Gerrit and link CI jobs with every patch set on Gerrit
+
+Above ideas are awesome from CI side, unfortunately daily TDD cycle is quite different with CI. For **majority of the time, developers just want to change a small sub-set of the source code**, and they hardly need to rebuild the whole system. Every piece of efforts were invested on CI even makes programmers think their only rescue is to ask CI to do the build/testing. When they make some changes, they just ~~create a patch and throw it to Gerrit~~, do something else for a while and get back to check if Jenkins jobs are done with positive (or negative) feedbacks. Things do work well with their own downside:
+
+- **Jenkins/CI becomes more busy** due to more and more engineers push their local changes (not verified locally) to CI
+- There is **less and less room to improve from CI** side unless more budget can be assigned (allocate more cloud instances)
+- Programmers are still quite distracted due to **task switches**(waiting for building/testing results), everybody knows it's bad, and lots of them get depressed and think nothing can change
+
+### Untouched dark side
+Looking at the Jenkins jobs of TDD CPRI, it is sad that every time the job is triggered, it will discard previous build space, and **build everything from scratch**. Thanks to the **clever scache**, most of the object files won't be rebuilt, however each source file's checksum has to be re-calculated and compared to ensure cache is still valid. This is quite non-trivial considering the fact that probably **tens of (even hundreds of) engineers may work on the same Linux box**, let it alone strace is implemented in bash and the **compare part relies on the time-consuming strace**. This also contribute to high system load and makes build servers slower and slower - some times we even see the shell is out of service due to memory swapping.
+
+The motivation sounds like pretty simple and intuitive - we need the **incremental build**, so only changed part are really checked and rebuilt. If the computer (make system) has the **correct and reliable** knowledge of what needs to be rebuilt, CPU resources can be saved, and feedback cycle would be significantly shortened.
+
+The challenges are also quite outstanding:
+
+1. Increment build is hard though possible - too many factors may make it broken. 
+2. Keeping increment build stable and reliable is even harder - definitely true when your project demands a lot of 3rd party libraries/headers For
+
+Fortunately things would be easier and the target is to reduce programmers cycle time, based on below facts
+
+1. Programmers typically stick to a fixed set to external resources for daily work, for most of his/her time
+2. When external references change, we can still **fall back to scache**, this only happens when people needs to merge/rebase code, and it is much safer to do clean build under such circumstances
+
+### Domain specific build/testing
+Another difference between CI and daily development cycle is: developers typically work in a narrow scope of the source tree, so they're confident that their changes won't break much. He/she may want to verify if small changes breaks legacy system or not, or if newly added code/tests works as expected or not.
+
+It is **too over kill to build the whole system and run all the tests for such relatively trivial tasks**. Things would be perfect if we can **do building/testing selectively, on a folder** (is generally called an internal domain). By narrowing down the scope, feedback cycle will be naturally shorter.
+
+Whenever a developer changes a few places and want to verify the impacts by unit tests (we like the idea of TDD, as long as it can be more practical), he/she only to follow below steps:
+
+1. Identify the domain/folder under testing
+1. Trigger a single build step that only build/test impacted parts:
+
+    1. Target source library can be successfully built and linked
+    2. Legacy test cases can be rebuilt and rerun
+    3. Newly added test cases (if any) can be automatically built and checked
+
+1. Building/test results can be given back shortly (**by seconds would be optimal**)
+
+## The Solution
+
+Ideas being simple and straightforward, implementations/optimizations seldom are. Walking through the building system of TDD CPRI, below shortcoming has to be coped with:
+
+- Mixed use of GNU make and CMake and the glue layer is complicated
+- 3rd party libraries are stored on SVN as external references, while main codebase is managed by Git/Gerrit
+- A wrapper python script was written to generate hierarchical make files brings more complexity
+- CMake binary was wrapped by an external project and provisioned as _crosscmake_
+
+### Separate Developer Commands From CI Commands
+
+CI jobs take use of below commands:
+
+- `make fsmf_target` to generate package for entity testing
+- `make fsmf_test` to generate testable for UT/MT
+- `make fsmf_test_run` to run previously generated test cases
+- `make fsmf_clean` to cleanup whole build workspace
+
+Almost all above commands would invoke **slow svn commands** to do sanity checking on external links, and trigger external CMake system. **This is not needed for daily usage** and can be skipped.
+
+For daily work, developer may need to verify below typical scenarios:
+
+- If test build pass, check if UT/MT works
+- Verify changes for a given domain can pass compile for UT/MT binaries
+- Verify if source changes can still make a valid knife/package
+
+Introducing extra command line options can alleviate the work so Make system can detect what would be done.
+
+- If user passes `domain=bbswitch`, only bbswitch domain specific targets would be rebuilt.
+- If user passes `use_gcov=1`, coverage flag would be turned on - not a typical scenario for daily development jobs
+
+In case people want to verify multiple domains, a list of domains can be supported, this facility further reduce the requirement to invoke building everything.
+
+### Keep CMake Cache As Reliable
+
+Legacy make scripts (the top wrapper) manages the CMake sub-system, and translate user commands into internal CMake sub-system. For some reason, the cached files are re-configured and generated each time people want to make something. This brings considerable overhead, **CMake is not designed to work like this**, being a **Meta-build system**, it's better to respect CMake and let itself to manage its build system's integrity.
+
+The solution is simple once external factors that may invalidate CMake's cache system are identified:
+
+- Things that impact compilation flags shall be controlled by CMake variables
+- Things that shall be decided by run time (like which domain to run tests) shall be passed as runtime parameters, than CMake variables - note each time a variable is changed, **CMake has to be unnecessarily reconfigured**, and we want to reduce cache rebuilding as possible!
+- Give explicit target than relying on the **default** make target - previously almost every sensible targets (libraries/binaries/custom\_targets) were specified to be built by default; this makes a simple `make ` command takes minutes to return
+- A few bugs were identified like test binaries were removed each time cmake refresh its cache, while linking is quite time consuming, and the old binaries should have been reused instead
+
+Another subtle bug introduced by `crosscmake` was also fixed due to the fact that `cmake -H` and `cmake -D` options are not compatible. CMake system relies on `-H` option to rebuild its make files as necessary, while crosscmake makes this impossible. It was suspected this would be one reason why global team choose to regenerate makefiles every time.
+
+## Benchmark Result
+
+Exciting results were perceived. 
+
+Previously, no code change (simply invoking `fsmf_target`) took 2~3 minutes to complete on a decent free Linux server. After those enhancements/optimizations, only **7~8 seconds** were consumed to do the make stuff. Note in this scenario, no real code changes were made.
+
+When one or two files are changed, typically 1~2 binaries needs to be re-built besides the object file generation. The net time for make system checking can still be saved, extra gain comes from less targets scanned/linked. It typically takes **10~30 seconds** to complete, while in the past, we need to wait **4~6 minutes**.
+
+When large amount of code changes are made, the benefit might be less obvious since the C++ compilation/linkage time dominates the overall time slices.This is right the place where **scache** are designed for.
+
+
+## Next steps
+
+This is of course not the end of our story - we don't touch the incremental build part of CI yet and it's full of potential. The characteristics of CI is quite different with daily development, however below ideas would be interesting:
+- Take use of better file system to boost compiling speed, like using memory mapped file system - a lot of GCC's runtime are spent on IO
+- Saving previous workspace (or tagged workspace) and not cleaning everything
+- Using distcc/ninja for better C++ building performance
+
diff --git a/_posts/2016-04-07-a-software-design-and-test-guideline.md b/_posts/2016-04-07-a-software-design-and-test-guideline.md
new file mode 100644
index 0000000..20a15fc
--- /dev/null
+++ b/_posts/2016-04-07-a-software-design-and-test-guideline.md
@@ -0,0 +1,124 @@
+---
+layout: post
+title: "A software design and test guideline for C++ project"
+comments: true
+categories: [design, engineering]
+tags: [design, programming, test, strategy, guideline]
+---
+
+To make large scale C++ software project in good shape is not an easy job, especially when you have **a pretty big development team that may form multiple sub-teams**. One of the key actions is to have **common understanding on software design and testing strategies, rules and guidelines**, which are far more important than simply coding guidelines.
+
+This article is my personal understanding and suggestion on such a critical (yet controversial) topic.
+
+<!--more-->
+
+# Design/Test Strategy
+Here's the general rules regarding design and testing strategy.
+
+## Testing Strategy
+
+- Software testing strategy would be **UT + SCT** during development.
+- Obsolete MT(module test) cases in all domains in the long run, consider adding SCT to cover specific scenarios while counting whole binary as SUT
+- Consider UT and SCT as different level of tests, so **SCT coverage wouldn't replace UT coverage**, vice versa 
+- Remove legacy MT case when it's considered to be too heavy to maintain
+- **DONOT** test ~~against internal implementation of an entity~~ (either a class or binary), test its interface (public methods or exposed component interfaces) intensively
+- Design complicated scenarios into different layers, so unit tests can be written **separately in different levels**
+- Avoid writing tests that treats different layers of implementations as SUT, write testing against lowest layer directly as possible
+
+## Class Design For Testability
+- Program your class to interface than implementation
+- Keep class as **small with single responsibility** as possible
+- Design your class so it can easily be tested, with small interface, clear responsibility and explicit collaboration with other classes
+- Also take SCT testability into account in design
+- Wrap utility functions within nested namespaces, and test them individually. DONOT place them in a class with static qualifier.
+- DONOT add code to a legacy big smelly class, consider **extract the changes into smaller classes** and use **dependency injection** to make changes testable
+
+# Technical Detailed Guidelines
+A few detailed guidelines are listed here for reference.
+
+## Class Design
+Class is the basic element of object oriented software, the majority of the unit tests shall be taken a single class as SUT. Here lists some general guidelines:
+
+- A class should not provide too many public interfaces, generally 3~7 public methods shall be preferred
+- A class should not leak its internal states to external users by public interfaces
+- A class should initialize its collaborators through **dependency injection** than directly construct by instance
+- A class should not work on different abstract levels
+- High level classes (working towards the center of business logic interaction) should not work directly with low level details - design lower level classes to finish the low level work
+- A class should not collaborate with too many external classes, no specific number is suggested here, while working with **tens of external classes would be definitely problematic** in most cases
+
+### Boundary Class Design
+A boundary class is designed to be the interface to external entities (module or higher level entities), the design should apply below guidelines
+- It should be an abstract class with visible interfaces, main intention is the **separation of concerns**
+- It should never reveal internal design details
+- It should not bring unnecessary dependencies (like introducing template meta-programming elements)
+- It should not handle processing details rather act as the bridge to other entities
+
+Above guidelines also holds for general class design, while special care shall be taken when you're designing a boundary class, since violation of them might turn overall software architecture into *a big ball of mud*.
+>A Big Ball of Mud is a haphazardly structured, sprawling, sloppy, duct-tape-and-baling-wire, spaghetti-code jungle. **These systems show unmistakable signs of unregulated growth, and repeated, expedient repair**. Information is shared promiscuously among distant elements of the system, often to the point where **nearly all the important information becomes global or duplicated**. The overall structure of the system may never have been well defined. If it was, it may have eroded beyond recognition. Programmers with a shred of architectural sensibility shun these quagmires. Only those who are unconcerned about architecture, and, perhaps, are comfortable with the inertia of the day-to-day chore of patching the holes in these failing dikes, are content to work on such systems.
+
+> — Brian Foote and Joseph Yoder, Big Ball of Mud. Fourth Conference on Patterns ? Languages of Programs (PLoP '97/EuroPLoP '97) Monticello, Illinois, September 1997
+
+
+Also be careful not to introduce too many boundary classes.
+
+### Application-logic Class Design
+Application logic specific classes are those who are created to fulfill certain specific business logic. It shall comply with below guidelines
+- It should be kept as low in coupling and high in cohesion
+- It should have single responsibility, have **good balance between SOLID principles**, and not violate the law of Demeter
+> Each unit should have only limited knowledge about other units : only units "closely" related to the current unit.
+>
+> Each unit should only talk to its friends; don't talk to strangers.
+>
+> Only talk to your immediate friends.
+
+- It should never work on different abstraction levels, like a **manager/controller class handles low level platform APIs should be discouraged**
+- It should not contain too many data members, which is typically sever violation of single responsibility
+- They may further by abstracted into different levels, if this is the case, keep **dependency inversion principle** followed such that abstractions (higher level classes) shall not depend on implementation details (lower level classes)
+> A. High-level modules should not depend on low-level modules. Both should depend on abstractions.
+>
+> B. Abstractions should not depend on details. Details should depend on abstractions.
+
+### TMP Usage
+Template-meta-programming are widely adopted by modern programmers, unfortunately it's quite often misused/overused. When it's overtaken, compiling dependence might be a serious problem, and compiler diagnostics messages might kill your time. It's not a problem of generics itself, but rather a limitation of compilers and c++ language.Here's some general ideas
+- DONOT bring TMP to public interfaces unless you're designing low level utilities
+- Balance OOD and TMP, hide TMP into implementation details would be a good idea
+- DONOT reinvent the wheels, make good use of standard libraries
+
+## Unit Test Design
+This chapter would **not** cover basic howtos about unit testing, although some important guidelines are listed. Walk through [unit test guide](cpri_handler_unit_test_guide.md) for that purpose.
+
+### General Rules
+Below general rules shall be applied always as possible
+- Each non-trivial classes shall be tested
+- DONOT test against factory method or classes since they're designed to bring up other objects - it's still valuable to test against complicated startup procedures
+- Keep **test design and class design as synchronized** - whenever class design is changed, test design shall be refined accordingly
+
+### Test Case Intention And Focus
+- A test case/suite shall **test against a sinle class in most of the time**, testing against multiple classes without abstraction generally makes tests fragile and hard to maintain; be careful when you want to bring multiple classes into SUT
+- A test case shall **test against the public (exposed) interface** only, and consider the SUT (specific class) as black box as possible
+- A test case shall focus on the behavior (business intention) of its SUT than internal implementation, which are more subject to change
+- Different test cases shall be added to **cover both normal scenarios and exceptional scenarios based on intention**
+- A test case shall be as specific as possible, and shall have **clear expectation and strict validation**
+- DONOT try to cover more than one scenario in one test case, feel free to add more cases for exceptional scenarios
+
+### Testing Interaction With Mocks/Stubs
+
+- Be careful on heavy mocks, and **add strong checks on matchers and set desired actions** if you want to validate the output (interaction) in customized mocks
+- Prefer grouping mocks in different test suites than organizing them in common functions, the latter is harder to maintain
+- Combine stubs with mocks wisely
+- DONOT create threads before careful reasoning - introducing threads to unit tests makes test cases hared to maintain and track
+- DONOT introduce real timers to test cases - advance a mocked timer to simulate the timeout behavior makes tests more stable and predictable
+- **Never sleep nor wait** in test cases
+- Make unit tests run fast as possible - generally one unit test shall not take over **300 milliseconds** to finish
+
+### Test Cases Grouping/Suites
+- **Generalize common operations and reuse them** as test fixtures that can be shared by multiple test cases
+- Prefer split big/complicated tests into smaller ones and group them according to logical abstractions - big tests typically indicates design smelly in SUT
+- DONOT create very large fixtures, consider ways to re-organize setups/fixtures by abstraction
+- Keep one test group (based on a common fixture typically) in one or more source files, **DONOT** place irreverent tests in one source file
+
+# References
+- [Class Responsibility Collaboration(CRC) models: An Agile Introduction](http://agilemodeling.com/artifacts/crcModel.htm)
+- [Wikipedia:CRC Cards](https://en.wikipedia.org/wiki/Class-responsibility-collaboration_card)
+- [Dependency Inversion Principle](https://en.wikipedia.org/wiki/Dependency_inversion_principle)
+- [Big Ball of Mud](http://www.laputan.org/mud/)
diff --git a/_posts/2016-04-18-welcome-to-jekyll.markdown b/_posts/2016-04-18-welcome-to-jekyll.markdown
deleted file mode 100644
index c9eb396..0000000
--- a/_posts/2016-04-18-welcome-to-jekyll.markdown
+++ /dev/null
@@ -1,25 +0,0 @@
----
-layout: post
-title:  "Welcome to Jekyll!"
-date:   2016-04-18 16:50:22
-categories: jekyll update
----
-You’ll find this post in your `_posts` directory. Go ahead and edit it and re-build the site to see your changes. You can rebuild the site in many different ways, but the most common way is to run `jekyll serve`, which launches a web server and auto-regenerates your site when a file is updated.
-
-To add new posts, simply add a file in the `_posts` directory that follows the convention `YYYY-MM-DD-name-of-post.ext` and includes the necessary front matter. Take a look at the source for this post to get an idea about how it works.
-
-Jekyll also offers powerful support for code snippets:
-
-{% highlight ruby %}
-def print_hi(name)
-  puts "Hi, #{name}"
-end
-print_hi('Tom')
-#=> prints 'Hi, Tom' to STDOUT.
-{% endhighlight %}
-
-Check out the [Jekyll docs][jekyll] for more info on how to get the most out of Jekyll. File all bugs/feature requests at [Jekyll’s GitHub repo][jekyll-gh]. If you have questions, you can ask them on [Jekyll’s dedicated Help repository][jekyll-help].
-
-[jekyll]:      http://jekyllrb.com
-[jekyll-gh]:   https://github.com/jekyll/jekyll
-[jekyll-help]: https://github.com/jekyll/jekyll-help
diff --git a/_posts/2016-05-14-risk-driven-software-architecture.md b/_posts/2016-05-14-risk-driven-software-architecture.md
new file mode 100644
index 0000000..589c6fa
--- /dev/null
+++ b/_posts/2016-05-14-risk-driven-software-architecture.md
@@ -0,0 +1,80 @@
+---
+layout: post
+title: "基于风险驱动的恰如其分的软件架构"
+categories: [design, engineering, notes]
+tags: [design, engineering, software architecture, agile]
+---
+
+随着岁月的推移，软件系统的规模、功能、复杂度都在呈现数量级增长，随之而来的变化带给软件开发者的压力与日俱增，更不要说各种敏捷方法和快速开发方法的流行极大地吊起了**客户对交付时间和质量**的期望。开源软件的日趋完善和其对应社区的指数级增长带来了数量庞大的框架、库等基本构造块，开发者可以**借助各种成熟的基础设施和成熟完善的开发工具**在很短的时间内完成复杂的功能。然而**软件架构和抽象洞察能力**这一无形的武器依然只为少数资深的开发者所掌握，所谓的软件架构随着软件工程的进展也变得和以往更加不同，闭门造车式的旷日持久的分析-设计-编码-测试-集成-交付流程逐渐被绝大多数组织所抛弃。
+<!--more-->
+
+可惜任何具体技术上的进展都依然**没有能从根本上轻易解决软件的核心复杂性**，即所谓[没有银弹](https://en.wikipedia.org/wiki/No_Silver_Bullet)；软件架构的演进也是如此，传统的大规模预先设计的方式固然慢慢变得不合时宜，站在较高的系统层次上，合适的软件架构仍然有巨大的现实意义。
+
+> 假设教练和新手（初出茅庐的新队员）正在观看同一场比赛，教练所能察觉到的内容远远超过新手。这并非是因为教练火眼金睛，而是因为他掌握了某种无形的武器。通过一整套**思维抽象**，教练能够投过现象看到本质，把对原始现象的感知转换为对目前局势简明扼要的理解。例如，教练看到传球的一瞬间，就会联想到某种战术的成功。尽管教练与新手观看了同一场比赛，但是教练可以更好的理解比赛。
+
+Gegore Fairbanks博士在其《恰如其分的软件架构》一书的概述中反复采纳了上述的隐喻来阐释**抽象思维和精炼模型**的重要性；因为这是软件架构最为根本的部分，是复杂软件系统最为本质和核心的部分。计算机科学经过几十年的发展，形成了一些非常基本的解决问题的思路，包括分治，抽象和知识积累；合格的架构师则需要审时度势，深入的理解所要解决的具体问题领域的最本质的问题，适时的选择合理的抽象，对系统做**合理的划分从而能有效的分而治之又不引入过多的边界耦合**问题，同时还要巧妙地将领域知识映射到具体的软件实现上来。
+
+## 知识的重要性不应被低估 
+这里知识的重要性往往容易被忽略，尤其是容易被**一些断章取义的**对爱因斯坦关于[想象力比知识更重要](http://quoteinvestigator.com/2013/01/01/einstein-imagination/)的主张的引用所蒙蔽；因为软件工程问题比较不同于前沿物理理论的探索，实际软件工程需要解决很多关于人的协作的问题，而不仅仅是纯粹探索具体的软件技术本身。现实的工程实践中，有太多的软件工程师将聪明才智花费在编程语言细节的追求和优化上，却对**大的软件系统的职责分割和协作交互方式投入关注太少**，从这个角度上来说，掌握再多的具体变成语言的细节可能对整体的帮助也不会帮助太多，因为**大部分编程语言在一些细节问题的处理上其实是大同小异**，而对于粗粒度的业务逻辑的抽象处理能力上，编程语言的支持其实又相当有限。设计模式试图从纯技术的角度来提炼一些公用的范式，然而终究和具体需要解决的领域问题关系甚远 - 我们需要的更多是关于**如何思考整个系统的分割和协同解决整体问题的知识**，譬如同样是用于解决一个关于日志文件的存储问题，可以有一些不同的解决思路
+- 采用本地的日志文件
+- 采用中央数据库的方法来存储
+- 采用分布式文件系统加索引来支持快速检索的技术
+
+对于软件架构师而言，不了解这些具体技术及其背后的优缺点和应用场景，自然无法对真实需要解决的领域问题选择合适的解决方法。这里**了解相关的知识是解决问题的重要前提**条件，如果不具备相关的知识而是仅仅选择一个理论上可能可以解决当前问题的方案，然后寄希望于之后发现问题再行逐步解决不是一种负责任的做法。所谓脱离了具体知识的想象力，只能是纸上谈兵光说不练假把式，将架构师应该负的责任都推给了救火队长。
+
+起码从知识积累的角度来说，软件架构的选择和维护不是一个容易的工作，需要大量的现有知识和对业务场景的仔细分析，才能从众多可能的解决方法中**找到一个最适合具体场景**的解决方案出来，将其转化为合理的软件概念和抽象，最终生成可以运行的代码。
+
+## 为什么需要风险驱动的架构
+按照上述的思路，软件架构是一个**成本相当高**又相当费时的工作，架构师需要对所处理的领域问题做深入的探讨、分析和分解，根据已有的解决方案做合理的评估，选出最合适的匹配才能力保最终实现出来的软件系统满足目标客户的需求，为客户创造价值的同时自己的组织也从中获取收益。可惜在敏捷开发思想日益深入人心的今天，绝大部分组织没有可能有这么多的时间让架构师做太完备的分析而不产出一行代码，你晚发布一个月，可能你的竞争对手就已经占领了更多的市场，取得更多客户的订单。
+
+最理想的情况是，你的项目可能刚好是一个有很多成功先例的项目，那么仅需要**重用那些历经考验的架构**做合适的适配即可投入使用；如果你面临的是一个相对很新的领域而没有现成的架构方式可以参考，你就需要特别小心谨慎的分析思考了。更可能的情况是，一个系统中有一些领域是相对成熟的有现成的方案，而另外一些子领域则可能是问题重重，需要比较大的投入去分析和考量。风险驱动的方式采用**和项目优先级对齐**的架构设计方式，通过对项目优先级的分析识别出相对合理的风险优先级，再基于这些风险优先级来决定做多少架构的工作，以及需要选择什么样的技术来解决高风险的问题。
+
+## 如何决定架构的重要性
+具体的就是如何判断对于某些具体的问题架构是至关重要的，而那些情况下不是。譬如开发一个现实商品细节的手机呈现页面，架构就是是无关紧要的，只需要开发者有足够的软件知识和清晰的界面布局约束，就可以以较低的风险完成编码测试并交付给客户；相反当你开发一个实现自动驾驶汽车的刹车子系统的软件模块的时候，则需要时刻关注整个自动驾驶系统的架构，因为一个微小的错误判断可能轻则导致车辆失控撞上马路旁边路灯，重则撞上前方静止等待红灯的车辆，引发严重的事故。
+
+对于**大规模或者复杂度高**的（有很多相关开发/测试等人员牵涉其中）系统，我们**需要格外重视其软件架构**，具体而言
+- 如果可能的解决方案空间很少，或者很难设计出满足要求的解决方案的系统，软件架构的风险也非常高，譬如设计一个对吞吐量、可靠性、实时性都有相当要求的系统，需要仔细的权衡那些具体的技术可以采用，可能会有哪些现在的风险
+- 生死攸关的系统或者**失败风险极高**的系统，譬如你在开发一个网络中间设备控制器软件，改软件下游有相当多的终端设备相连，任何时候改控制器软件发生故障或者性能下降，下游的设备都会受到波及从而招致客户的抱怨；这种情况下架构的决策以及权衡也变得相当重要
+- 对**质量有相当高要求**的系统，譬如高可用性约束的系统，对系统发生故障导致不可用的时间和故障修复时间有明确的高可靠性要求，那么具体设计中就需要考虑使用那些高可用技术既保证系统的一致性得以满足又能够有适当的备份机制提供热切换，始终尽量保持服务处于不中断状态
+
+## 如何做：风险驱动模型
+
+既然风险驱动架构的目的是**期望用最小的架构技术去降低最紧迫的风险**以达到事半功倍的效果。随之而来的就是具体采用怎样的步骤来达到目标,概括起来可以用如下的步骤
+1. 识别系统的风险，对这些风险排定优先级；这些在专门的风险管理知识中有专门的介绍，包括定性分析方法和定量分析法等，比较正规的办法是使用风险矩阵，包括美国的军方标准MIL-STD-882D，当然大部分软件组织在设计计算机系统的时候不会这么正规。
+2. 选择运用一组技术，这些技术必须是可以用来合理的降低风险而不是增加系统的风险，同时能完成功能需求
+3. 评估风险减低的程度
+
+风险驱动模型的核心在于始终将风险放在极为显著的位置，充分将风险暴露出来，考虑其带来的影响并采用合理的技术解决之。很多情况下，特性驱动的开发模型过于关注对基本功能的完成情况而选择对系统重要的非功能风险置之不理，直**到系统功能完成差不多了才来审视这些质量属性和约束，往往这个时候已经到了项目的维护期而为时已晚**，早期对这些风险的缺乏重视导致项目的维护难以为继而失败甚至推倒重来。
+
+有可能出现的一个问题是，不同的开发人员对风险的评估和认识和你的不同，这个时候可能就需要仔细的评审和和基于事实的一些评估；甚至要做一些简单的原型验证工作。**这些工作都是恰当而必要的，因为你始终工作在方法优先级较高的风险**上。
+
+### 选用什么样的技术
+
+在这个语境下，技术是个很宽泛的字眼，往往关注的是一些独立于具体领域问题的技术，如设计模式或架构模式来分解系统，对领域进行建模采用[领域驱动设计](https://en.wikipedia.org/wiki/Domain-driven_design),做原型测试等等。任何特定的技术都只是擅长于解决某些类型的风险，但并不一定适合于解决其它风险，譬如吞吐量分析和原型测试有利于降低性能风险，但并不能解决系统可靠性的风险。有些风险可能有多种技术手段可以解决，而有些特定的风险则必须结合多种技术才能解决，因此不能一概而论或寄期望于有一个“万能手册”
+> 如果你面临 <X> 风险，请使用<Y> 技术降低它。
+
+有意义的是这种根据风险来选择技术的思路，它可以帮助我们提高工作的效率,**避免在一些低效的技术上浪费时间或者资源**，但同时又不忽略那些真正关乎项目成败的风险。
+
+具体实践上我们也不能根除项目的所有风险，因为消除风险的成本是巨大的，所以必须结合项目的优先级，权衡工程风险和非工程风险，合理采用技术手段和非技术（项目管理）手段，综合考虑技术因素和非技术因素最终确保项目的成功。
+
+## 何时停止？
+合理把握设计和架构的度是个复杂的问题，因为时间成本是此消彼长的关系；用在设计和分析的时间太多了，能分配在构建和测试上的时间就会相应减少。因此我们需要一些中庸之道，采用**恰如其分**的软件设计，即不做过多又不能忽视可能是实际项目实施陷入困境的风险。因而一个简单的模型指导原则是
+
+> 为架构所付出的努力应该与相应失败的风险相称
+
+譬如如果性能风险微不足道，就没必要在性能测试或者分析优化数据结构上浪费太多的时间。然而当性能变的直观重要的时候，就必须从一开始尽量想清楚目标环境的各种性能约束条件，选择合适的算法和数据结构，仔细权衡各种网络和IO开销，及早开始做性能测试甚至可以在开始阶段多做原型验证，确保设计没有大的缺陷。
+
+## 架构和设计的演进
+
+![BDUF_vs_emergent_design](https://randomarchitecture.files.wordpress.com/2013/07/bduf-vs-emergent-design1.png?w=441&h=179)
+
+正如马丁·福勒在其[演进式架构](https://martinfowler.com/articles/designDead.html)中所说，系统的设计会随着具体的实现的增长而增长；过往的软件工程历史表明，演进式设计一直充满了争议，局部而又不协调的设计决策会带来一系列的混乱，从而制造出一个大杂烩系统，导致系统的可维护性下降，进一步阻碍系统的进一步演进。甚至于一不小心还会陷入[大泥球架构](http://www.laputan.org/mud/)的泥潭。
+
+当然随着敏捷开发方式的日渐流行和各项重构技术的发展，演进式架构以及渐渐克服了上述这些缺点从而再度焕发生机，奥妙就在于各种更为敏捷的工程实践，包括重构、测试驱动开发、持续集成等越来越深入人心。
+
+传统的方法上来说，也有预先计划式设计这种从建筑行业借鉴来的方式（架构师这个名称也是从建筑行业来的），要求实现做好周密的设计然后再开工写代码做测试；只是时至今日一见很少有人主张采用预先大量设计([Big Design Up Front](https://en.wikipedia.org/wiki/Big_Design_Up_Front))。
+
+介于两者之间的是预先小量的设计，采用这种方式可能是更好的一种这种，譬如在一开始阶段，通过对系统风险的分析对最大的风险采用预先设计的方式防范最首要的风险，然后随着项目的逐步推进，采用演进式设计来逐步完善整个系统的整体设计图景；当然这里最重要的前提是，**确保重构、持续集成、测试驱动开发等关键的敏捷开发实践能够落到实处**。
+
+**T.B.D**
+
diff --git a/_posts/2016-10-14-fp-support-in-java8.md b/_posts/2016-10-14-fp-support-in-java8.md
new file mode 100644
index 0000000..e614c60
--- /dev/null
+++ b/_posts/2016-10-14-fp-support-in-java8.md
@@ -0,0 +1,525 @@
+---
+layout: post
+title: Java8中的函数式编程
+categories: [language, programming, fp, design]
+tags: [java, programming, language, fp, pattern, design, optional, stream]
+---
+
+Java8是日益臃肿、略显老态的老牌程序语言对日益流行的**新的函数式编程范式**的反击；
+它采用了巧妙的技术让自己面向对象的古老躯体也套上了函数式编程的舞鞋再度翩翩起舞，焕发新的光彩。
+
+<!--more-->
+
+## FP的基本要素：函数
+Java并不打算放弃其面向对象的内核 - 所以的东西必须都是对象，那么函数也不例外，它依然是对象。具体而言，是一个特殊的函数式接口的实现。
+
+### 函数依然是对象
+在新的`java.util.function`包里，预定义了形形色色的函数接口，譬如带2个参数的函数的定义如下
+
+```java
+@FunctionalInterface
+public interface BiFunction<T, U, R>{
+  //all functions implements apply that takes t of type T and u of type U, and returns R
+  R apply(T t, U u);
+
+  //compose function
+  default <V> BiFunction<T, U, V> andThen(Function<? super R, ? extends V> after) {
+    Objects.requrieNotNull(after);
+    return (T t, U u) -> after.apply(apply(t, u));
+  }
+
+}
+```
+从定义来看，它是一个接口，任何实现了该接口的对象都是一个二元函数。从纯粹的面向对象思路来看，只要让所有实现类似调用的类也实现新的接口就行。
+仔细考虑则发现该思路有个不足 - 很可能我们已经有一个已有的接口
+
+```java
+public interface MyInterface{
+  ReturnType doSomething(ArgType1 arg1, ArgType2 arg2);
+}
+
+public class MyBusinessClassA implements MyInterface {
+  @Override
+  ReturnType doSomething(ArgType1 arg1, ArgType2 arg2){
+    //detailed implementation
+  }
+}
+```
+
+考虑用户代码想要使用上述的接口，同时希望采用函数式编程的思路，接受一个函数参数
+```java
+//client code
+void myMethod(BiFunction<ArgType1, ArgType2, ReturnType> certainProcessing) {
+  //calls certainProcessing.apply(arg1, arg2);
+}
+
+MyBusinessClassA businessClass;// = ...;
+ArgType1 arg1; //= ...;
+ArgType2 arg2; //= ...;
+myMethod(/*use existing business classes?*/)
+```
+如果仅仅是因为需要采用函数式编程风格来编写代码，就必须要求我们修改原来的接口或者class定义破坏性就太大了。Java8采用了变通机制，
+当**某个接口有且仅有一个方法定义**的时候，该接口可以被编译器隐式地转换为一个函数式接口的一个扩展；实现了此业务接口的类则被视为函数式接口的一个具体实现。
+对应的这个方法(`doSomething`)会被认为是默认的`apply`方法，即使这个方法的名字是别的，
+只要参数个数、类型、返回类型能匹配到对应的泛型函数接口的对应类型(`doSomething(...)`)，它就会被视为是实际实现的方法。
+当用户代码用函数式编程的风格来调用抽象的函数式对象(`BiFunction`)的`apply`方法时，实际调用会被委托为实际实现方法(`doSomething`)的调用。
+
+为方便代码维护和协助编译器检查的考虑，Java8提供了`@FunctionalInterface`注解方便我们清晰的知道某个接口符合函数式接口的要求。
+也许是为了更灵活的配合函数式编程，Java8也允许一个接口中有提供默认实现(用`default`关键字标识)，此时这样的方法被认为是具体的而非抽象的；
+这样只要一个接口中**有且只有一个抽象的方法**，它依然符合函数对象的要求。
+
+如果接口声明没有加上`@FunctionalInterface`注解，调用的地方却使用了lambda表达式语法，编译器会检查对应的类接口中是否满足函数式对象的约束如有违反则报错。
+因而该注解不是必要的；出于代码可读性的考虑，还是建议尽量加上该注解。
+
+### 内置函数
+
+Java8的工具库中提供了一些常见的基于泛型的函数式接口
+
+- 返回值为布尔类型的函数 - Predicate
+- 参数类型和返回值类型一样的函数 - `Operator`
+- 没有返回值的函数 - `Consumer`
+- 不带参数而能产生某些返回的函数 - `Producer`
+- 基于非装箱原始类型的特殊函数 - 某些时候希望避免自动装箱和自动解箱的性能开销
+- 添加了参数个数信息的函数，譬如`BinaryOperator<T>`用于描述签名为`(T a, T b) -> T`的函数;对应的`UnaryOperator<T>`用于描述的函数签名为`(T a) -> T`
+
+依据以上的命名风格，`java.util.function`中定义了几十个泛型的函数接口，可以满足几乎所有的简单场景。查看[JDK文档](https://docs.oracle.com/javase/8/docs/api/java/util/function/package-summary.html)可以发现, Java8**没有提供超过2个参数**的函数接口定义，默认的`Function<T, R>`描述的是最普通的单映射函数。
+
+### 匿名函数和Lambda
+
+匿名函数其实是被Java8给封装成具体的函数对象（实现某个预定义的接口)。语法上没什么奇特的地方，和C++/Haskell的都比较类似。
+在任何一个可以传入函数调用的地方，都可以传入lambda表达式或者代码块，并且类型信息可以省略,如上边代码的例子
+
+```java
+MyBusinessClassA businessClass;// = ...;
+ArgType1 arg1; //= ...;
+ArgType2 arg2; //= ...;
+myMethod((arg1, arg2) -> businessClass.doSomething(arg1, arg2));
+```
+
+lambda表达式中引用上下文变量的情况下，该lambda表达式自然形成了一个闭包。
+当函数实现逻辑不能用一行写下来的时候，也可以用大括号写代码块；和其它主流支持函数式编程的语言没什么两样。
+
+## Optional类型
+Optional类型是个典型的容器类型，用来表示有一个合法值或者空值；其本身是一种简单的[Monad类型](http://learnyouahaskell.com/a-fistful-of-monads)。
+
+### 从错误处理方式说起
+长久以来，Java都是采用两种方式处理可能的逻辑例外情况，要么是采用返回对象的方式，要么是采用异常传递。
+Java的异常在设计上被分类为检查异常和非检查异常；前者别用来表述一些可以恢复的意外情况，编译器会在编译的时候检查可能抛出该类异常的API的**调用方必须显式的处理**检查异常；
+非检查异常用来表述编程上的错误；严格来说非检查异常应该是代码的某些地方处理除了问题；需要通过修改代码来解决问题。
+
+Sun是这样设计Java的异常机制的，开源社区却对这种编译器强制检查的异常颇有微词，甚至很多有名的开源项目都**主张永远不使用检查异常**；
+遍布`try/catch`块的代码的可读性非常差，可怜的业务逻辑很容易淹没在异常处理代码的包围圈里。
+
+仅使用非检查异常的副作用是，程序很容易因为没有正确处理的异常而崩溃。
+于是很多程序员会转而采用破坏对象状态的方式，到处传递空指针；为了避免空指针异常导致的程序崩溃，我们有不得不在代码中加上很多引用是否为空的判断，写出越来越难维护的代码。
+
+> I call it my billion-dollar mistake. It was the invention of the null reference in 1965. ... My goal was to ensure that all use of references should be absolutely safe,
+> with checking performed automatically by the compiler. But I couldn't resist the temptation to put in a null reference, **simply because it was so easy to implement.** 
+> This has led to innumerable errors, vulnerabilities, and system crashes, which have probably caused a billion dollars of pain and damage in the last forty years.
+> > -- Tony Honare, apology for inventing the null reference
+
+### 用Optional来处理错误
+
+传统的C/C++语言中，返回值也是一种处理错误的方式；其不足之处是，正常处理和异常情况的处理会产生很多复杂的逻辑判断，导致正常的逻辑难以理清；Java不建议集成这笔古老的遗产。
+
+`Optional`类则提供了**一种新的错误处理方式**；从概念上来说，这三种方式是不能同时采用的，要么采用`Optional`要么采用异常，但是不应该两者都采用。
+
+从概念上来说，一个`Optional`对象是关于某种具体对象的一个容器，它要么包含一个已经初始化的对象，要么什么也没有。
+看起来和null引用没什么区别；主要的差异在于类型系统上 - Java是种静态语言，**null对象不是一个合法初始化过的对象**，对它做任何方法调用都会引起引用异常；
+`Optional`则不同，即使没有正确的初始化某个对象，它**本身依然是一个合法的对象**。它用一套统一的接口来操作内部封装的对象。
+
+具体到Java8的定义它本质上是一个不可被外部构造和继承的一个具体的类，可以参考JDK的源码
+```java
+public final class Optional<T> {
+  private static final Optional<?> EMPTY = new Optional<>();
+  private final T value;
+}
+```
+
+从容器封装的角度来看，`Optional`可以**看作是集合类的一个特殊的退化情况** - 它要么保护一个对象，要么什么也没有；但是不能包含超过两个或更多个对象。
+`Optional`提供了很多API供我们使用
+
+### 构造出新的Optional对象
+
+构造的方式有很多种，可以用默认的空构造创建一个空的对象，此时内部的封装对象没有被初始化；另外一种方式是静态方法
+- `of`方法传入一个**非null**的对象，构造出包含给定对象的容器
+- `ofNullable`方法传入一个可能为null的对象；构造中会依据是否为null来决定是创建初始化的容器还是空容器
+
+`Optional`对象一经创建就不允许在修改其内部的状态；但是可以通过`get`方法来获取内部存储的对象 - 如果是空则会抛出`NoSuchElementException`。
+一般情况下不建议未经检查便直接调用`get`方法；因为`Optional`本身提供了很多函数式编程的模式。
+
+### 模式
+
+有如下模式可以供我们组合使用
+
+#### 对封装数据的修改/转换相关的模式
+
+`filter` 提供过滤器功能，可以依照用户传入的一个谓词函数对容器中的对象进行过滤，如果谓词判断为真，则原封不动返回原容器，如果是假，则返回空容器
+
+`map` 提供对象转换功能，其参数是一个转换函数，实现一个对象到另外一个对象的转换；
+这里`Optional`保证传给参数函数的输入值一定不会是空对象，即**转换函数不需要做null判断**因为map实现本身已经帮你判断了。
+从函数式编程的角度来看，`map`是一个高阶函数 - 其参数是另外一个函数
+
+`flatMap` 和上边的`map`类似，差别在于传入的参数函数的返回这无法确保非null的情况下选择了一个新的`Optional`类型作为返回；
+为避免`Optional<Optional<T>>`的麻烦，`flatMap`会将这个二层封装给解开，生成一个单一的封装。
+其实现代码非常简单
+```java
+public<U> Optional<U> map(Function<? super T, ? extends U> mapper) {
+  Objects.requireNonNull(mapper);
+  if (!isPresent())
+    return empty();
+  else {
+    return Optional.ofNullable(mapper.apply(value));
+  }
+}
+```
+
+#### 数据提取相关的模式
+`orElse` 提供容器封装对象的提取；如果原来的容器里存有合法的对象，则直接返回此对象；如果没有则返回参数提供的默认值。
+这里的提取实际上是一个解封装操作；返回的对象同样也抱枕是非null的，**拿到这个对象的调用者不需要做额外的null判断**
+
+`orElseGet` 是一个类似的提取操作，和`orElse`不同的是对于空容器的处理，返回值由一个传入的`Supplier`来提供；同样**也要保证尽量不要提供nulli**
+以免让使用者操心null判断的事儿。从函数式编程的角度来看，这也是一个高阶函数。
+
+`orElseThrow` 则提供了一个和传统的异常相结合的方式，同样不需要外层调用者自己加逻辑判断，容器会在有对象的情况下返回对象出来，
+没有则调用传入的`Supplier<? extends Throwable>`抛出一个异常。这同样是一个高阶函数
+
+
+上述的模式提供了丰富的组合功能使我们对一个`Optional`对象做函数式编程变得简单明了；甚至不需要一个`if`/`else`分支判断就可以做一些复杂的操作。
+比如下面的一段代码
+```java
+AnotherResult result = Optional.ofNullable(someObj.doSth(parX))
+  .filter(someResult -> someResult.meetSomeCondition())
+  .map(conditionalResult -> transformAsAnotherResult(conditionalResult))
+  //.flatMap(conditionalResult -> transformAsAnotherResult(conditionalResult)) if transformAsAnotherResult returns optional
+  .orElseGet(() -> new anotherEmptyResult());
+  //.orElseThrow(() -> new SomeRunTimeException()); //if we want to throw
+
+//Now result wouldn't be null at all!
+```
+
+#### 反模式
+`Optional`可以帮助我们大大简化代码，然而也有一些**反模式需要小心留意**；比如以下这些
+
+##### 违反基本的约束
+以下列举了几个常见的基本错误，这些错误只要稍微深入理解下`Optional`的设计思想就可以避免
+
+1. 混用异常和`Optional`类型返回 - 显然两种机制是鱼和熊掌的关系，设计方法的时候必须选择其中一个，而不是两者混用。
+如果**选择让方法返回Optional类型，就不要在实现内部再抛出异常**，否则你的用户将会抓狂。
+
+2. 在Optional的值中存放`null` - 这是明显**违背设计契约**的做法，导致`Optional`封装完全失去意义。如果想重新构造一个Optional,
+如果不能确保它不是null，请用`ofNullable`
+
+3. 在模式提供的高阶函数的实现中检查参数是否为null - 这里是做了不必要的额外检查，因为`Optional`已经给你保证了传给你的参数不会是`null`。
+
+ 譬如下边的实现纯粹是画蛇添足
+
+```java
+anOptional.map(v -> doSth(v));
+
+private SomeType doSthn(ValueType v) {
+  if (v != null) {
+    //do something and generates return type
+  } else {
+    //This won't be ran!
+  }
+}
+```
+
+##### 冗余的判断
+还有一些典型的误用和**不熟悉函数式编程的惯用法**有关，可以通过简单的重构解决
+
+1. 混用`if/else`和Optional的`isPresent()`和`get()` - 这是一种非常常见的误用；往往使得代码变得更加复杂。
+因为`Optional`本身就是设计来处理可能的例外情况，更合适的方法是用好上述的模式。
+
+ 如果需要提取出值对象，就用`orElse`系列方法；如果不需要产生任何类型的新值，可以用`ifPresent`传入lambda表达式;如果需要将结果从一种类型变化为另外一种，就采用上述的转换模式。
+
+2. 复杂的链式操作，即多个连续的`map`操作 - 这种情况下代码的可读性也变差；根源是不同层次的细节被堆积在一个抽象层次中了；用简单的**重构技巧抽出新的子函数**即可。
+逻辑上来说，`anOptional.map(a -> transformAsB(a)).map(b -> transformAsC(b))` 等价于 `anOptional.map(a -> composeTransformAAndB(a))`；这里的字函数都不需要做null判断
+
+3. 用`Optional`类型作函数的参数 - 这个是一个轻微的反模式，IntelliJ IDEA甚至会温馨的提示你需要重构。
+原因也比较简单，Optional类型和外部函数组合的时候，都期望通过合适的变换/提取函数将值取出来传出去，是否存在的事儿，用已有的模式去做就可以了。
+任何用`Optional`在函数中传递的写法，都**对应一个更简单的复合Optional模式**的写法;为什么不采用这些模式而要自己写判断？
+
+  比如如下的例子
+```java
+Optional<SomeType> anOptional = ///initialize;
+RetType b = doSth(anOptional);
+
+private RetType doSthn(Optional<SomeType> opt){
+  return opt.map(obj -> obj.transform()).orElse(new RetType());
+}
+```
+
+  可以重构为更符合[局部性原理](https://en.wikipedia.org/wiki/Locality_of_reference)的形式,避免`Optional`类型的蔓延
+```java
+Optional<SomeType> anOptional = ///initialize;
+RetType b = anOptional.map(v -> doSthn(v)).orElse(new RetType());
+
+private RetType doSthn(SomeType obj){
+  return obj.transform();
+}
+```
+## Streams API
+Java8新提供了`Streams` API来实现更类似于Haskell的[List Monad](http://learnyouahaskell.com/a-fistful-of-monads)风格的函数式编程设施；
+值得注意的是，在老版本的Java库里边，`List`这个接口已经用来描述传统的基于共享内存模型的数据结构了（和C++的类似）；
+这也许是Java8另起炉灶新添加新的接口来描述这一概念。
+
+类似于Functional Interface,Streams API也是包含一系列**新的Java接口**的包的简称；这些接口都放在`java.util.stream`包中。
+
+### 基本概念
+Stream是一个函数式编程概念的接口抽象；它和集合类的概念比较类似；比较大的差异在于Stream是
+- 关于**操作的抽象**而不是关于数据的抽象，可以将其看作一个流水线，
+一些数据流入抽象的Stream,经过某些操作变换产生某些输出；这些输出可能成为流的下一步处理的输入
+
+- 无状态的，所有绑定的**操作不能修改数据源**，即只能决定产生的输出是什么样子，不能回头修改输入的数据；
+这也是纯函数式编程所要求的**无副作用**；同样的数据经过某个处理操作产生的输出一定要是一样的。
+
+- **惰性运算**赋值的，即Stream上的操作不一定会消耗所有的输入数据，譬如我们在一个Stream上取前3个数据，
+那么即使输入数据有无穷多个，操作也能在取到3个的时候就结束返回给下一步处理。
+
+- 可能有无限多个输入，只要后续的操作是有限的
+
+- 同一个Stream的输入**只能被使用一次**，下一次若想操作必须重新生成Stream；从这点设计约束看，Java的Stream没有Haskell的纯粹;
+也可以认为流水线一旦被处理，最原始的数据就不存在了。
+
+### 基本的Stream类型
+所有的`Stream`接口都继承自一个公共的**泛型接口** 
+```java
+public interface BaseStream<T, S extends BaseStream<T, S>> extends AutoClosurable {
+  Iterator<T> iterator();
+  Iterator<T> spliterator();
+
+  @Override
+  void close();
+  S onClose(Runnable closeHandler);
+
+  //...other common interfaces...
+}
+```
+其中`T`用于声明其初始输入的元素的类型，`S`则用于将子类的类型带上来，和C++的[CRTP](https://en.wikipedia.org/wiki/Curiously_recurring_template_pattern)技巧类似。
+从接口声明上看，一个Stream类也
+- 提供了迭代器访问接口，可以用传统的迭代器访问模式操作`Stream`
+- 实现了`AutoClosurable`接口；从而我们可以结合Java8的try-with-resource表达式方便的自动管理资源。
+
+  **大部分的Stream实现并不会管理资源**，因而不显示关闭Stream往往也不会带来什么问题。
+
+#### `Stream<T>`接口
+
+最平凡的Stream是名为`Stream<T>`的泛型接口
+
+```java
+public interface Stream<T> extends BaseStream<T, Stream<T>> {
+  //operations...
+  //terminators...
+  public interface Builder<T> extends Consumer<T> {
+    @Override
+    void accept(T t);
+
+    default Builder<T> add(T t){
+      accept(t);
+      return this;
+    }
+
+    Stream<T> build();
+  }
+}
+```
+
+该接口包含一些**转换操作和终止操作**组成；转换操作将Stream中的数据作为输入，经过变换或过滤等产生新的输出；并准备好下一次转换操作或终止流水线；
+终止操作则直接终止流水线，返回某些汇聚之后的结果出来。
+
+#### 以Java基本类型为数据元素的特殊Stream
+Java泛型技术的一个限制是，对基本的数据类型（这些类型不是一个Object）必须用包装类，
+直接用包装类替换基本类型则会带来比较大的[性能开销](https://tavianator.com/java-autoboxing-performance/)；
+尤其是Java5之后引入的自动装箱对程序员隐藏了这些实现细节，某种程度上加剧了问题的严重性。
+
+`Stream`对所有的基本类型都提供了一个对应的接口，比如`IntStream`、`LongStream`等等。这些接口都继承自`BasicStream`,暴露的方法和`Stream`比较类似；从接口声明上看，
+很多方法和`Stream<T>`都是类似的，仅仅是针对类型做了特殊处理，这个也是很老的一个对Java语言设计的槽点了。
+
+### 生成Stream
+大部分情况下，用户不需要手工创建Stream对象；它们可以用不同的方式产生
+
+- 使用`Collection`接口的`.stream()`方法；还有一个对应的`.parallelStream()`返回一个可以并发执行的对象
+
+- 使用`Arrays`工具类的`.stream(Object[])`从一个数组构造出来
+
+- 使用`Stream`本身的一些静态方法产生，包括
+ 1. `Stream.of(T t)`产生单个元素的Stream对象
+ 2. `Stream.of(T... values)`从对象列表中产生
+ 3. `Stream.generate(Supplier<T> s)` 用给定的`Supplier`函数产生无穷序列(其实受`Long`类型的最大可能值限制)
+ 4. `Stream.concat(Stream<? extends T> a, Stream<? extends T> b)`连接两个已有的流
+
+ 这些方法也有对应的针对基本类型的Stream的版本。
+
+- 使用`StreamSupport`辅助类来产生，包括
+ 1. `stream(Spliterator<T> spliterator, boolean parallel)`从一个迭代器产生，可以支持并发的`Stream`
+ 2. `stream(Supplier<? extends Spliterator<T>> supplier, int characteristics, boolean parallel)`支持从给定的迭代器的Supplier中一一调用`.get()`方法；支持并发方式迭代
+ 3. 类似功能的针对基本类型的Stream的封装
+
+- 特定场景的构造方法，比如
+ 1. 随机数产生器流，用`Random.ints()`
+ 2. 缓冲的IO流中产生的流 - `BufferedReader.lines()`
+ 3. 其它形形色色的JDK库提供的封装；以及第三方库提供的封装
+
+- `Builder`接口
+该接口是`Stream<T>`的内部接口，扩展了`Consumer<T>`；可以利用`add(T t)`方法添加元素到Stream中；该操作支持链式调用，最后用`build()`方法生成最终的Stream对象。
+实现在`Consumer`的接口则具有和`add`类似的语意，只是不支持链式操作。比如`IntStream.Builder.add(1).add(2).add(3).build`生成一个包含3个数字为输入的Stream。
+
+### 流水线操作和变换
+作为一种函数式编程工具，Stream就天然是为组合而生的；这些组合本身就构成了流水线处理 - 初始化的元素作为流水线的输入，而中间的转换步骤可以有任意多个，
+最终则往往会有一个终止操作来产生期望的输出 - 该输出也是我们从流水线上拿到最终结果的地方。
+
+#### 中间操作和终止操作
+所有这些中间操作每次返回一个新的`Stream`状态，其输入是经过转换的 - 如前所述`Stream`的输入是不可修改的；该新的Stream的输入是对前一次的输入，
+输出则由前一次操作的针对每一个输入做运算之后的输出组成；如果某些运算不产生输出，则这些数据就像筛子一样被过滤下来了。
+
+所有的终止操作从函数签名上来看，都不会返回新的Stream对象。
+
+所有的中间操作都符合**延迟计算**规则；即真正的输出并没有在调用这些转换操作的时候被计算出来；
+只有**当终止操作被调用以取出需要的值的时候**，这些转换操作才真正被计算出来。
+
+当我们提供一个无限长的输入提供给Stream的时候，真正参与具体操作的元素个数仅仅以满足终止条件为准。
+
+譬如下边的代码
+```java
+int first5PrimeSum = IntStream.iterate(1, i -> i+1)
+    .filter(x -> isPrime(x))
+    .limit(5)
+    .sum();
+```
+
+初始构造的Stream包含无穷多个元素（受限于int类型的长度），但是经过`filter`操作之后，由用`limit`取出前5个，并最终求和；
+那么实际参与运算的初始输入元素只有1到11而已。
+
+根据以上的赋值求值规则，我们可以认为终止操作是**贪婪求值**的并会产生副作用；一旦调用了终止操作，Stream对象即产生了最终的运算结果；
+原始的输入元素遭到了破坏，无法回头重新来过。
+例外的情况隐藏在`iterator()`和`splititerator()`操作上，它们虽然是终止操作，却不会破坏流水线的状态，用户可以用`iterator`接口来决定流水线的运算时间点。
+
+#### 中间操作模式
+`Stream`接口提供了很多传统的符合函数式编程风格的方法，一些甚至允许更灵活的高阶函数
+- `map`用于普通的函数变化，其参数是一个转换函数，将数据从一种类型转换为新的类型
+- `flatMap(Function<? super T, ? extend Stream<? extends R>> mapper)`将Stream的每一个元素应用之转换函数，然后将转换结果流中的数据取出来汇聚为新的Stream。
+ 该操作是一种相对高阶的模式，可以避免手工来拼接流
+- `skip`/`limit`分别用于截取或者跳过某些元素
+- `sorted`则产生按照给定排序规则排列为有序输出数据的流
+- `filter`用来过滤流中满足给定谓词逻辑判断的数据
+- `distinct`会删除重复的元素
+- `peek`用于在产生输出数据的同时，做一些参数指定的函数操作；该操作大部分时候可以用于方便debug，比如
+```java
+Stream.of("one", "two", "three")
+  .filter(e -> e.lenth() > 3)
+  .peek(e -> System.out.println("Filtered value: " + e))
+  .map(String::toUpperCase())
+  .peek(e -> System.out.println("Mapped value: " + e))
+  .collect(Collectors.toList());
+```
+
+#### 有状态和无状态的中间操作
+
+中间操作可以携带lambda表达式，从而可以简单将其分类为有状态的和无状态的操作。
+有状态的操作会**携带额外的上下文信息**，如果这些操作的运算结果跟操作的中间结果有关，则Stream的行为会变得依赖于流水线的执行顺序 - 如果操作被并发调度，
+结果就会显得不确定。
+
+比如这个例子
+```python
+Set<Integer> seen = Collections.synchronizedSet(new HashSet<>());
+stream.parallel().map(e -> if (seen.add(e)) {
+      return 0; 
+    } else {
+      return e;
+    })
+  .reduction(...)
+```
+第一个`map`操作时间的执行体中会根据给定的元素是否已经处理过来决定返回0或元素本身；这个lambda操作本身依赖于之前的运算所以是有状态的。
+
+显然有状态的操作在用`parallelStream`调度计算的时候**会产生不确定结果**；而无状态的操作则没有这样的副作用。
+
+Java8引入`Stream`的首要目的就是并行计算和并发，默认串行的操作，仅仅需要在生成`Stream`的地方加上`parallel()`就可以自动获得多核并发调度的好处。
+
+#### 潜在的操作干扰
+
+传给Stream的数据在Stream运算的过程中被视为静态的；如果这些数据可能被同时修改，则操作的正确性就难以保证了。
+考虑一个用Java的ArrayList产生的Stream做运算的情况
+
+```java
+List<String> strList = new ArrayList(Arrays.asList("one", "two", "three");
+Stream<String> strm = strList.stream();
+strList.add("four"); //WoW!
+String result = strm.collect(joining(" "));
+```
+有状态的函数操作或者互相干扰的函数操作会**破坏并发安全性并带来出乎意料的行为**（因为多线程、同步、调度的细节被隐藏了）；应该不建议使用。
+
+#### 常用的终止操作
+终止操作的方法很多，基本上`Stream`的API中，除了静态方法以外，所有的返回类型不是`Stream`的都是终止操作，常用的有
+- `allMatch`/`anyMatch/nonMatch`接受一个谓词函数作为参数，返回是否流中的元素都满足给定的条件，或至少有一个满足条件;以及是否没有满足条件的元素
+- `collect(Collector<? super T, A, R>)`用于收集流参数到给定的集合中;这里的`Collector`是一个可修改的归并操作运算抽象；
+ 常用的方式是使用`Collectors`这一工具类提供的静态方法传入各种各样的`Collector`
+- `collect(Supplier<R> supplier, BiConsumer<R, ? extends T> accumulator, BiConsumer<R, R> combiner)`是上述接口的一个简化版本，显示提供了归并操作的其中三个函数参数
+- `count`返回元素的个数
+- `toArray`返回元素为数组形式
+- `forEach`则提供遍历操作
+- `findFirst`/`findAny`返回第一个/任意一个元素，由于可能不存在希望取的元素（没有元素的情况），返回类型是`Optional<T>`
+- `reduce`归并操作，包含几个重载形式
+
+### 归并
+归并操作是map/reduce模式中比较复杂和灵活的终止操作；`Stream`接口也提供了丰富的支持。其实这里的`reduce`在其它的函数式语言中也被称为`fold`。
+
+#### 最灵活的形式
+
+一般形式的`reduce`操作支持如下几个参数
+- `U identity`是单位元元素，同时作为输出的默认值
+- `BiFunction<U, ? super T, U> accumulator` 负责中间的每一次运算的累加
+- `BinaryOperator<U> combiner` 约束accumulator 和 identity的函数，需要满足 `combiner.apply(u, accumulator.apply(identity, t)) = accumulator.apply(u, t)`
+
+调用的效果类似于
+
+```java
+U result = identity;
+for (T element: this stream)
+  result = combiner.apply(result, accumulator.apply(identity, t))
+return result
+```
+
+#### 省略`combiner`的版本: `T reduce(T identity, BinaryOperator<T> accumulator)`
+该形式下，accumulator的类型是`BinaryOperator<T>`,同时`identity`的类型必须和Stream中的元素类型相同。
+
+`sum`/`max`/`min`等都可视作是该版本的特化实现；即
+```java
+Integer sum = integers.reduce(0, (a, b) -> a + b);
+//same as
+Integer sum = integers.reduce(0, Integer::sum);
+```
+
+#### 只有`accumulator`的版本
+这种情况下，返回的类型是`Optional<T>`;由于没有默认值，因此返回合适的结果必须至少有2个元素可以参与累加器运算；如果少于2个则返回空的Optional。
+等价的代码为
+
+```java
+boolean found = false;
+T result = null;
+for (T element: this stream) {
+  if (!found) {
+    found = true;
+    result = element;
+  } else {
+    result = accumulator.apply(result, element);
+  }
+}
+return Optional.ofNullable(result);
+```
+该种形式的操作将Stream和Optional结合了起来。
+
+## 总结
+
+在函数式编程变得日益火热、几乎无处不在的今天，传统的基于面向对象范式的Java语言最终也通过**更新语言核心**的形式**拥抱**这一新的编程范式。
+其设计从根本上来说，依然是基于围绕着传统的面向对象的抽象、封装、接口形式实现的，处处体现着面向对象编程的影子。
+它对`Optional`类型的丰富支持和多样的接口抽象能极大地方便程序员的日常使用；强大的`Streams API`提供了基于流水线的高层抽象；
+并发流的支持使得仅仅需要加入一个简单的`parallel()`调用即可实现无状态运算的并行化。
+
+同时，一些"历史包袱"也深深地影响着Java的实现方式，包括基本类型不是对象，以及泛型接口的类型设计特性等导致某些接口看起来比较臃肿和罗嗦。
+早期Java的简单性早已经消失殆尽了，因为它同样随着时间的推移加入了面向对象、泛型编程、注解、函数式编程等复杂的特性；
+也许这是作为大规模采纳的程序语言不可避免的老路。
+
+总体上来看，这些问题依然是瑕不掩瑜，大部分情况下普通程序员不需要被困扰过多。
+随着时间的推移，业界的大规模采纳应该不是什么问题。
diff --git a/_posts/2016-12-24-software-design-in-agile-development-context.md b/_posts/2016-12-24-software-design-in-agile-development-context.md
new file mode 100644
index 0000000..d0cde56
--- /dev/null
+++ b/_posts/2016-12-24-software-design-in-agile-development-context.md
@@ -0,0 +1,62 @@
+---
+layout: post
+title: Software Design in Agile Development Context
+date: 2016-12-24 19:32
+comments: true
+categories: [design, engineering]
+tags: [design, agile, methodologies]
+---
+
+在目前大部分的软件开发组织中，敏捷开发已经成为毋庸置疑的标配。随着数位技术大神和布道师的宣扬和数量庞大的敏捷教练的身体力行式推广，商业环境和客户需求变更速度的日益加快，采用端到端交付周期更短的敏捷开发过程基本已经成为项目成功的必要条件。
+
+<!--more-->
+
+## 软件设计的刚需被敏捷了吗？
+
+工作流程的变更以及开发节奏的加快并不能绕开一个很核心的问题：**写出容易维护方便扩展的代码的复杂程度本质上没有改变**；软件的维护周期越长，迭代的版本越多，这个基本问题就越突出。要想顺利解决这一问题，只能**依赖于系统具有相对良好的设计**，使得添加新的功能不会轻易破坏原有的结构，出现问题的时候，不需要大范围地对系统做出变更。
+
+传统的瀑布式方法希望通过借鉴成熟的建筑行业的做法，采用预先大规模的架构设计，对系统做好明确的分割；继而进行不同层次的设计，直到所有可以预见到的需求都得以满足，然后才开始进行的代码的编写和构建。这种方法生产出来的软件交付工期很长，适应性很差，除了少数特殊行业之外基本已经被市场所淘汰。
+
+[敏捷宣言](http://agilemanifesto.org/) 提出了一些基本的原则来指导我们怎样用相对更"**敏捷**"的方式开发和交付我们的软件；通过多个不同的迭代，增量式的构建和持续交付系统来降低风险。然而软件本身的复杂性导致我们不能将客户的需求一对一的翻译成代码，像搭积木一样构建出来一个可以轻易维护的系统。因为新加入的需求很可能导致原有的代码结构无法适应新的需求；某些为了尽快完成需求而做出的**关键的假设可能必须被打破**导致添加新的需求会破环大量已有的功能。如何做出恰如其分的软件设计，既能满足现有的短期需求，又能平衡潜在的变更。
+
+各种不同的敏捷实践方法论对如何管理用户的需求，如何增强不同角色的沟通，如何实施日常的开发和测试活动，如何验证需求保证已经交付的承诺不被变更所破坏，如何规划和平衡资源和进度等复杂问题都给出了丰富的可选实践供项目管理人员裁剪；对于如何做软件设计以及做多少软件设计并没有很详尽的描述。就连基本的是否需要软件设计，以及需要多少软件设计，怎样算作过度设计都语焉不详。
+
+## 真的需要软件设计吗？
+
+大部分情况下，对于这个基本的问题我想答案应该是肯定的，除非你是在做一个很小的个人项目。如果需要牵扯到多个人一块合作并且最终的产品需要维护比较长时间，那么起码**某种程度的软件设计**应该是不可或缺的。毕竟**软件开发活动本身也是围绕着人展开**的，既然需要多个不同知识背景，不同技能，不同角色的人一起来协作交付功能复杂多变的软件，那么必然需要一些设计保证**参与其中的人有一致的理解**。
+
+敏捷运动的早期一个常见的误解就是，敏捷软件开发不需要软件设计，不需要软件架构，只需要采用极限编程，将人们聚集一个公共空间里，直接动手写代码就行了；复杂的设计文档都是浪费，都是可以避免掉的，代码就是最好的设计文档。这样的过程可能适合于几个能力超强的程序员聚在一起做的临时小项目，放到更广泛的商业环境则难以持续下去。人员的流动，特殊需求的变更，性能问题的修补会使一个一开始看起来极其简单的几个源代码文件组成的小项目演进成**难以维护的“庞然大物”**。
+
+如果系统没有明确的分工和边界，没有相对清晰的职责分工和交互限制，软件的结构很容易陷入“大泥球”结构而不可维护，试想如果代码里的每一个包或者类都有可能和另外其它的任意一个类有交互关系，即使是一个绝对代码行数很小的项目也会变得无法继续添加新的功能。
+
+## 哪些东西应该包含在软件设计中？
+
+所谓的设计其实可以理解为关于如何组织软件各个部分（特性和行为分割）的一些决策，以及做出相应决策的一些原因。
+
+敏捷场景下，重构的重要性以及早已经深入人心，因而容易经**由重构来去掉“坏味”的部分就不宜放在设计**中。因为一般为了重用的目的都会将设计决策写下来供后续使用；如此一来必然产生一些维护成本；而维护设计文档的开销一般比代码要大很多。因此容易通过重构而优化的部分，放在专门的软件设计中显得有些得不偿失了。毕竟敏捷软件开发的基本思路就是**消除浪费**，使得**投入产出比最大**化。
+
+某些跟具体实现技术相关而和核心业务需求关系比较远的决策，大部分也**不适宜包含在软件设计**中。譬如期望某部分关键数据需要做持久化以保证系统异常重启的时候依然可以恢复。对于业务需求而言，这块数据需要持久化是重要的，但是如何做持久化，又可能是易变的，譬如今天是考虑用文件来做持久化就可以了，将来可能发现不够必须用关系数据库，或者甚至关系数据库可能也不是一个合适的选择，得要用键值对数据库。**识别到可能变化的部分，并将不变的部分抽象出来，放入设计中**可能就足够了。这样技能照顾到当前的需求，又能满足将来扩展的需要。至于具体是怎样实现的，看代码就足够了。
+
+需求的**概念抽象化，和软件的静态模型可以作为设计的中心**之一，必须详细考虑并归档维护。之所以要对需求进行抽象化处理，是因为用户的期望可能是模糊不清的，甚至是“朝令夕改”的。敏捷方法强调持续交付就是为了使用户早期得到反馈，**及时修正他们的需求**，更好的管理客户的期望，避免开发出不符合客户真正预期的产品，浪费开发资源不说也浪费了客户的投资。软件的静态模型是关于大的软件职责的拆分和交互边界，这一部分不仅是当前进一步开发的基本依据，日后万一需要重构也是很重要的参考，值得花力气仔细讨论达成一致，减少日后维护成本。
+
+软件的部署和核心模块的交互在有这方面的变更的时候（新加入模块或者服务等）也需要仔细考虑并作为软件设计的关键活动。模块的边界是粗粒度的系统耦合的地方，一些关键的交互流程也适宜详细讨论并放在软件设计文档中。
+
+系统核心的模块/类以及之间的交互，如果有发生变更，也需要第一时间考虑清楚并放置在设计过程中产生合适的产出，便于沟通和交流。如果模块的粒度足够大（譬如估计有很多的代码），那么哪些部分是对外交互的接口也应该提早考虑清楚，并提取出来以便后续写代码以及代码评审的时候对照，确保设计被正确遵守。
+
+## 什么时候应该停止继续设计？
+
+敏捷语义下，任何的浪费都是可耻的，代价巨大的设计工作自然也不例外。知道何时还需要仔细讨论搞清楚，何时应该停止变得尤其困难，甚至需要一些接近于艺术化的方法，**需要经过大量的实践经验累积和反思**才能做到不偏不倚。
+
+如果发现所讨论的问题可能代码实现很容易就能完成，如果考虑不完备，那么修改代码的代价非常小，那么就可以立即停止了；因为设计的目的是为了更好的写代码，更好的维护既有的代码。因此只有重构代码的代价远远大于预先仔细设计付出的代价是，才应该花费力气去做这些烧脑的工作。发现代码实现已经很容易没什么问题的时候，就放手去写代码或者重构代码吧。这种情况往往发生在我们想去“设计”一些内部实现细节，而这些细节对模块的边界以及待修改模块和核心部分耦合很小的情况。
+
+如果是在构建一个新的模块，而这个模块和已有的系统有形形色色的复杂联系（耦合），那么如果这个模块和已有的系统的各个部分的交互已经比较清楚，而且其内部实现估计工作量也很小的时候，那么就可以放心将剩下的工作交给聪明的程序员去继续了。将一些**细微的工作也放入设计中，只会使设计文档变得庞大而又难以维护**。毕竟可工作的代码比完美的文档更重要，虽然后者也很有价值。
+
+如果对于是否应该继续设计有分歧，可以和其它准备实现的程序员坐在一起讨论（其实任何时候都应该如此，如果团队规模比较小而且时间允许），看将要写代码的程序员是否觉得足够清楚，返工的风险是否足够得小。如果对于一些核心的模块或者类的职责还有不同的认识，或者程序员不知道某些改动是应该新创建一个子包，还是应该在已有的摸个包中修改来实现，那么**很可能有些关键的部分没有设计**清楚。
+
+决定何时应该适可而止也和你的程序员团队的**实际水平和能力**密切相关。一群天才程序员可能需要极少的设计来达成基本的共识就可以产出高质量易维护的代码，而水平平庸的程序员团队则需要更多设计上的预先讨论沟通以达成基本共识，减少返工。
+
+## 工具
+
+软件工程的一个关键要素就是工具。软件设计自然也离不开合适的工具，尤其是软件设计又是对需求进行抽象的结晶；选择合适的工具可以增进协作和沟通，使得设计输出是有实际指导作用的而不仅仅是纯粹的文档工作。
+
+**轻量级的文档工具**往往使维护和修改变得更加容易，因为设计输出本身也是一个迭代的过程；便于多人评审和协作显得尤其重要。目前主流的方式基本都是基于Markdown和Plantuml的；前者可以用来存放文本，后者则可以用文本的格式来描述UML图。
diff --git a/_posts/2017-06-04-kotlin-language-functional-programming.md b/_posts/2017-06-04-kotlin-language-functional-programming.md
new file mode 100644
index 0000000..23f649f
--- /dev/null
+++ b/_posts/2017-06-04-kotlin-language-functional-programming.md
@@ -0,0 +1,212 @@
+---
+layout: post
+title: Kotlin语言之函数式编程
+date: 2017-06-04 22:32
+comments: true
+categories: [language, programming, fp]
+tags: [kotlin, programming, language, fp]
+---
+
+[Kotlin语言](https://kotlinlang.org/)是大名鼎鼎的JetBrains公司（就是可以甩Eclipse数条大街的IntelliJ IDEA背后的公司）出品的现代的编程语言，之前已经在IDEA中蹦达出来很多次了；只是最近随着Google在其[2017年的I/O大会上将其列为Android平台官方支持的语言](https://techcrunch.com/2017/05/17/google-makes-kotlin-a-first-class-language-for-writing-android-apps/)而窜上了热点。
+
+本文尝试从函数式编程的角度管窥Kotlin的特性。
+
+## JVM上的函数式语言生态
+作为一门比较年轻的编程语言，要想在既有的数百种语言中脱颖而出，成功吸引开发者的心，对新的[函数式编程范式](https://en.wikipedia.org/wiki/Functional_programming)的支持是必然不可少的 - 这一点基本成为语言出品商心照不宣的潜规则了，当然在21实际，不支持面向对象的范式也是说不过去的。
+
+作为基于JVM平台的语言，和Java的互操作性肯定是一个重要的优势，当然这方面已经有成熟的函数式语言[scala](https://www.scala-lang.org/)和更早一点的[clojure](https://clojure.org/about/rationale)在前。可能比较遗憾的是，正统的函数式编程风格太难被传统的OO程序员所接受，因此基于传统Lisp的clojure一直曲高和寡，scala在近年来有变得更加流行的趋势，只是目前看来[仍然没有跨越期望的引爆点](https://dzone.com/articles/the-rise-and-fall-of-scala)。
+
+### 有丰富的特性还希望有速度
+传统印象中的静态函数式语言的编译速度往往会比较慢，这一点在工程实践上是个很重要的因素。
+
+Kotlin作为后来者，其开发者认为静态语言的编译速度是个至关重要的，然后Scala的编译速度远不能令人满意。对大型的项目而言，笨拙的编译速度浪费的可是大量的时间和金钱；毕竟天下武功唯快不破，更快的编译时间意味着更快的反馈周期，更多次的迭代开发。Kotlin的目标之一是期望编译速度可以像Java一样快，[benchmark分析](https://medium.com/keepsafe-engineering/kotlin-vs-java-compilation-speed-e6c174b39b5d)也表明了二者的速度是差别不大的。
+
+## 基本特性
+函数式语言的基本元素就是function，这一点kotlin倒是没有玩太多花头。用`fun`关键字来声明函数，函数是第一等公民，可以支持函数作为参数，返回函数等基本特性。
+
+### 不可变类型支持
+Kotlin强制要求程序员声明某个特定的变量是否是可变类型。
+
+如果是可变类型，则需要用`var `来声明；那么后续程序中任何地方访问变量都会被IDE给highlight出来，提醒可能的副作用。因为可变类型意味着内部存储着状态，从函数式编程的角度来看，状态会**影响函数的纯度**，带来副作用和复杂性。
+
+![immutable_hints.png](http://upload-images.jianshu.io/upload_images/5275528-e33afde1447172d5.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)
+
+### 函数声明
+基本的函数声明是这样的 
+```kotlin
+fun thisIsAFunction(x: Int) : Int {
+}
+```
+当然这里的类型后置语法和传统的C家族语言有些不同，但是适应起来倒也不是难事儿。
+
+### 类型推导
+Kotlin也支持强大的类型推导，从而在很多情况下，可以省略不必言的类型指定，简化代码；譬如函数的返回类型可以被自动推断的时候，其类型声明可以被省略。
+
+### 特殊的返回类型 `Unit`
+`Unit`是一个特殊的类型，用于指定某个函数返回的值可以被省略，类似于Java8的`Void`类型。如果一个函数没有返回值，那么可以指定其返回`Unit`或者直接省略其返回
+
+```kotlin
+fun someFunc(arg: SomeType) : Unit {
+    // do something with arg
+    // no return needed
+}
+
+// same as above
+fun someFunc(arg: SomeType) {
+    // do something
+}
+```
+
+### 中缀表达式
+中缀表达式写法更替进人的思维习惯，在定义某些操作符的时候是非常有用的。此用法往往用于扩展已有类型的操作，定义的时候需要满足以下条件
+- 属于某个类的成员函数，或者是定义某个类的扩展函数(后边再回头来看)，因为这里我们**必须知道左侧的操作对象**是谁
+- 必须只有一个函数参数（操作符后边的对象）
+- 用`infix`关键字来标记
+
+譬如
+
+```kotlin
+infix fun Int.shl(x : Int) -> Int {
+  /// implementation of shl operation
+}
+
+// call site
+1 shl 2
+```
+
+### 命名参数和默认值
+这点和Python很像在多个参数的复杂函数的使用上有很大帮助，能极大提高可读性减少维护成本。调用方可以在调用点指定需要传入的参数的名字；也可以省略掉不需要指定的参数。
+
+譬如有如下的`reformat`函数用于格式化
+
+```kotlin
+reformat(str,
+    normalizeCase = true,
+    upperCaseFirstLetter = true,
+    divideByCamelHumps = false,
+    wordSeparator = '_'
+)
+```
+
+调用点可以简单写作
+
+```kotlin
+reformat(str, wordSeparator = '_')
+// equals to
+reformat(str, true, true, false, '_')
+```
+
+这个功能在传统的C++/Java里边没有提供，但是IDEA提供了只能提示可以弥补Java的不足；而Kotlin则将其内置在语言中了；本身没多少复杂性在里边。
+
+## 高阶函数和语法糖
+
+### 高阶函数
+函数的参数可以是一个函数，这个在Kotlin的库里已经有大量的例子，譬如基本的`Sequence`的filter函数携带一个谓词函数，其针对给定的参数返回一个` Boolean`
+```kotlin
+public fun <T> Sequence<T>.filter(predicate: (T) -> Boolean): Sequence<T> {
+    return FilteringSequence(this, true, predicate)
+}
+```
+
+### 单参数函数的表达式形式
+当函数只有一行实现的时候，可以省略其函数体，直接用`=`来书写，就像复制给一个变量一样
+
+```kotlin
+fun add2Numbers(x : Int, y: Int): Int = x+y
+```
+
+### Lambda和匿名函数
+匿名函数用大括号括起来，上面的例子也可以写作
+
+```kotlin
+val add2Numbers2 = {x : Int, y: Int -> x+y}
+```
+
+### 函数调用的形式省略
+当函数仅仅有一个参数的时候，其参数名字默认为`it`保留关键字可以不用显示指定。
+
+当函数的最后一个参数是一个函数的时候，其函数体可以用`{}`块的方式来书写，获得更好的可读性。
+
+譬如如下的例子用于打印指定数目个偶数
+
+```kotlin
+val printEvens = { x: Long ->
+    IntStream.range(1, 10000000)
+            .filter { it%2 == 0 }.limit(x)
+            .forEach { println(it) }
+}
+```
+
+### 一个具体一点的例子
+
+假设要实现如下功能的函数
+1. 遍历某个目录树
+2. 找出所有符合条件的文件夹
+3. 取其文件绝对路径
+4. 归并为一个字符串列表返回
+
+可以通过如下几个函数完成
+```kotlin
+fun extractAllDomainDoc(dirName: String) {
+    File(dirName).walkTopDown().filter { isDocDir(it) }
+            .map { it.absolutePath }.toList()
+}
+
+private fun isDocDir(file: File): Boolean {
+    return file.isDirectory && isDomainDocDir(file)
+}
+
+private fun isDomainDocDir(file: File): Boolean {
+    return file.absolutePath.split(File.separator)[file.absolutePath.split(File.separator).size - 1] == "doc"
+}
+```
+这里每个函数的含义都是比较清楚易懂的。如果利用上述的省略规则，那么可以更简略的写为
+
+```kotlin
+fun extractAllDomainDoc(dirName: String) = File(dirName).walkTopDown()
+        .filter { isDocDir(it) }
+        .map { it.absolutePath }.toList()
+
+private fun isDocDir(file: File) = file.isDirectory && isDomainDocDir(file)
+
+private fun isDomainDocDir(file: File) = file.absolutePath
+        .split(File.separator)[file.absolutePath.split(File.separator).size - 1] == "doc"
+```
+
+## 类型扩展函数
+Kotlin 支持对已有的类型添加扩展，值需要在任何想要的地方添加想要的功能，则原有的类型即可像被增强了一样具有新的功能，该机制提供了OO之外新的灵活的扩展方式。
+
+譬如默认的Kotlin的`Iterable`类没有提供并发的`foreach`操作，可以通过扩展机制很容易的写出来一个使用`ExecutorService`来并发循环的版本
+
+```kotlin
+// parallel for each, see also https://stackoverflow.com/questions/34697828/parallel-operations-on-kotlin-collections
+fun <T, R> Iterable<T>.parallelForEach(
+        numThreads: Int = Runtime.getRuntime().availableProcessors(),
+        exec: ExecutorService = Executors.newFixedThreadPool(numThreads),
+        transform: (T) -> R): Unit {
+
+    // default size is just an inlined version of kotlin.collections.collectionSizeOrDefault
+    val defaultSize = if (this is Collection<*>) this.size else 10
+    val destination = Collections.synchronizedList(ArrayList<R>(defaultSize))
+
+    for (item in this) {
+        exec.submit { destination.add(transform(item)) }
+    }
+
+    exec.shutdown()
+    exec.awaitTermination(1, TimeUnit.DAYS)
+}
+```
+
+这里在函数体中，`this`自动会绑定于被扩展的对象。
+
+如果我们想实现一个自动将一大堆plantuml文件转换为png格式并copy到指定目录，因为默认的plantuml的API是单线程的，我们可以基于上述的parallelForEach实现来并发调度UML的生成过程，对应的代码可以写为
+
+```kotlin
+markDownFileLists.parallelForEach {
+    SourceFileReader(File(it)).generatedImages.firstOrNull()?.apply {
+        copyFileToDirWith(this.pngFile.absolutePath, getCopyTarget)
+        println("${System.currentTimeMillis()} - Created png for $it")
+    }
+}
+```
diff --git a/_posts/2017-06-05-kotlin-variable-invariants.md b/_posts/2017-06-05-kotlin-variable-invariants.md
new file mode 100644
index 0000000..0e1a953
--- /dev/null
+++ b/_posts/2017-06-05-kotlin-variable-invariants.md
@@ -0,0 +1,175 @@
+---
+layout: post
+title: Kotlin语言之变量约束设计
+date: 2017-06-05 23:12
+comments: true
+categories: [language, programming, design]
+tags: [kotlin, programming, language,fp]
+---
+可变状态的泛滥往往被认为是软件维护灾难的元凶之一，尤其是当过程封装遇上多线程，普通的面向对象编程技巧完全不堪大用，因为**继承/封装/多态等手法针对的都是程序组织上**的处理措施，具体到底层实现上，传统的C/C++/JAVA依然依赖**过程式实现跟操作系统打交道**。
+
+## 函数式编程里的副作用
+在函数式编程的世界里，事情会变得很传统的过程式处理不一样，因为这里非常讲究函数本身是否是**有副作用**的，如果**同样的输入不能保证相同的输出**，那么则是有副作用的。这里的输出不仅仅表示返回值，还隐含其它形形色色的对环境的影响，包括
+
+- 申请但是没有释放的内存
+- 向操作系统请求占用共享资源如网络套接字
+- 屏幕输出，磁盘占用等
+
+## 为什么要区分副作用
+
+显然，副作用引入了**额外需要程序员维护**的状态，而传统的线程库或基本的OS机制将其完全交给了程序员负责。从而导致在多线程编程环境下，复杂的问题随着状态的增加成**指数上升**。状态意味着有共享资源需要维护，当有并发执行的进程或是线程的时候，为了保证正确的程序语意，则不得不引入锁(昂贵的操作)和竞争，从而制约性能。无锁算法通过CAS+重试机制，可以**部分缓解锁的开销**，却不能从本质上解决问题。
+
+无副作用的函数则是天然适合并发的，因为没有共享自然可以并行不悖地执行，问题不是完美解决了吗？然而**现实世界总是不允许绝对完美二字存在**的，纯粹无副作用的函数几乎一无是处，因为它本质上没什么用，什么也做不了。
+
+退而求其次的想法是，能否尽量隔离两者的实现，然后又可以优雅地将二者集成起来完成实际功能？**HASKELL用其优雅的monad抽象**回答了这个问题。然而对于抽象思维能力不是那么强（或者没有那么好数学基础）的程序员而言，**Monad实在是太阳春白雪**了而难以接近；想更加接地气一点的程序语言无一不选择和Monad保持距离，即使某些构造和设计的思想就来源于Monad, 譬如随处可见的Optional，基本的map/reduce链式操作等。
+
+对于这些没有显示引入monad的非纯函数式语言来说，严格的隔离就显得有些太激进了。取而代之的相对折中一点的**平庸**策略是语言机制本身提供某些基础机制，剩下的怎么用这些基本机制，一切由程序员自己来定夺。
+
+## kotlin的语言层面基本机制
+
+kotlin通过关键字 `val` 来声明**只读**的变量，用 `var` 来声明可变量。任何函数只要引入对可变量的使用，则其本身就是有明显的副作用的。然而一个变量声明为只读，仅仅表示在其对应的作用域中，不允许修改此变量的值，并**不意味着实际指向的数据对象本身是不可变**的， 因为在可能有其他的地方使用 `var` 的方式来操作此变量，或者有显示的方式将一个 `val` 的变量转换回可变的 `var`。
+
+考虑下边的例子：
+```kotlin
+// field1 是只读的，在本class中不允许修改它
+class SomeClass(val field1 : SomeType, var field2 : Int) {
+   fun doSth() {
+       // can only modify field2, but not field1
+   }
+}
+
+//calling site
+var someTypeInst = SomeType()
+val obj = SomeClass(someTypeInst, 112)
+// someTypeInst can still be changed by others! Not recommended!
+obj.doSth() 
+```
+虽然`someTypeInst`是以只读方式传入`obj` 的，然而并不能保证没有其它的线程并发地修改实际的对象，如果发生这种情况，**程序员仍然需要保证数据的一致性和安全**。 
+
+### 只读变量的初始化
+
+显然不可变变量则仅仅能够初始化一次，后续使用中不能再修改了。这样也带来一些限制，譬如在 `init block` 里想一次性初始化某些资源然后将其设置为在class内部是只读，则无能为力。一种变通的方式是将其设置为 `var` 类，然而这样做我们就损失了只读约束；另外一种做法则需要使用property构造来封装。
+
+
+## 核心集合类
+kotlin对来自JAVA的集合类库进行了二次封装，清晰地划分了只读集合类和可变集合。
+
+### 接口定义
+常用的集合类接口在`kotlin,collections` 包中被重新定义 ( 源码中位于 `Collections.kt` )
+```kotlin
+package kotlin.collections 
+//...
+// by default not mutable
+public interface Iterable<out T> {//... }
+
+// mutable iterable supports removing elements during iterating
+public interface MutableIterable<out T> : Iterable<T> {//...}
+
+//Only read access to collection
+public interface Collection<out E> : Iterable<E> {//...}
+
+// Supports read/write operations
+public interface MutableCollection<E> : Collection<E>, MutableIterable<E> {//...}
+```
+
+具体的集合类接口则选择从以上接口中**选择对应的**来扩展实现，因而对同一个类型有两种实现，分别是只读的 (没有前缀) 的和可变类型 (**用 Mutable 做前缀区分**) 。譬如 `List` 类就定义为 
+
+```kotlin
+// Read only list interface
+public interface List<out E> : Collection<E> {//...}
+// Mutable list
+public interface MutableList<E> : List<E>, MutableCollection<E> {//...}
+```
+
+需要注意的是，实际的具体实现类是复用Java中的定义，可参考collection包中的 `TypeAliases.kt` 文件
+
+```kotlin
+package kotlin.collections
+//...
+@SinceKotlin("1.1") public typealias ArrayList<E> = java.util.ArrayList<E>
+```
+默认的集合操作以及Streams API返回的大部分是不可变接口对象。
+
+### 集合类扩展/工具函数
+除了使用默认的JDK实现来生成具体集合类对象，Kotlin标准库中同时提供了大量的封装函数方便程序员使用，某些来源于对JDK的直接封装，有一些则是直接inline实现。
+
+譬如返回空list的包装和初始化形形色色的list
+```kotlin
+/** Returns an empty read-only list. */
+public fun <T> emptyList(): List<T> = EmptyList
+
+/** Returns a new read-only list of given elements.  */
+public fun <T> listOf(vararg elements: T): List<T> = if (elements.size > 0) elements.asList() else emptyList()
+
+/** Returns an empty read-only list. */
+@kotlin.internal.InlineOnly
+public inline fun <T> listOf(): List<T> = emptyList()
+
+/**
+ * Returns an immutable list containing only the specified object [element].
+ * The returned list is serializable.
+ */
+@JvmVersion
+public fun <T> listOf(element: T): List<T> = java.util.Collections.singletonList(element)
+```
+
+生成可变List的函数封装大多也是清晰明了 , 并且有很多种类的封装，使得就地生成 List 的工作大大简化；大部分情况仅仅需要**使用已有的函数**即可，不需要发明新的轮子
+
+```kotlin
+/** Returns an empty new [MutableList]. */
+@SinceKotlin("1.1")
+@kotlin.internal.InlineOnly
+public inline fun <T> mutableListOf(): MutableList<T> = ArrayList()
+
+/** Returns an empty new [ArrayList]. */
+@SinceKotlin("1.1")
+@kotlin.internal.InlineOnly
+public inline fun <T> arrayListOf(): ArrayList<T> = ArrayList()
+
+/** Returns a new [MutableList] with the given elements. */
+public fun <T> mutableListOf(vararg elements: T): MutableList<T>
+        = if (elements.size == 0) ArrayList() else ArrayList(ArrayAsCollection(elements, isVarargs = true))
+```
+
+其它集合类  (set/map等) 的实现原理**大概类似**，可以通过查看对应源码。
+
+### 不可变集合转换为可变集合
+很多场景下，API返回的都是不可变集合，将其变成一个可变对象再行编辑修改是常见不过的变成任务；kotlin 通过其**自身的扩展机制**将这些工具函数自动添加到了对应的集合类上
+
+如果想要将一个只读的 `Array` 对象变为一个可变的 `MutableList`，那么其实现是通过重新初始化一个新对象实现的： 
+
+```kotlin
+// Below code is copied from generated standlib as _Arrays.kt
+//  see https://github.com/JetBrains/kotlin/tree/master/libraries/stdlib
+
+/**
+ * Returns a [MutableList] filled with all elements of this array.
+ */
+public fun <T> Array<out T>.toMutableList(): MutableList<T> {
+    return ArrayList(this.asCollection())
+}
+```
+
+对于具体的Array类，有不同的实现，如 `ByteArray` 的初始化方法则有所不同，直接调用其构造函数，然后注意添加现有的各个元素
+```kotlin
+/**
+ * Returns a [MutableList] filled with all elements of this array.
+ */
+public fun ByteArray.toMutableList(): MutableList<Byte> {
+    val list = ArrayList<Byte>(size)
+    for (item in this) list.add(item)
+    return list
+}
+```
+之所以如此，是因为具体这些子类是被映射到具体的 JVM 对象上的。如ByteArray的文档如是说 
+> public final class ByteArray defined in kotlin
+> An array of bytes. 
+> When targeting the JVM, instances of this class are represented as `byte[]`.
+
+而对于CharArray，则其映射到`char []`类型上去。
+
+## IDEA支持
+作为官方的IDE环境，IDEA对可变量的引用做了显示的**下划线**提醒，程序员可以一目了然地看到代码中对可变量的使用。
+
+然而想要更深入的查看整个实现调用链中，哪些引入副作用哪些没有，工具的支持就比较有限了。
+
diff --git a/_posts/2017-06-21-welcome-to-jekyll.markdown b/_posts/2017-06-21-welcome-to-jekyll.markdown
deleted file mode 100644
index 91291dc..0000000
--- a/_posts/2017-06-21-welcome-to-jekyll.markdown
+++ /dev/null
@@ -1,25 +0,0 @@
----
-layout: post
-title:  "Welcome to Jekyll!"
-date:   2017-06-21 13:13:39 +0800
-categories: jekyll update
----
-You’ll find this post in your `_posts` directory. Go ahead and edit it and re-build the site to see your changes. You can rebuild the site in many different ways, but the most common way is to run `jekyll serve`, which launches a web server and auto-regenerates your site when a file is updated.
-
-To add new posts, simply add a file in the `_posts` directory that follows the convention `YYYY-MM-DD-name-of-post.ext` and includes the necessary front matter. Take a look at the source for this post to get an idea about how it works.
-
-Jekyll also offers powerful support for code snippets:
-
-{% highlight ruby %}
-def print_hi(name)
-  puts "Hi, #{name}"
-end
-print_hi('Tom')
-#=> prints 'Hi, Tom' to STDOUT.
-{% endhighlight %}
-
-Check out the [Jekyll docs][jekyll-docs] for more info on how to get the most out of Jekyll. File all bugs/feature requests at [Jekyll’s GitHub repo][jekyll-gh]. If you have questions, you can ask them on [Jekyll Talk][jekyll-talk].
-
-[jekyll-docs]: https://jekyllrb.com/docs/home
-[jekyll-gh]:   https://github.com/jekyll/jekyll
-[jekyll-talk]: https://talk.jekyllrb.com/
diff --git a/_posts/2017-06-24-migrate-blog-to-jekyll.md b/_posts/2017-06-24-migrate-blog-to-jekyll.md
new file mode 100644
index 0000000..1bcb8d4
--- /dev/null
+++ b/_posts/2017-06-24-migrate-blog-to-jekyll.md
@@ -0,0 +1,139 @@
+---
+layout: post
+title: Migrate blog to Jekyll
+categories: [ blog ]
+tags: [ blog ]
+---
+之前本blog的内容是基于强大的[octopress](http://octopress.org/)生成为静态站点，然后将生成的内容静态拷贝到 github-pages 上去的。当octopress的作者宣布重构后的[新版本预告](http://octopress.org/2015/01/15/octopress-3.0-is-coming/)后便急冲冲上去升级了本站内容，可惜很多插件都不工作了。眼见2年多过去了，貌似正式的3.0版本还没有被宣布，官方页面的帮助依然停留在2.0版本时代。
+
+很明显，**octopress项目要死了**，这在开源软件社区是常有的事儿；但是活人不能被尿憋死，本来用octopress的目的也是因为 Jekyll 太抽象了想顺带找个近路学习学习前端知识；这些没有了借口，还是升吧。
+
+<!--more-->
+
+## 上新版本Jekyll，安装主题
+
+最开始用octopress的时候，Jekyll还是 0.6 版本；这么多年过去，Github 团队官方已经发布了 3.0 版本了，功能支持的已经比较完善了。本身Jekyll是基于 gem 的，模块化做的非常好了，不像原来的 octorpess 直接fork一个代码就在里边改来改去，还要创建多个branch 防止无法升级的问题。按照 [官方文档](https://jekyllrb.com/docs/installation/) 的步骤按部就班即可。
+ 
+Jekyll支持**丰富的插件**，生成好对应的site之后，修改配置文件就可以用 `bundle update` 来安装。但是默认的Jekyll主题太过于原始，所以找个适合自己口味的主题是首要的。因为本blog是托管在github上的，gith-hub pages [支持的主题](https://pages.github.com/themes/) 却**比较有限**, 而且要没没有提供预览，要么提供的预览不适合个人口味。
+
+回头看Ocotpress发现其实现方式完全是自己生成页面的，不用Github自己的build系统；这里可以很容易的依法炮制，自己将所有的东西编译好，将生成的site内容给传上去即可。个人还是比较喜欢原来的 Octorpress提供的默认主题，简洁明快；所以最终选择的是 [Minimal Mistakes](https://mademistakes.com/work/minimal-mistakes-jekyll-theme/) ；浏览选择过程中，对 [Feeling Responsive](http://phlow.github.io/feeling-responsive/)主题也非常入眼，只是看起来文档比较复杂，可以留待以后尝试折腾下。
+
+Minimal Mistake主题支持比较多的设定，因为打算自己生成页面，所以采用类似fork的思路，安装**自己想要的插件**（可以突破[Github-Pages的限制](https://pages.github.com/versions/))，最后build成页面给push上去即可。
+
+## 自动同步
+
+由于是自己手工编译生成静态内容，所以很希望有类似于Octopress的Rakefile，遗憾的是**copy下来的Rakefile**不能正确执行。Google上search了一圈发现没有现成的方案，而且Github-pages的个人站点仅仅**支持push到master分支**, 而~~早期的时候是push到gh-pages~~分支的；这个细微的更新貌似很多google页面都没有提及；不过好在也不是很难发现，仅仅需要在自己site的设置页面查看build的分支就可以看到只能接受master分支了。
+
+自动化的工作最终写了个简单的shell脚本来完成, 基本的步骤是沿用 Octopress2 的步骤，设置2个入口
+1. 一个用于初始化一个deploy目录，和github的站点内容保持同步，初始化git和remote等等。
+2. 另外一个用于每次更新内容，调用 `jekyll build` 完成编译后，将生成的内容全部copy到deploy目录下，然后再同步到github的repository
+
+```bash
+#!/bin/bash
+deployDir=$(pwd)/_deploy
+siteDir=$(pwd)/_site
+siteUrl=https://github.com/skyscribe/skyscribe.github.io.git
+
+function setup() {
+    rm -fr $deployDir
+    mkdir -p $deployDir
+    cd "$deployDir"
+    git init
+    echo "dummy content" > index.html
+    git add .
+    git commit -m "dummy script init"
+    git branch -m master
+    git remote add origin "$siteUrl"
+    echo "Setup complete for $deployDir"
+}
+
+function deploy() {
+    bundle exec jekyll build
+    cd "$deployDir"
+    cp -r "$siteDir"/* "$deployDir/"
+    git pull origin master
+    git add -A
+    now=$(date "+%Y-%m-%d_%H:%M:%S")
+    git commit -m "site updated at $now"
+    git push origin master --force
+    echo "deploy completed"
+}
+
+case $1 in
+  setup)
+	    setup
+        ;;
+
+    * )
+        deploy
+        ;;
+esac
+```
+
+## 数据搬运
+
+相对来说数据搬运不是很困难就是比较繁琐，原来很多Octopress支持的插件，在这里都得自己检验是否不工作或者是否有合适的插件可以替代。期间的过程就是不断的**测试驱动**搬运，发现编译出错后，打开`--trace`开关，看问题出在什么地方然后一一修改之。最麻烦的一个问题是 gist 插件貌似产生了不兼容，原来的 `include_file` 插件也没法再用，只好将文件内容copy过来，用Liquid的 `highlight` 和 `include` 标签，套用如下的模板 
+
+{% raw %}
+    {% highlight html %}
+        {% include code/include.html %}
+    {% endhighlight %}
+{% endraw %}
+
+## 插件和定制
+
+没有了github的插件束缚，就可以装自己想要的插件了
+1. jekyll-compose 可以用**命令行来生成新的post**，类似于之前的octopress的命令行
+2. jekyll-archives 可以用来生成归档页面，方便使用
+
+默认的blog页面用的是post layout，但是默认没有定义，简单起见，自己在 `_layout` 下边加一个就行，从默认的single.html拷贝过来修改一下即可。
+
+### Tag cloud
+Octopress的tagcloud插件，找了一圈也没找到好的，仿照别人家的，写了个简单的 tagcloud.html 
+
+{% raw %}
+    {% assign all_tags = site.tags | size %}
+    <h3>
+      <a href="{{absolute_url}}/categories/index.html">Categories</a>
+    </h3>
+    <div class="tagCloud">
+      <ul>
+      {%for tag in site.categories %}
+      {% assign category_name = tag | first %}
+      {% assign cat_count = tag | last | size %}
+      {% assign cat_avg = cat_count | div: all_tags %}
+      <li>
+      <span class="tag">
+          <a href="{{absolute_url}}/categories/{{ category_name | downcase}}/index.html">{{ category_name }}({{ cat_count }})</a>
+      </span>
+      </li>
+      {% endfor %}
+      </ul>
+    </div>
+{% endraw %}
+
+稍微定制下需要显示的地方，将上述html给include进去即可。
+
+### 布局调整
+页面在高分辨率的屏幕下感觉空白太多，进入 `_sass/minimal-mistakes` 修改即可，代码相对比较清楚
+- `_variables.scss` 包含一些全局变量的定义，譬如字体大小，缩进，padding等
+- `_sidebar.scss` 包含对边栏的样式定义
+- `_masthead.scss` 指定主头部元素的样式定义
+- `_page.scss` 包含页面主要内容部分的样式定义
+
+大概对着浏览器窗口调整即可，无需赘述。
+
+## 未尽事宜
+还有一些其它的问题暂时没找到解决方案，暂时不折腾了，先列在这里。
+
+#### 无法删除的老页面
+之前的blog采用的是octopress的URL设置，当在新的主题里，将permalink依法炮制的时候，发现更新的页面没有被github正确重新加载，依然显示的是老的页面。无奈之下，只好修改一下permalink的前缀部分，强制生成不一样的页面。问题是老的页面依然可以访问。
+
+#### 页面布局
+默认的布局中有很多*额外的padding*没法去掉，尤其是PC的分辨率比较高的时候，页面右侧的边框显得特别大；用Chrome的Inspect工具打开可以看到右侧的padding有16%之多，然而修改附带的css并不能生效。
+
+## 参考链接 
+1. [How I migrated my blog to Jekyll/Github](http://rafabene.com/2015/10/11/how-migrated-blog-jekyll-github/)
+2. [Include partial snippets of code](https://hblok.net/blog/posts/2016/10/23/jekyll-include-partial-snippets-of-code/)
+3. [Raw tag plugin to prevent liquid from parsing given text](https://gist.github.com/phaer/1020852)
+
diff --git a/_posts/2017-06-27-excessive-null-checks-in-java-defensive-programming.md b/_posts/2017-06-27-excessive-null-checks-in-java-defensive-programming.md
new file mode 100644
index 0000000..8a8ef6d
--- /dev/null
+++ b/_posts/2017-06-27-excessive-null-checks-in-java-defensive-programming.md
@@ -0,0 +1,210 @@
+---
+layout: post
+title: Excessive null checks in Java Defensive Programming?
+categories: [programming, language, design]
+tags: [programming, java, design, patterns, fp, language]
+---
+
+最近在参与某开发小组的[团体代码审查](https://atendesigngroup.com/blog/group-code-reviews)会的时候，发现组内的一线开发工程师对于何时应该做空指针检查并没有很清晰的认识；然而这在Java社区里早已经是个老生常谈的争论 。
+
+<!--more--> 
+
+按照最偷懒的做法 (毕竟[懒惰是伟大程序员的美德](http://threevirtues.com/)之一)，可以对使用的对象不做检查，那么万一该指针为空，则运行期抛出的空指针异常**默认行为就会将程序给crash掉**，你的用户会很不高兴，你公司的客户会不高兴乃至投诉你的研发老板，你的老板会更加不高兴甚至于愤怒以至于半夜将你叫起来加班解决问题；试想当你拖着睡眼惺忪的躯壳爬到办公室查看日志，迷迷糊糊一看，原来是有个地方的对象引用是null指针，没有做判断导致JVM退出了。那么最自然的方案是添加个判断了，原来的代码可能是 
+
+```java
+someObj.doSth()
+```
+现在被改成了
+```java
+if (someObj != null) {
+    someObj.doSth()
+}
+```
+后边可能出现了新的问题，那么你可能依法炮制，继续加上更多的分支判断。对于简单的代码片段而言这样做没什么问题，足够清晰易懂；只是实际的业务逻辑代码可能布满了各种各样的业务判断，再掺入这类判断代码，**可维护性立刻直线下降**。这时候可能有个聪明的程序员跳出来说，我们不是有[防御性编程](https://en.wikipedia.org/wiki/Defensive_programming)大法吗，可以来的更彻底一些，**干脆对所有的传入对象做空指针检查**不就可以了吗？
+
+乍看起来似乎很有道理，转而仔细想一下就会发现这里**有很大的隐患**。上述的检查其实对每一次对象的调用其[复杂度](https://en.wikipedia.org/wiki/Cyclomatic_complexity)就会增加1，实际的业务代码里，一个类往往**引用了很多对象**，每次都要去做判断很快使代码变得难以维护，尤其是考虑到一些稍微复杂一些的方法可能有多个出口的情况，条件判断的增多会直接导致内部状态变得难以分析。本质上对某个方法的实现上下文来说，当前**所有的成员对象和传入的上下文参数对象**是否为null的状态都需要按照这个策略去来判断，在没有明确的前置条件约束的情况下，具体实现的业务逻辑会被埋藏在各种繁杂的空指针检查中难以理清。
+
+显然对所有的对象引用做空指针检查不是一个明智的主意。那么是否有什么方法可以减少这些检查或者有其它的提高可读性的变通之道吗？
+
+## 哪些情况需要判断空指针
+
+为了探讨这个问题，我们可以详细列举一些可能需要判断的情况逐一分析一番就能做到心中有数了。因为Java语言中一切皆是对象(当然基本类型不算)，所有对象都由某个class给构造出来，所以我们**仅仅需要讨论class中涉及到的对象**即可。
+
+### 成员对象 (field)
+一个Java类的基本元素是其成员引用 (其实是对象指针) ，因为从成员对象开始探讨是个不错的主意。Java语言本身允许两种类型的成员对象：
+
+#### 在构造中被初始化过的成员对象
+构造中初始化的对象，其是否为null指针其实跟该类的设计密切相关，因为构造方法是对象"出生"的地方；其实现直接决定了构造出来的对象的内部状态。这种情况下，对象是否为null是个**比较关键的设计决策**之一。
+
+对于这些纯粹是被使用到的对象(即其生存周期不由本class决定)，**只接受合法的构造参数并确保总是生成带有非null引用**的成员对象，会大大减少类内部需要检查空指针的情况。这样类的职责也很容易做到单一而明确；对应的其它方法里边就无需判断某个成员对象是否为null，当然如果其他的方法中会修改某个成员为null，那么情况会变得复杂 - 当然这种情况下出现的时候，往往意味着某些方法之间在使用成员对象来存储中间状态，很可能这些方法之间的隐式依赖需要仔细分析重构。
+
+如果构造方法中的传入**参数非法而导致某些成员对象没法被正常构造**出来，那么我们的确可以采用防御式编程的思路，在构造里抛出来异常即可。当然这里有些Java语言特殊的情况需要仔细考虑，譬如是否需要抛出**待检查异常**还是非检查异常；并且在抛出异常的时候需要仔细小心留意没有资源泄露的情况，因为Java里没有C++中的RAII的概念，如果抛异常前已经分配的资源没有合适的释放(必须是手动的), 那么**调用者永远也没有办法处理**！
+
+尽管有以上诸多细微之处需要留意，在构造方法中考虑好对象的初始状态约束，是减少不必要的null指针检查的第一步(可能也是非常关键的一步)。
+
+#### 没有在构造中初始化的成员对象
+没有在构造中初始化的成员对象，可以有几种不同的情况。然而毕竟**不能确保初始化对象的方法在什么时候被调用**了(除非有合适的设计约束)，因此成员方法中用到该对象的地方，都需要做空指针检查，否则就有可能出现意外的异常。当然详细的分析一下具体的场景也有助于我们做更深入的分析。
+
+一种常见的典型场景是通过`setter`方法来初始化的对象，从纯粹面向对象设计的角度来考虑，简单的`setter`方法其实是**破坏封装**的，应该尽量避免。然而一种合理的情况是希望解决类之间的环形初始化依赖的情况，譬如依赖注入框架中的`setter injection`；当然环形依赖的情况之所以出现，往往意味着没有仔细的遵循[基于接口编程](https://stackoverflow.com/questions/383947/what-does-it-mean-to-program-to-an-interface)的原则。即使需要用，也应该尽量避免滥用。
+
+还有一种常见的情形是在两个相互关联的方法之间传递中间状态；这种情形还可以再仔细甄别 - 如果是在两个共有方法之间共享状态，那么需要仔细考虑为何不在构造方法中设置好初始状态，也许[空对象模式](https://en.wikipedia.org/wiki/Null_Object_pattern#Java)是个值得考虑的好主意。如果是在两个私有方法或者是一个公有方法和其内嵌的私有方法之间传递状态，那么往往意味着代码的实现出现了**坏味道**，因为方法实现之间传递隐式状态很可能意味着本**类的职责过多需要拆分**出来新的类，或者是用空指针来传递控制流程迁移，这类不必要的空指针检查完全可以避免；因为私有方法可以看作是实现细节的隐藏，在实现内部具体的状态迁移都应该是严格受控的，要么通过合理的参数来传递，要么考虑好具体场景而不宜随意传递可能为空的对象。
+
+### 静态成员对象 (Field)
+
+静态对象是个和全局变量类似的问题，其初始化的时机其实已经超出了具体类对象的范围，会和其他的类产生**明显的强耦合**。因而静态成员对象应该尽量去避免，如果真要使用，确保其生存期被正确的管理，譬如使用依赖注入框架等。
+
+### 方法传入参数对象
+方法传入的参数对于方法的实现体而言是外部输入，因此也值得仔细判断。
+
+#### 公有方法中的参数对象
+显然共有方法中引入的参数对象是由调用者指定的，方法实现中需要考虑好什么样的参数是允许的，是否允许空指针传入；如果不期望空指针传入，那么可以在**类设计中考虑进去并写入JavaDoc**，用具体上下文信息封装一个合适的异常传递给调用者，并保证方法调用前后，类的状态仍然是合理而符合预期的。如果允许方法中的某些参数对象为null，并依据是否为null执行不同的行为，那么建议应该尽量避免这样的设计, 空指针控制业务流程和常规的直觉不符,完全可以通过其他方式传入，或者增加新的公有方法或重载版本。仔细考虑之后，仍然决定允许为空指针，**同样要在JavaDoc中写好**，方便你的用户。
+
+#### 私有方法中的参数
+私有方法往往是为想隐藏公有方法中的实现细节而准备的。显然由私有方法中引入的null类型参数是在实现某个公有方法的封装中引入的；由于公有方法的参数中没有带入这类空指针（见上述讨论），那么出现的空指针参数必然是由实现逻辑的过程中传入的；这**往往意味着实现中出现了不自然的设计**，这种情形和上述的共有方法传入空指针还不一样，因为私有方法的用户始终是这个类的某个公有方法（或者是其基类)，那么更没有理由不去重构了。
+
+##### 一个具体的例子
+譬如某个类有如下的实现方法
+
+```java
+class SomeClass {
+  //....
+  public void doSomeThing(SomeParam param) {
+    //do something but not check param!
+    if (someConditionMet()) {
+      doSomeLowlevelWork(param, null);
+    } else {
+      //construct another param returns a new valid param
+      doSomeLowLevelWork(param, constuctAnotherParam());
+    }
+    //....
+  }
+
+  private void doSomeLowlevelWOrk(SomeParam param, AnotherParam anotherParm) {
+    //!oops, have to check param & anotherParam
+    if (param == null) {
+      //dosomething 
+      return;
+    }
+
+    if (anotherParam == null) {
+      //do something special
+    } else {
+      // do something as normal
+    }
+  }
+}
+```
+这里的公有方法没有检查其传入的参数就直接将其传入了一个更底层的实现，并且显示的传入了另外一个null指针作为某个特殊的条件逻辑;这里的空指针用于决定底层实现逻辑的分支选择其实引入了不必要的跨逻辑层次依赖，属于比较明显的代码坏味道，可以将其重写如下 
+
+```java
+  //...
+  public void doSomething(SomeParam param) {
+    if (param == null) {
+      //do something special
+      return
+    }
+
+    doSomeLowlevelWork(someConditionMet(), param);
+  }
+
+  private void doSomeLowlevelWork(boolean conditionMet, SomeParam param) {
+    //Now I'm sure no null passed in!
+    if (conditionMet) {
+      //do some thing without another param
+    } else {
+      AnotherParam anotherParam = constructAnotherParam();
+      //do something else with another param, no null objects!
+  }
+```
+重构后的版本将外部传入参数的判断放在公有方法的顶层处理，来确保相对底层的私有实现中不引入额外的空指针，取而代之的是具体的业务逻辑条件判断；代码的可读性显然有了良性的变化。
+
+##### 例外情况
+
+凡事总有例外，这里毫无疑问也存在一种特殊的情况，即是在实现[模板方法模式](https://sourcemaking.com/design_patterns/template_method)的时候，在基类中将空参数给传递进来了；这种情况下**如果不能修改基类的代码，那么依然不得不做处理**。
+
+譬如在一个抽象类中定义了模板方法操作 
+
+```java
+public abstract class AbstractBehavior {
+  
+  //both firstParam and secondParam can be null, but not checked in below public API
+  public void doSth(Param firstParam, AnotherParam secondParam) {
+    doStep1(firstParam);
+    //certain other handling
+    doStep2(secondParam);
+  }
+
+  abstract void doStep1(Param firstParam);
+  abstract void doStep2(AnotherParam secondParam);
+}
+```
+
+在一个具体的实现类中，因为抽象类未做检查，子类实现必须检查父类传入的参数
+
+```java
+public class ConcreteBehavior {
+  @Override
+  void doStep1(Param firstParm) {
+    //have to check if firstParam is null or not!
+  }
+
+  @Override
+  void doStep2(AnotherParam secondParam) {
+    //have to check if secondParam is null or not!
+  }
+}
+```
+
+话说回来，继承一个无法修改代码的基类可能往往不是一个很好的注意，这种情况下，[使用组合而不是继承](https://en.wikipedia.org/wiki/Composition_over_inheritance)可能是一种更好的方法，如果可以的话；因为从代码的耦合上来说，**继承关系是一种很强的耦合**以至于所有父类中的不良设计会被所有的子类所继承，形成无形的约束。这也许是我们需要始终对以高复用为目标的框架保持谨慎的原因。
+
+### 外部对象
+
+所谓的外部对象是这些在某个方法实现中被引用到，却并没有被类如方法传入参数，也没有被放在成员对象列表中的对象。当然如果出现这种情况，往往是全局对象的引用（要么是静态全局对象，要么是单例对象）。然而不管哪种情况下，你的class已经悄无声息地引入了**隐式依赖**，而隐式依赖在大部分情况下引入的问题比解决的问题要多。
+
+对于这类对象，如果用现代的依赖注入方案来解决，很自然它们就和普通的成员对象没什么区别了。关键的问题是需要考虑好，是否真的必须引入这类隐式依赖就可以了，绝大部分情况下，**显示依赖比隐式依赖要好**。当然去掉了隐式依赖后，一个额外的好处是你的测试将变得更加容易了，因为不需要特殊的mock或是Stub来设置上下文了；只需要构造被测试对象的时候安插好构造参数即可。
+
+## 变通之道
+啰嗦这么多，看起来很多地方可能还是不可避免需要去做空指针检查。是否有办法做个变通，既保证逻辑正确，也能确保代码维护性不被破坏？其实回头仔细想一下，之所以有空指针异常这回事儿，根本上还不是因为**Java用异常机制来非正常情况的**处理吗，从这个角度出发，其实我们还有这些选择 
+
+1. 用返回值而不用异常 - 然而我们是在讨论Java，虽然依然可以用返回值对象，或者类似C或者golang的error code的方式，但是如果你以这种方式写代码，其实**可维护性的负担反而加重**了,顶多是少了一些花括号而已
+2. 使用**新的编程范式**，没错我们还有[函数式编程]({{site.baseurl}}/categories/fp/index.html)可以选择，因为Java8已经给我们送来了这个大礼 - Optional
+
+### Optional
+Java8新引入的[Optional](https://www.mkyong.com/java8/java-8-optional-in-depth/)类型提供了不同于传统基于返回值或者基于异常的新的错误处理机制。一个Optional类型是一个包装类型，其封装了原有的对象类型，但是在对象的状态上，允许表达该对象**要么是存在要么是不存在**的概念。表面上看起来和传统的null没有太明显的区别，然而两者之间有很大的不同
+
+譬如同样一个可能为空的对象上的一个多步骤操作，传统的方式可以写为 
+
+```java
+ResultType result = someObj.doSth();
+if (result != null) {
+  return doSomethingWith(result);
+} else {
+  //exceptional handling code, other return
+  return doExceptionalHandling();
+}
+```
+
+如果换用Optional封装则可以写为
+
+```java
+return Optional.ofNullable(someObj.doSth())
+    .map(result -> doSomethingWith(result))
+    .orElseGet(() -> doExceptionalHandling());
+```
+
+- 传统的空指针或者返回值方式返回的对象是不同的类型，程序员必须**对返回值做类型相关的处理**，从这种意义上说，返回值方式(包括空指针)提供的相对低层次的封装，毕竟对于C++/Java这类强类型语言而言，不同的变量类型相关处理意味着底层语言基础设施和应用业务逻辑这两个不同层次的抽象被混杂在同一个层级的代码范围内
+- `Optional`类型提供的是统一的对象类型封装，你可以对该类型做相对更高层次的封装，根据你具体的业务逻辑写出声明式的代码
+
+### 隐藏在Optional中的模式
+从上面的示例代码可以看出，Optional类其实提供了关于一些基本过程逻辑的封装，使得使用者可以**站在更高的层次写代码**，关于一些基本的分支判断等过程逻辑控制，Optional提供了一些模式给程序员来调用，使得程序员可以更加关注在业务逻辑上，减少程序语言的底层实现细节的纠缠，同时又**不丢失静态语言带来的编译器检查**的便利。
+
+当然Optional类型本身是一个封装类，作为函数式编程中的一个模式在Haskell中它是[一种具体的`Monad`抽象]({{ site.baseurl }}{% link _posts/2012-04-15-haskell-functor-and-monad.markdown %})，其提供的方法提供了各种各样关于封装对象的高层操作，包括过滤器/映射/异常处理等，可以实现更复杂而高级的操作，这里不再赘述；细节可参考Optional的使用。
+
+### Java8的 Type Annotation
+其实在Java8中，新引入的类型注解针对空指针问题提供了另外的处理方式，即通过指定`@Nonnull`，编译器可以用于检测某个代码路径中有可能接受到空指针的情况，从而避免程序员处理空指针异常。IntelliJ IDEA提供了贴心的提示建议插入这个annotation从而帮助我们写出更整洁的代码。
+
+## 参考引用
+1. [Defensive programming, the good, the bad, the ugly](http://enterprisecraftsmanship.com/2016/04/27/defensive-programming-the-good-the-bad-and-the-ugly/)
+1. [Is it a good practice to make constructor throw exception](https://stackoverflow.com/questions/6086334/is-it-good-practice-to-make-the-constructor-throw-an-exception)
+1. [Composition over inheritance](https://en.wikipedia.org/wiki/Composition_over_inheritance)
+1. [Java8 new type annotations](https://blogs.oracle.com/java-platform-group/java-8s-new-type-annotations)
diff --git a/_posts/2017-07-14-missing-connections-by-socket-accept.md b/_posts/2017-07-14-missing-connections-by-socket-accept.md
new file mode 100644
index 0000000..749b518
--- /dev/null
+++ b/_posts/2017-07-14-missing-connections-by-socket-accept.md
@@ -0,0 +1,128 @@
+---
+layout: post
+title: TCP服务端socket会丢连接的诡异问题及思考
+comments: true
+categories: [linux, programming, debugging, design]
+tags: [linux, programming, netty, java, debugging, design]
+---
+最近在跟踪项目的性能测试的过程中，发现了一个奇怪的问题：**Netty服务器端新建的Channel的数目比Tcpdump抓包得到的经历过三次握手成功的连接数要少**：
+总有几个连接从抓包来看成功，然后Netty并没有为其分配Channel。直观上来看，似乎是Netty的处理问题值得怀疑，似乎是用于接受新连接的线程池堵塞了。
+
+深入追踪下去，发现问题不在Netty身上，而是**操作系统没有通过IO事件反馈给**应用程序(Netty)导致了丢连接的情况出现。经过更深层次的思考后，
+问题之所以出现，还与我们的协议设计不太合理有关。
+
+<!--more-->
+
+## 问题发现和定位
+
+项目的服务器端和客户端之间采用的是基于**TCP长连接**的应用层自定制协议；协议的基本工作流程如下
+1. 服务端监听在事先设置的服务端口上；用Netty的`ServerBootstrap`来封装服务器端的监听`socket`处理;其内部封装了`listen`和`accept`等底层API
+2. 针对每个连接上来的客户端，Netty会创建一个新的SocketChannel,其初始化方法中会初始化应用层的协议处理
+（即一些列的`ChannelHandler`对象）来负责对应连接上的IO事件以及应用层逻辑
+3. 连接建立成功后，客户端会处于Idle状态，**等待服务器端发起第一条消息**，初始化应用层握手。
+4. 客户端收到握手消息后，确认相关信息，之后即进入正常的协议交互处理
+
+项目的初始设计目标是需要处理**最多20000条并发连接**;这个性能指标应该说不算特别高，因为业界早就实现了从[C10K到C100K](https://qunfei.wordpress.com/2016/09/20/from-c10k-to-c100k-problem-push-over-1000000-messages-to-web-clients-on-1-machine-simultaneously/)的跨越。
+当然任何**性能指标如果不加以测试的话，都是假把式**。为了验证该目标，我们设计了**针对性的性能测试模拟器**, 并设计了一个测试并发建链接的测试用例；
+其目的是模拟多个逻辑上没有依赖的客户端同时发地发起大量的连接，验证服务器端是否能满足预设计的健壮性和可靠性要求。
+
+当上述第二步模拟器端以每秒近1000条连接的配置从本地环回端口(loopback)发起并发连接的时候，实际走到第三步的连接数有**一定的概率**少于1000个，
+而模拟器端显示所有的连接都成功建立。所有的网络通信都是从127.0.0.1这个本机IP地址在不同的应用程序之间周转的，可以直接排除网络不稳定的干扰。
+
+### 对模拟器和Python的傲慢与偏见
+
+由于模拟器的主框架是用Python语言写成的，一开始大家都怀疑是否是[Python性能缺陷的原罪](http://jakevdp.github.io/blog/2014/05/09/why-python-is-slow/)导致的；
+毕竟Python的性能一直为人诟病；只是任何怀疑都必须找到切实的证据，必须做小心的分析和求证；具体到这个问题上，还是找一些中间的分析结果来的容易一些。
+
+两端都查了一堆的log之后最终也没有太多实质性的发现，最后大家还是决定看tcpdump的抓包，并过滤TCP协议的初始握手包更为简单直接，
+只是过滤器的设置稍微复杂一点；google一下不难找到。
+
+### 网络协议分析是最强有力而值得信赖的
+Tcpdump的抓包分析表明，每次这些连接全部都建立成功了,统计TCP握手的3个步骤的时候，
+不管是初始的SYN(0)包，还是服务器返回的SYN(0)+ACK(1)包，以及第三次握手的ACK(1)包都完全发送成功。
+这也就意味着，从TCP/IP传输层的角度来看，第二步其实已经全部完成。客户端是无辜的。
+
+问题就仅可能出现在服务器端了；接下来就是尝试修改Netty的源码加入更多的打印来观察其是否调用了`ChannelInitializer`对连接上来的客户端初始化ChannelHandler。
+仔细看下来，居然是Initializer的数目就根本不对。
+难道是Netty的实现有问题吗?作为一个在开源业界关注度如此之高的一个项目，我们采用的还是其非常成熟的4.0版，出现这种低级错误的可能性实在太小；虽然一切皆有可能。
+
+### 排除Netty的嫌疑
+
+稍微阅读Netty的代码后，发现并没有特别的逻辑漏洞 - 它默认采用的是异步IO模型，用`select/poll`模型来做连接的多路复合(Multiplexer);即使有传说中的[CPU空跑的问题](https://github.com/netty/netty/issues/2616),看了代码之后发现对应的问题在新版本中早已fix掉了。
+
+保险起见，我们又尝试[换默认的NioEventLoop为Linux本身的Epoll](http://netty.io/wiki/native-transports.html)，问题依然没有得到解决。从行为上来说，
+epoll机制也仅仅能解决效率高低的问题，**并不应该解决行为不一致**的问题。
+
+回想到我们采用的线程模型上，server socket上的事件循环还承担着应用层程序和协议栈交互的任务（我们通过UserEvent的方式向对应的pipeline上发事件来避免数据同步），
+默认的单线程处理这些应用层事件的处理方式是否会导致效率低下也是一个值得验证的点；等到增大了线程数之后，问题依旧没有什么眉目。
+和上面的处理机制类似，这样的方式也只是从效率的思路出发尝试解决问题，**逻辑上依然是无法解决行为不一致**的问题。
+
+### 从操作系统的角度分析
+
+转了一圈，发现问题还是出在`listen`调用和`accept`的交接的地方；这里实际的TCP行为是发生在Linux的内核空间的；逻辑上其内部也是有个类似的异步队列，
+对进来的TCP连接请求，内核会设置相关的socket状态，分配相关的数据结构，自动完成TCP协议的握手过程，待到握手完毕之后，将这个连接成功事件通知给应用层（select/epoll)；
+然后应用层可以检查对应的socket读事件，调用`accept`获取新的socket文件描述符。
+
+这一系列过程都是异步的，并且跨用户空间处理和内核空间调度。
+确定了可能出问题的地方，查找的方向就比较明确了；只需要找找可能影响server socket的行为就可以了。
+此时一个可以的关于SO_BACKLOG的设置引起了我们的注意,因为这里设置的值是`8`，尝试调大这个参数后，丢连接的情况突然消失了。
+
+### 检查socket选项 - `backlog`设置
+
+上述的参数是从Java的API中继承来的，实际设置的时候，其实也是传给了JDK的对应的参数；引用JDK的参数说明
+> The maximum queue length for incoming connection indications (a request to connect) is set to the backlog parameter. If a connection indication arrives when the queue is full, the connection is refused.
+
+这里比较奇怪的是，当队列满了之后，从抓包的角度来看，**对应的连接并没有被拒绝**，而是显示连接成功了！如果后续没有任何数据交换(`send`/`receive`)的话，
+对应的socket(以及操作系统分配的相关资源)其实也悄然泄露了?可是真会有这么低级的问题吗？
+
+既然有此疑惑，还是仔细翻阅一下Linux的`listen`的manpage为好；搜索`backlog`选项,对应的说明如下
+
+> The backlog argument defines the maximum length to which the queue of pending connections for sockfd may grow.  
+> If a connection request arrives when the queue is full, the client **may receive an error** with
+> an indication of ECONNREFUSED or, if the underlying protocol supports retransmission, **the request may be ignored**
+> so that a later reattempt at connection succeeds.
+
+不确定这是否是一个bug，因为客户端测并没有检测到这个`ECONNREFUSED`的错误而是显示连接成功。
+StackOverflow上有人提了[类似的问题](https://stackoverflow.com/questions/37609951/why-i-dont-get-an-error-when-i-connect-more-sockets-than-the-argument-backlog-g)，
+合理的解释是，因为TCP支持重传，所以该请求**仅仅是被忽略了**，直到下一次连接过来的时候，对应的连接会直接成功！
+
+要保证这样能工作，操作系统也必然需要在某些地方保存已经分配好的socket（以及相关的数据结构）以便下次可以通过`accept`取到。
+
+### 如何解决和避免再次发生
+对设计用来处理比较高的并发处理请求的服务器程序来说，设置`backlog`选项为比较小的值是个比较糟糕的主意，更容易"踩上这个坑"。也许这也是默认情况下，
+Linux将这个值设置为128的原因；如果想修改它，最好**设置的比128更大一些**。
+
+由于这种情况在连接状态的backlog缓冲满了之后，再有新连接完成三次握手之后就可能出现，设置再大的值，理论上来说都不是足够保险;除非我们能提前预测或者限制客户端的行为，
+避免大量的并发连接上来，或者让客户端能检测到这种情况。
+
+考虑到实际环境中，**这种情况出现的概率还是很低的**，只有在基于内网的模拟器环境下，才会有这么“巧合”的情况出现;
+在不能修改客户端行为的情况下，将该选项的值修改大一些即可有效地降低其出现的几率。
+
+要想彻底解决这个问题，单单从socket层面来看，应该是吃力不讨好的事情，因为行为的不一致发生在
+操作系统的系统调用和用户程序的交互的地方；一个可行的思路是从更高层的应用层及时检测这种情况；这样的解决方案需要应用协议层面的特别处理才行。
+
+## 对协议设计的影响
+由于问题发生的场景比较特殊一点，具体来说有以下必要条件
+
+1. 多个客户端在短时间内发起大量的并发连接
+2. 服务器端接收新连接的**内部队列长度设置比较小**，以至于某些完成握手的连接在客户端重试的时候直接返回成功
+3. 这些由于队列满而引入的默默完成的连接不被服务器应用程序所知道（没有新的IO读事件）
+4. 连接建立**成功之后，客户端处于静默状态，等待服务器端发起第一条消息**，从而从应用逻辑角度看，双方进入了“死锁”状态
+
+其实从根本上解决该问题的方式是避免第四个条件的出现；有两种方式可以凑效
+- 永远保持让客户端发送第一条协议消息，或者
+- 客户端在连接建立之后即发送业务层的心跳 - 这一机制在应用层有心跳支持的情况下变得更清晰
+
+## 一点额外的总结和感想
+做技术的很容易对某些特定的技术产生“宗教式”的虔诚或“魔鬼式”的憎恶，技术偏见也会由此产生，并蒙蔽我们的视野，导致我们掉进一些坑里。
+一开始的时候我们对Python的想当然的偏见耽误了不少的时间来检查是否模拟器的实现是否出了问题；幸好我们及时发现这种直觉上的错误；
+顺利找到问题的根源。
+
+看起来很复杂的问题，根源往往在很小的一个基础的知识点上；
+对操作系统底层处理机制的积累和对基本TCP/IP协议的实现的了解极大地节约了我们分析和解决问题而耗费的时间。
+这些最基本的东西，其重要性怎么强调都不为过，应该作为程序员的基本功保持长期不懈怠。
+
+应用层网络协议的设计和实现上；**遵循惯例和技术直觉**(Least Surprise)总是没有太大错误；当初我们设计协议的时候，选择让客户端等待服务器发送第一条消息，
+虽然有一些感觉奇怪的地方，由于其它种种原因，当时没有仔细去考虑；最终在做性能测试的时候，就有问题爆出来狠狠地咬了我们一口。
+幸好这类问题还没有被真正的客户所发现就被我们“扼杀”在实验室测试中！
+
diff --git a/_posts/2017-08-22-performance-tuning-with-java-flight-recorder.md b/_posts/2017-08-22-performance-tuning-with-java-flight-recorder.md
new file mode 100644
index 0000000..c48f70d
--- /dev/null
+++ b/_posts/2017-08-22-performance-tuning-with-java-flight-recorder.md
@@ -0,0 +1,212 @@
+---
+layout: post
+title: 用Java Flight Recorder来调优JVM性能
+comments: true
+categories: [programming, debugging]
+tags: [programming, tuning, java, debugging, performance]
+---
+
+随着Java程序在后端压倒性的普及，其性能本身早已经无人质疑；然而一个经常不为人道的事实是，Java平台上的程序不是天然就具有很高的性能；
+因为Java语言显著降低了程序员的准入门槛，真正到系统性能这一块，仍然需要大量的调试和优化，即所谓的JVM性能调优。
+
+Java Flight Recorder（后文简称JFR）是Oracle官方推出的商业环境的性能调优利器；其本身对运行期系统的侵入性很小，同时又能提供相对准确和丰富的运行期信息；
+合理使用改工具可以极大地提高工作效率。本文就个人工作环境中的一些实际使用情况做一简单的总结。
+
+<!--more-->
+
+## 基本工作模型和采样
+
+JFR本身是基于周期性对JVM虚拟机的运行状况进行采样记录的，其采样的频率可以通过其参数传入;只是需要留意的是，采样间隔越小对系统的性能干扰就越大。
+和传统的JProfiler/VisualVM这些基于JMX的工具所不同的是，JFR记录的信息是**近似而非精确**的；当然大部分情况下这些**模糊性信息就足够说明问题**了。
+对于大部分场景下，这些近似信息反而可以更容易发现一些真正的问题。
+
+要想使得JFR能够产生采样信息，首先需要确保你采用的JVM是Oracle的JVM，否则JFR也不认识虚拟机的内部工作机制；此外还需要在JVM的启动参数中开启商业特性的开关，
+并开启JFR；相关选项很容易在官方文档里找到，这里就不赘述了。
+额外需要注意的一点是，你必须有**Oracle的商业使用许可**，否则是不能用的。
+
+开启JFR选项后，有两种方式可以产生采样文件以便时候分析
+- 在启动参数里指定启动后即开启采样；这种方式对于想分析启动时候性能的情况非常有用；只要在参数中指定采样间隔，时间以及保存的文件路径即可
+- 通过`jcmd`的JFR命令来按需产生采样；该方式更适合在程序启动之后按需产生采样。Oracle JDK自带的Java Mission Control程序可以挂在本机上运行的Java程序上做观测，
+本质上也是这种机制。
+
+产生的采样文件可以在本地机器上使用Java Mission Control工具打开做事后分析。
+
+## 哪些信息被采样保存
+基本上所有有用的信息都被保存下来了；最主要的概要信息保存在`General/Overview`里边。
+
+### General面板
+
+以下是一个具体的CPU在某段时间出现繁忙的例子，这种采样在繁忙的后端服务器上可能是比较常见的，因为大部分情况下我们需要**尽可能占尽可用的CPU时间来追求更高的吞吐率**。
+当然如果CPU已经满负载运行，而吞吐量又不太理想的时候，详细深入的分析就变得更为重要。
+![an example program's overview with hot cpu](/assets/images/jfr/jfr_overview.jpg)
+
+首先映入眼帘的是一个常常的时间轴和系统时间图，开始时间和结束时间都可以按需选择；
+如果选定了synchronize selection,则所有的**信息显示都会随着选择范围的变化而实时刷新**。
+这一机制非常灵活有用，因为很多时候我们都需要根据基本分析和直觉印象去选择某些特点的时间来对比观察。譬如在追求高吞吐率的场合，发现CPU没有用满但是吞吐率有上不去的时候，
+可以选择CPU有锯齿的地方，详细去查看特定的时间点内发生了什么。
+
+接下来的三个大大的仪表盘会给出Java的堆内存、CPU使用、GC停顿时间的平均值和最大值；从而可以看到系统在给定时间内，JVM的内存/GC情况和CPU利用概况。
+
+最下方的部分则会显示一个更详尽的CPU使用图表曲线，在任何一个时间点（依采样频率而定）机器总的CPU利用率、JVM和用户程序在用户态、内核态的CPU使用情况。
+对于追求高吞吐率的后端程序而言，这些信息值得仔细查看。
+
+最后一部分则显示了JVM的概要信息，包括其启动时间，JVM的具体版本等。除了这个概要页面，还有2个总体的标签页，分别显示具体的JVM命令行选项（包括默认没有设置但是传入给JVM的项），
+JRE环境的属性和变量，采样记录信息如线程上下文切换计数的时间间隔等；这些信息在分析一些具体的性能参数的时候，是很重要的参考。
+
+### 内存面板
+由于Java中的内存分配和回收是JVM帮助程序员做的，Java性能调优的很大一部分工作是和内存调优密切相关的。
+内存面板则是根据运行期的采样数据将JVM的GC相关的数据汇聚显示出来；和其它的类似，同样是顶层的时间轴曲线可以依据选择来同步其他图表。
+
+中间的部分显示详尽的内存使用概览，包括总共可用的机器物理内存、已经使用的物理内存、提交给OS的堆空间、已经使用的对空间等。
+锯齿状的曲线就是已经使用的堆空间随着GC的活动而动态变化的历史。如果图表中出现**比较粗的“柱子”**图样，则表明GC的工作情况需要具体仔细查看了。
+
+最下栏则显示了当前GC的配置情况，如初始、最大的堆空间大小，不同的代的空间分配、GC活动的统计技术以及空间分配的概要情况。
+大部分情况下，我们更多关注运行过程中间的**GC统计指标**，包括总共的收集次数，最小、最大以及平均的停顿时间；
+这些数值当然都是越小越好了；因为任何的GC活动都会挤占应用程序的可用资源。
+
+#### GC活动信息和收集细节
+一些额外有效而更细节的信息则会显示在单独的标签页中，包括这么几类
+- 垃圾收集详细信息：所有的GC活跃情况，以ID为标号详细地显示出对应的停顿时间，收集的类型，回收的原因，开始/结束时间，以及统计性的最长停顿时间等。
+这些信息很多和**具体的GC算法是密切相关**的
+- GC的停顿情况：同样针对的是每一个GC活动，针对具体的回收事件，对具体引用类型的收集停顿间隔以及相应停顿处理活动的开始时间信息等；
+虽然不能看出具体的回收对象，但也足以看出大概的整体停顿比例和时间，对耗时的GC活动**做定性的分析**还是足够有用的
+- 对象引用情况：简要的显示了某次GC活动的时候，各种类型的对象引用的个数，可以辅助上一项，提供了更细节一点的数量统计
+- 堆空间的变化情况：回收前后的堆空间情况，和`jstat`提供的信息一样
+
+下图是上面同一个采样的GC信息，其中可以看出GC的活动对于CPU繁忙时段的贡献是不大的，基本可以排除GC对性能的影响
+![GC activities](/assets/images/jfr/jfr_memory_gc.jpg)
+
+#### 详尽的GC时间统计信息
+GC时间统计页面则从时间的角度给出各个GC的代在收集过程中所占用的时间，最小、最长、平均停顿等。
+这些统计同样是按照新生代、老生代、以及所有的收集活动耗费的时间来呈现的。同样这些信息**和具体的GC算法是密切相关**的，需要根据GC算法的配置来综合使用。
+
+同样是上面的程序运行期的一个采样，其GC时间信息如下
+![GC times information](/assets/images/jfr/jfr_memory_gc_times.jpg)
+
+上述采样表面，大部分GC活动事件属于新生代GC，即回收临时对象的常规动作；老生代GC仅仅有3次，并且占用的时间并不算长。
+注意这里采用的是G1 GC算法，**老生代的回收并不会完全阻塞应用程序线程的运行** - 具体的时间信息可以结合应用程序的log时间戳打印综合确认。
+
+#### GC算法相关的具体配置细节
+GC算法的参数配置则可以在其相邻的标签页找到，它给出了更为详尽的算法配置参数，包括
+- 新生代、老生代对应的收集算法
+- 并发收集的线程个数 （可能对某些算法不适用）
+- 是否开启并发收集
+- 是否允许应用程序显式地调用GC
+- GC被允许运行的时间占所有可用CPU时间的比率的上限值（G1等新型的GC算法支持这种约束，防止GC过分活 跃）
+- 各个代的空间信息，包括初始空间大小、最小对空间大小、最大空间大小，以及对空间的地址大小、指针压缩情况和对象对齐情况（对**64位的Java程序尤为重要**）。
+新生代的配置还会提供诸如TLAB空间占用的情况和配置，以及默认隔多长时间会将仍然在引用的对象挪到老生代等信息。
+
+同样是上面的采样，其GC配置信息如下
+![GC parameters configuration](/assets/images/jfr/jfr_memory_gc_cfg.jpg)
+
+以上这些复杂的信息对于深入的内存分析和针对是非常宝贵的;
+譬如如果应用程序中生存期较长的对象并不多（面向对象设计提倡**大部分的运行期对象是朝生夕死**），然而老生代却有比较大的压力，
+就要怀疑是否是部分关键逻辑运行时间过长，导致经过数次新生代回收之后，仍然没有被释放出去，从而导致进入老生代被老生代的回收活动处理。
+
+### 代码面板
+
+代码面板则是基于采样得到的信息的代码执行情况给出统计分析结果。
+需要注意的是，所有的数据都是依据具体的采样点，具体的**线程当时正在运行的的函数调用栈的具体状态来计数**并累加的。
+
+比如某个调用栈有10次被捕获到，那么相应的栈上的所有的函数的计数都会被记为10；这样得到的结果和**实际代码的CPU占用率比较类似**，但是并不完全精确。
+所有的百分比数值都是相对百分比，其计算方法是用当前函数的采样数和整体（线程或全局CPU采样数）的采样数相除。
+
+#### 代码概览
+概览页面会显示按照Java的包情况统计的采样数和相对总体的百分比；可以按照具体的列点击排序。最下边的视图则显式热点的类列表。
+同样这些视图都可以根据选定的时间间隔来同步数据，使得我们可以方便的按照具体时间来分别查看CPU被占用在什么地方。
+
+对于上述的程序运行采样，以下是其代码概要视图
+![code overview](/assets/images/jfr/jfr_code_overview.jpg)
+
+可以看出在给定的CPU热点时间，有超过20%的采样都提取到了`java.util`包的活跃样本，紧随其后的是一个Guava的工具函数包以及用户程序的一个基础工具库。
+热点的类统计中，Java基本的Array类更是占据前列，这个在大规模的Java程序中是很常见的情况，同时也使得**深入的分析变得困难**而又必要，
+因为对Java基础库或API的调用是被层层封装过的。
+
+#### 热点方法
+
+热点方法标签则提供了基于调用栈的采样排序情况，可以点击具体的调用栈展开，具体查看可疑热点的调用情况从而做针对性的深入优化。
+同样地对于上述的采样，其热点方法如下
+![hot methods](/assets/images/jfr/jfr_code_hot_methods.jpg)
+
+显然繁忙的CPU活动依然发生在Java API的内部，排在第一的是Stream API的pipeline操作，逐级展开JDK的封装，最终还是能找到应用程序的调用点。
+同时每一个调用栈的右侧会显示对应的采样数和百分比。
+这里的Stream操作会在运行的时候被多个上层函数所调用，则每个调用栈极其采样个数都被显示出来，可以顺势点开查看详情。
+
+**基于80/20原则**，一般收效最大的是仅仅对占比最大的函数栈进行针对性优化；同时如果上一级函数的调用和字函数的采样个数不一致，说明函数内部的其它代码也需要仔细查看。
+最麻烦的情况是80/20原则不太明显的时候；此时我们**必须对多个可能的热点方法**做优化，耗费的精力和时间就会更多。
+
+回头看这个具体的例子，排行第一和第二的两个栈的采样数基本差不多，CPU时间耗费在哪里看起来似乎不是很明显;这是因为对应的采样是已经优化了一部分之后的中间结果。
+令人惊讶的是，Guava的Interner API也占用了相当多的CPU时间；在CPU已经满的情况下，针对性的优化就要麻烦一些。
+
+#### 热点的调用栈
+
+调用栈试图提供了和上述热点方法类似的信息，所不同的是其调用栈情况聚合了所有的API情况，譬如多个线程的同一个底层方法调用会被聚合在一起；
+这样更容易从一个系统性的视角去理解程序实际运行时候的概况。
+
+回到这个具体的采样样本，其热点调用栈如下
+![call trace](/assets/images/jfr/jfr_code_calltrace.jpg)
+
+可以看出大部分的CPU样本落在`Thread::run`方法中，这在多线程的后端程序中是最正常不过的情形了。具体展开来看，大部分的时间花费在了Netty的管线处理中；
+由于Netty的管线处理是采用调用链的方式逐级深入的，调用栈展开起来比较繁琐一点；最终展开的时候，可以看出这里的大部分CPU花费在了消息解码上。
+
+### 线程面板
+如今几乎所有的后端Java程序都是基于多线程的，运行期同时有数十乃至上百个线程在多核CPU上执行也是屡见不鲜的。
+各色各样的第三方框架、库都会创建各种`ExecutorServie`实例，依据负载情况动态的创建或者调度线程。
+
+线程面板从JVM线程的角度来分析采样的数据。其概要面板同样提供了最基本的CPU情况，并且支持根据时间选择来刷新其它标签页视图数据、表信息等。
+其线程信息则显示线程数量的历史信息，包括后台线程和活跃线程数等信息。
+
+#### 热点线程
+热点的线程显示在该标签页中，其中包含了丰富的信息
+
+![hot threads](/assets/images/jfr/jfr_threads_hot_threads.jpg)
+
+最上边的面板中显示地给出了线程上下文切换的频率；换算为多核的CPU就很容易看出来是否对应的采样时间内，CPU在忙于做上下文切换。
+如果开启了很多个用户线程，这些线程又有比较粗粒度的锁，那么上下文切换的开销就很客观需要考虑优化。
+比如这个例子中，在8个CPU核参与运算的情况下，CPU切换在2500多，平均Linux的10ms的时间片内，平均每个线程切换了3次多，属于比较正常的情况。
+
+具体的热点线程数据和其调用栈情况，可以依据采样计数排序后详细查看。这个例子中，String的`append`操作消耗了大量的CPU，这个也算是大规模应用程序常见的情况。
+
+#### 线程竞争
+同样是上边的运行其采样，线程的竞争情况视图为我们提供了更多关于CPU繁忙时候各个线程抢占CPU时间片的大概情况：
+
+![contention](/assets/images/jfr/jfr_threads_contention.jpg)
+
+这里依据具体的CPU事件，JFR为我们提供了三个子视图来呈现多线程运行期的细节信心
+- 竞争锁情况，按照其阻塞CPU运行的时间排序，分别显示了各个锁在给定的时间周期内等待的次数，最长、平均、总共的时间。一般时间越长需要优化的空间会越大，因为很多CPU时间被浪费在频繁等待和获取锁上边。具体的运行其堆栈可以在下方的细节视图中具体查看
+- 被阻塞的线程信息，列举了这些等待获取锁的线程的信息，时间、堆栈等
+- 阻塞其他线程的线程信息，和上一个类似，只是显示的是占有共享锁而阻塞了别人的线程的相关信息
+
+#### 时延和锁竞争情况
+线程的时延信息则从运行期所采样到的操作等待时间长短的维度呈现一些排序和统计信息，同样可以依据其数目、平均等待时间以及最长时间等因素来排序查看对应的运行其堆栈情况，如下图
+![threads latency](/assets/images/jfr/jfr_threads_latency.jpg)
+
+线程锁信息则反馈一些基于Java锁对象为中心的时间信息，对于同一个锁对象指针（底层地址空间的指针）其关联的所有线程的追踪信息，并显示出多个关联线程被采样到的次数信息。
+
+由于这些统计信息是基于操作系统内存地址的，**垃圾收集算法可能在运行清理操作的时候拷贝对象从而使得指针被重写，因此该信息不是非常可靠**,尤其是GC比较活跃的时候，某些应该被计数在内的线程活动会被计数到不同的实例上。幸运的是，JFR同样对给定的时间段内GC的活动情况给了个概要视图呈现在最下方。
+![threads locks](/assets/images/jfr/jfr_threads_lock.jpg)
+
+#### 线程Dump情况
+JFR会依据采样配置情况，定期保留当前所有线程的调用栈信息;由于堆栈保存对实际运行程序的影响比较大，JFR的默认策略是很长时间才会取样一次调用栈信息。
+
+对于时间比较短的采样，这个页面的信息很可能是空的。如果确定有必要（比如怀疑某些线程僵死的情况，可以通过设置采样参数让JFR提取更多的信息。
+
+### IO情况
+对于后端应用程序来说，系统性能的提升和IO活动密切相关因为大部分的程序运行瓶颈在IO上，
+即**快速的CPU处理速度和缓慢的IO活动之间的不可调和的矛盾**往往导致应用程序性能的下降;然而大部分的后端应用的**目标是追求更高的吞吐率**。
+
+当吞吐量上不去，而CPU的运行曲线又不太平稳（譬如有很多锯齿）的情况下，往往是IO的处理浪费了宝贵的运行时间;
+此时只要查看IO的情况，减少对程序逻辑的阻塞即可快速提升性能。
+如果CPU已经用满，而吞吐率又不太理想，则优化起来就困难重重了;当然这种情况下IO的行为还是值得查看的，
+因为不恰当的IO锁或者过多的IO操作仍然可能有潜力去挖掘，只是更加困难一些。
+
+IO事件按照其访问速度的差异一可以大概分为如下几类
+- 本地磁盘文件读写操作：其速度和物理磁盘的特性、文件系统以及程序所使用的API、框架等密切相关。典型地如频繁的log操作可能引起额外的小量的IO操作，如果这些操作是阻塞的，则程序的性能会下降比较厉害
+- 网络文件系统操作:这类场景往往对应用程序的逻辑是做了隔离的，但是在复杂多变的网络环境下很容易引起性能的急剧恶化;遇到这种情况尽快分析出原因是很关键的。
+- 网络通信读写（通过基于TCP/IP的各类协议的程序逻辑信息交换)：和网络文件操作类似，不同的是和应用层协议的设计和模式密切相关，对于大的系统而言，定位和分隔问题的边界是必不可少的。
+
+JFR对这些时间都分类列出其操作的时间信息，方便我们进一步定位和分析IO方面的问题。大部分情况下，IO里给出的信息都要结合线程乃至内存的情况综合判断。
+
+### 系统信息和事件
+
+**TBD**
\ No newline at end of file
diff --git a/_posts/2017-08-29-thinking-on-service-architecture.md b/_posts/2017-08-29-thinking-on-service-architecture.md
new file mode 100644
index 0000000..674510a
--- /dev/null
+++ b/_posts/2017-08-29-thinking-on-service-architecture.md
@@ -0,0 +1,150 @@
+---
+layout: post
+title: 架构服务化的一点思考
+comments: true
+categories: [design]
+tags: [programming, design, architecture, SOA, microservice, monolith]
+---
+
+微服务是个非常热门的话题，最近几年随着互联网的深入演进和云计算的逐渐普及，几乎所有的公司、技术社区、组织都是言必谈微服务；
+似乎没有微服务都不好意思说自己能保持技术能力的与时俱进了。这厢微服务还没有完全在实践中铺开，那边潮头Amazon又挑起了无服务器架构的大旗，引来无数人的关注。
+本文试图对这些概念和架构思想做一简单的分析和梳理。
+
+<!--more-->
+
+## 服务架构的前世今生
+考虑到微服务其实仍然是基于服务的架构方式，既然有“微”则必然有“宏”与之对应;只是之前大家都是直接叫基于服务的架构而已。
+
+### 没有服务的架构
+在软件工程的早期洪荒时代，所有的软件都是按照最原始的模块化思路组织和开发的;那时候编程语言基本是C/C++的，各个子部分之间采用头文件的方式来模拟相互之间的接口，源代码文件作为实现之间的隔离。
+这种情况下，各个逻辑**子部分的约束基本是比较弱的**，要么是依赖于组织内部的约定，要么是依赖于一些比较hack的方式。
+这种方式可以认为是基于内部API和调用约定的无服务的架构方式。应用程序要么是独立组织的，要么是通过API定义好接口，然后各个模块分别开发，再统一连接起来形成最终的可执行程序。
+
+这么做的弊端非常明显，因为接口的定义极大地影响系统集成的效率，以至于各个模块独立开发的时候没什么问题，一旦到了集成阶段则困难重重，迟迟不能发布出来。
+个人觉得这个问题的本质在于，**完美的API定义是非常困难的**，需要极高的技术能力和对问题业务领域的深刻分析。
+
+### Unix编程哲学
+
+[Unix哲学](https://en.wikipedia.org/wiki/Unix_philosophy)倡导如下的核心实践如下
+> 1. Write programs that do one thing and do it well.
+> 2. Write programs to work together.
+> 3. Write programs to handle text streams, because that is a universal interface.
+>
+> --Mcllory, inventor of Unix pipe 
+
+它推崇用多进程和管道的方式开发复杂应用，每个小程序负责一件事儿，进程之间采用管道链接输入和输出。
+由于程序之间的输入和输出缺乏统一的规范化，**Unix哲学推荐用基于文本的进程间接口**来组织程序，以便调试和分析、诊断等。
+
+美中不足的是，它对于**具体怎么实践这些基于文本的接口**却没有统一的建议或规定，文本格式却是需要被程序去理解的，其中应该包含这负责的业务逻辑而不是简单的计算机字符串，简单按照这种设计哲学去开发应用程序依然是困难重重。
+
+另外一个难题是，Unix程序都假设是基于单个物理机器的运行环境，因为早期的Unix都是大型机，它无法预料到后期廉价PC的崛起。
+各种围绕本地IPC机制设计的管道、系统信号等通信方式和TCP/IP的网络环境有很大的差异，导致代码并不能很好的复用。
+
+然而Unix设计哲学所推荐的这种**系统职责分割方式和基于文本的协议交互对后来的微服务有巨大的影响**。
+
+### 分布式对象技术
+90年代后期，微软提出了组件化开发的COM以及DCOM开发模型，使用接口来达到软件复用，最终程序通过接口定义和动态链接和查找实现分布式开发。
+而Java社区则走向了分布式对象的模式，提出了JavaEE并和C++社区的CORBA对象代理技术兼容。
+这种情况下，对象分布式技术的着眼点是基于OOA分析的划分。
+
+### SOA架构
+
+JavaEE提出也提出了基于服务的架构方式，它在很多场合也往往被成为**Big Web Service**,其典型特征如下
+- 复杂的系统被分割为一个一个相互通信的接口
+- 使用WSDL来定义服务和服务之间的接口的通信
+- 该**通信方式是基于HTTP+XML+SOAP封装**，消息模型为**基于请求/响应**的RPC模型，其中定义了消息通信的消息结构和通信端点抽象;
+支持通过工具将WSDL转换为对应的代码，简化接口编码、解码的工作量
+- 高级特性支持安全、服务注册和发现，以及多版本向后兼容等
+
+SOA极大地提高了企业应用开发的效率，采用SOA架构的软件曾被认为是面向未来的，当时的业界对SOA的期望一如今天对微服务的期许。
+
+它的**缺陷在于过于笨重**，部分原因在于XML本身的臃肿和复杂;实际场景中可能用于XML/SOAP解析和校验的开销变得过于巨大以至于性能很糟糕。
+XML过于臃肿的特性导致大家追求通过压缩消息来节省网络带宽以优化性能，然而压缩和解压反而需要消耗额外的CPU资源。
+另一部分则是因为JAX-WS规范的一些高级特性是可选的，而**某些特性是由跳过了HTTP协议直接在SOAP中实现**的;然而HTTP协议本身也提供了丰富的特性，弃之不用自然会导致资源的浪费。
+
+此外基于RPC的通信方式并不是在所有方式下都适合，因为其隐含的模型是同步的请求、响应;实际的业务逻辑都直接定义在这些接口中，造成**业务逻辑和接口直接产生了依赖**。如果频繁的因为需求变动导致WSDL接口定义变更，后向兼容又会变成一个沉重的负担。当然这个也是基于服务的方式必须要面对的问题。
+
+### WEB技术的发展和RESTful架构风格
+WEB技术在最近20年也经历了深刻的发展，从基于B/S模型的厚后端模型为起点，到基于Ajax（XML）技术的风靡一时，再到REST风格的以资源为中心的厚客户端模型，越来越多的业务逻辑被搬到了前端处理，MVC模型最终占据了大部分应用场景。
+
+RESTful风格的架构强调使用HTTP协议本身的语义模型，用HTTP的方法来描述资源的CRUD操作，用URL来规范操作的资源，
+接口定义上**采用资源为中心的方式有效地减小了和业务流处理的耦合**，相比传统的RPC方式相比，前后段的交互方式与业务流程的耦合更小，更有利于前后段独立发展。
+
+### 领域驱动开发
+Eric Evans通过他划时代的《领域驱动设计》一书将面向对象技术推向了新的深度;通过提倡业务统一语言，领域对象的识别和绑定上下文的分析等技术，
+实现了**软件架构能更好地随着业务的的变更而低成本的演进**这一需求。
+恰当的领域职责划分，以及领域专家和软件技术专家的通力合作和互相理解更容易生产出可维护、易扩展、更容易拥抱实际商业环境变化的系统。
+
+### 软件开发方法学和云计算基础设施革命
+敏捷软件开发和持续集成等实践在过去的近20年几乎席卷了软件开发领域的大部分角落。
+**持续发布以及DevOps运动**则进一步减小了软件开发的反馈周期，深刻地改变了大部分传统软件测试人员的工作方式和线上运维的成本结构。
+
+传统的先设计，再编码内部测试，最后再搞一个旷日持久的大集成及系统测试的开发模式再也不能适应追求快速响应的企业软件市场。
+**更快的设计、测试、发布上线速度**，成为影响企业成败的一个关键因素之一。
+
+云计算技术的日趋成熟将企业开发从传统厚重的基础设施维护工作中解放了出来。
+以往那种设计实现一个企业应用系统需要考虑诸多服务器部署、存储、安全、运营维护等一系列复杂的底层细节被少数提供云服务的大公司统一按需提供和管理;
+商业公司可以将研发精力聚焦在业务逻辑的部分更快地将产品推向市场，这也是**社会分工更加深化**的结果。
+容器技术（docker为代表）的飞速发展和原生云应用软件概念在不损失性能的情况下标准化了基础设施的管理和编排，极大地简化了中间件以及第三方组件的复用过程。
+
+## 站在巨人肩上的微服务
+从某些方面看，微服务架构可谓是站在巨人的肩上诞生的新的弄潮儿;
+它是在面向对象深入发展到领域驱动设计的基础上，随着WEB技术的深度发展和RESTful的日益流行而自然产生的。其特点和要求如下
+- 采用**业务领域特点来划分服务边界**，其基本思路是DDD的
+- 服务的**粒度要尽量的小**，符合Unix的编程哲学，每个服务只做一件事并将其做好;有的建议是一个服务最好能被一个小的开发团队（比如Scrum的5～7人模型）负责分析、设计、开发、测试、发布等所有工作。
+- **每个服务是一个进程**，对外提供基于RESTful风格的HTTP服务（也有基于Protobuf的gRPC微服务框架）
+- 服务接口提供多个版本，每个服务负责自己的向后兼容性，方便**独立开发和部署**
+- 服务的**设计本身需要预先考虑到可能的错误**情况，从设计的角度需要预料到错误发生是一种正常情况
+- 服务本身需要**无状态，便于扩展**;需要预料到服务示例可能有多个副本同时在运行
+
+一些隐含的假设还有
+- **添加新服务的代价很低**，往往数小时之多数天就可以添加一个新的服务并能和现有系统集成在一起
+- 服务的拆分需要和业务模型、领域划分想匹配;软件技术专家和业务领域专家能够紧密合作，快速变更;这是领域驱动开发的预设条件之一
+- 采用敏捷开发技术和**团队最熟悉的编程语言、框架及技术栈**，但是也不宜过多;否则团队的合作又会变得难以掌控
+- 组织开发结构和服务的拆分能互相匹配，减小组织沟通成本，最好是组建跨职能的团队;这也是由康威定律所决定的
+- 采用服务发现和监控机制，以及负载均衡设施便于处理分布式应用场景，业务流的追踪和监控也会是新的挑战（想对于传统架构）
+- 基于容器技术
+
+## 微服务是“银弹”吗
+正如Fred Brooks在1986年所语言的那样，软件开发从来没有出现一个满盘通吃的银弹;
+虽然Brooks只是比较保守地估计了其后十年的情况，然而最近30年的行业发展依然没有见证银弹的出现。
+> there is no single development, in either technology or management technique, which by itself promises even one order of magnitude [tenfold] improvement within a decade in productivity, in reliability, in simplicity.
+>
+> -- Fred Brooks, 1986
+
+不少人满怀希望的认为微服务会打破常规，变成大家梦寐以求的神器，然而我们也见证了太多类似这种预言的屡次落空。
+目前业内主流的观点依然是，微服务不是银弹;企业仍然需要谨慎地依据实际场景谨慎选择使用。
+
+### 先决条件
+微服务的实施有很多先决条件，需要技术决策者仔细考虑。
+
+首当其冲的是企业的组织结构是否和微服务的拆分和设计想匹配。
+如果团队之间的沟通结构存在很多的层级和结构，微服务的设计和演进的速度就会严重受到影响。
+团队之间有明显的层级汇报或者审批关系会使情况变得更复杂，因为服务的自治性受到巨大的威胁。
+> "organizations which design systems ... are constrained to produce designs which are copies of the communication structures of these organizations."
+>
+>  — M. Conway
+
+另外一个不得不考虑的因素是**企业的敏捷开发、持续集成以及发布的能力**。
+如果企业的基础设施不够完善，不能尽快地对开发过程给予反馈，快速迭代难以为继，开发人员很快就会陷入困境，因为整个系统的测试和集成难度相比传统架构更高了。
+没有足够的持续交付能力，微服务落地自然很容易变成无缘之水。
+
+**开发人员的技术能力，以及选用的技术框架、编程语言**是否适合成员的技术背景也会成为一个巨大的挑战。
+最好的情况是，能够开发微服务的团队至少也能够应付中对规模的单体应用。
+目前的开发生态更加倡导多语言的混合团队，使得每个团队可以选用自己擅长、喜欢的技术更快的开发自己的微服务，然而这样做也是好坏参半。
+**软件开发活动归根结底是人的活动**，人员的能力不能匹配技术的需求，或者有过多的技术栈以至于超出大部分成员的能力等情况，都需要慎重对待。
+
+正如Martin Fowler在他的[《微服务架构的先决条件》](https://www.martinfowler.com/bliki/MicroservicePrerequisites.html)一文中所指出的那样，能力因素是个至关重要的决定因素。
+![microservice_competence](https://www.martinfowler.com/bliki/images/microservicePrerequisites/sketch.png)
+
+### 如何实施
+鉴于以上讨论到的这些“坑”，微服务并不是任何时候、任何组织都可以开展;应用微服务同样需要讲究天时、地利、人和。组织的敏捷程度和自动化能力，沟通结构，人员的技术配备能力都缺一不可。
+
+Martin Fower建议的方式是我们总是**可以从传统的单体架构**开始，采用演进式设计的思路逐步过度到微服务架构。
+等到我们**对系统对应的问题域有更深刻的理解**之后，可以自然地按照领域驱动设计的思路仔细地划分服务粒度和范围，将服务拆分出来。
+
+毕竟微服务是基于分布式环境的设计风格，而分布式的设计总是会有各种各样的复杂挑战需要仔细解决。
+如果需要解决的业务领域有很高的实时性要求或者大规模、高并发的需求，拆分和设计的时候更需要小心分析，大胆假设加上仔细的设计和验证。正如Martin在企业应用架构模式中所说的
+> First Law of Distributed Object Design: "don't distribute your objects"
+> 
+> -- Martin Fower, [Patterns of Enterprise Application Architecture](https://www.martinfowler.com/books/eaa.html)
\ No newline at end of file
diff --git a/_posts/2017-09-24-data-management-evolution.md b/_posts/2017-09-24-data-management-evolution.md
new file mode 100644
index 0000000..e248c6d
--- /dev/null
+++ b/_posts/2017-09-24-data-management-evolution.md
@@ -0,0 +1,255 @@
+---
+layout: post
+title: 数据访问与管理技术的演进
+comments: true
+categories: [design]
+tags: [design, architecture, database, microservice]
+---
+
+数据访问和管理是软件设计需要解决的一项非常关键而又基础的问题;从早期的大型Unix应用开始，到基于C/S架构的商业应用，
+乃至在互联网大潮中取得压倒性优势的基于B/S架构的企业应用，对于如何管理、访问、保存、检索、备份、维护数据这一基本问题，
+无数先辈们创造了丰富多样的技术选项，然而随着行业潮流的变换，不同的技术依然在它各自适应的领域闪耀这光芒。
+
+<!--more-->
+## 数据访问、管理技术的关键要素
+到目前为止，几乎所有的软件依然是工作在冯诺依曼设定的计算机架构之上,因而从**最微观的粒度看,运算器、控制器、存储设备互相配合**完成形形色色的任务。
+各色复杂的软件都要在此基础上做更高层次的抽象和封装，才能完成复杂度更高的任务。程序语言、编译器和各种各样的库函数、中间件等则都围绕着该基本模型来处理高层次的领域相关问题。
+
+由于最底层的硬件要么具有访问速度快但易失性的特点，要么是访问速度慢但可以持续保存很长时间；同时硬件在长时间工作的情况下总会面临各种各样的失败。
+面向业务问题的计算机**软件必须要被仔细设计以隔离上述问题，使得用户觉得失败永远不可能发生**（或者至少是现实意义上的不会失败）。
+这对数据的访问和管理技术提出了很高的挑战
+- 数据容量在需要的情况下能尽可能地大，甚至是可以**按需动态扩展**；传统上基于单机的数据存储模型被扩展到可以被存储在地理上分散的网络节点
+- 数据访问的延时需要满足特定的场景需求；由于数据可能被存放在不同的设备上，不同的存储设备有不同的访问性能和时延特性
+- 多用户同时访问的一致性：复杂的应用总会允许有逻辑上同时访问数据的需求，如果是访问同样的数据或者相互有逻辑关联的数据，用户不应该得到不一致的数据状态
+- 数据的可靠性：在任何硬件失效的情况下，数据的丢失总是应该被尽量杜绝的
+
+这些目标、挑战有些是互相矛盾的，因此在现有的技术条件下并没有出现过一种一招通吃的方案，各色各样的技术方案都会在某些方面有所取舍。
+只是在同样的取舍考虑下，优秀的技术能比它的竞争对手们做的更为出色。
+
+## 前“关系数据库”时期的数据结构和文件方案
+在20世纪70年代关系数据库理论出现之前，软件已经被用于解决很多形形色色的问题了， 这个时期其实并没有专门针对数据管理的特定技术。
+
+### 基于操作系统和基本库的思路
+需要管理和访问数据的时候，最基本的方案就是依赖操作系统和编程语言提供的基础设施了。
+这种场景下数据的访问**基本是没有很强的结构化特性**的，软件的规模也不是太大，因而直接依赖于底层的机制也算够用了。
+
+数据组织上基本以常用的数据结构为主，从最简单的顺序数组，到稍微复杂一点的链表结构，乃至树形结构、跳表、哈希表等依赖于计算机内部存储（处理器寄存器乃至内存）的高效数据机构。这些数据组织方式特别适合于规模不大的数据管理；
+其优点是数据的访问和存取都比较高效，然而其限制也比较明显，数据量比较大的时候，就必须找数据持久化存储的方法。
+
+一种最简单的方式是将数据用文件的方式写入到外部存储设备中；然后在需要的时候在从外部设备加载回来。
+数据量超过内部存储容量（或者超出预先分配的空间）的时候，可以用选择性的方式将某些数据换回到外部设备中。
+
+### 问题和挑战
+带来的挑战是如何选择合适的算法来确定什么时候需要将数据保存到外部存储设备，或者何时需要将数据加载到内存中。
+另外一个难题是如果**存储设备出错了，应该怎样应对这些错误**?对操作系统和通用的库函数来说，这可是应用程序自己的责任。
+由于应用程序的处理逻辑和数据管理、控制逻辑是放在一起的，这些异常处理和策略选择会使软件的逻辑复杂度大大提高。
+
+#### 数据抽象能力和校验
+因为操作系统和函数库提供了非常基本的抽象，数据结构之上所承载的数据格式定义，以及数据内容之间的相互关联关系都需要应用程序自己负责维护。
+当有大量类似关系的数据需要在多个地方处理和保存的时候，就会出现明显的代码重复并引入额外的维护想难题。
+
+一个可行的方案是当程序的规模变得比较大的时候，提供统一的应用层封装库最为基础设施给开发人员使用；
+不足之处是维护这样的**通用基础设施的技术复杂度比一般的上层程序逻辑要复杂**，需要考虑到很多负责的异常情况并有很强的适应性以匹配各种期望的场景。
+还有一种考虑是可以购买第三方成熟的中间件系统以减小维护成本；不利之处是系统出了问题的时候，仍然需要对所使用的软件有很深入的了解才能快速解决复杂问题；
+尤其当实际场景对安全性或者法律合规方面有比较打顾虑的时候，第三方软件的成熟度可能成为一个极大的问题，
+有时候如果这些第三方软件的设计缺陷没有被及早发现的话，后果可能更加难以承受。
+
+#### 存储设备特性和性能考量
+另外一个挑战是当数据容量变得特别巨大的时候，不可避免的需要将存储设备放在不同的物理机器上，
+然后通过网络通信协议的方式（比如NFS）将远端机器上的文件系统挂载在本地机器上；使本地机器以为它是在控制“本地”的文件;
+而微观上所有的操作都是通过一个网络通信通道（socket）加上对应的控制协议和数据搬运协议来完成。
+
+从寄存器到内存到磁盘再到网络磁盘，数据的容量是越来越大，然而其性能和延迟也急速下降；对CPU寄存器的访问可能几个时钟周期就可以完成（虽然其容量很小），
+对内存的一次读写需要的时间就会达到几十乃至数百倍，访问本地磁盘的延时往往是毫秒级甚至几十毫秒；当文件被用NFS的方式映射到本地的时候，
+一次访问的时间可能在数十毫秒乃至数秒；因为**网络层的封装可能是很厚重的，往往一个简单的操作可能后台需要好几次消息的来回**才能完成。
+如果网络出现拥堵或者中间设备出现故障，系统行为将变得更加难以预料。
+
+这些时间上的开销给软件开发带来了诸多挑战 - 长时间的延时（要么是库函数调用要么是系统调用）导致同步调用变得效率底下，甚至抵消了多线程编程带来的便利。
+由于太多阻塞的操作导致处理器使用率底下，更高的吞吐率难以达到，我们不得不借助于异步编程技术来分割应用程序的逻辑。
+
+#### 编程模型和协作的挑战
+可惜的是，因为IO行为的差异引发的编程模型的转化是的软件的可维护行大大降低。
+试想一个简单的业务逻辑因为需要访问外部存储设备而被分割成２个任务，丢在２个不同的线程调度器里，通过IO完成的callback事件关联在一起；
+这比基于内存数据的顺序处理逻辑复杂多了。
+
+虽然函数式编程模型或者Reactor模型可以应对这一设计挑战，但是仅仅因为数据访问的原因而变更熟悉的编程模型并不是在很多场景下都可以被轻易接受；
+毕竟软件开发是依赖于人的集体智力活动。
+
+### 对软件设计和架构的影响
+这些**非功能的属性会极大影响到应用程序的逻辑设计**；软件设计人员不得不在开发的早期阶段谨慎选择，以免掉入性能不足的漩涡最后不得不重写代码。
+本来软件的抽象是为了解决应用领域的复杂问题，隔离底层的细节，不幸的是**当底层细节的不同影响到了程序整体的行为的时候，这种关注点分离的方式就很难凑效**。
+尽管有各种各样的限制，在很多复杂度不是很高的场景下，基于操作系统和基础设施的数据管理方案仍然是最直观且最优的选择。
+只要切记在合适的时机依据需求的变化切换到更合适的方案上来即可；要么是变更的成本不大可以直接修改代码完成之，要么是一开始的时候设计好数据访问的隔离，
+才与适配器的模式隔离数据访问部分。
+
+## 基于严格结构化的关系数据库技术(SQL)
+
+关系数据库技术自从上个世纪７０～８０年代诞生以来便得到了业界的青睐；其**清晰的模型和严格的数学理论论证**深刻地征服了各个主要的IT厂商，
+其采用专门的属于来规范数据的定义和各种功能、非功能属性，学院式的精心设计预先考虑到了各种各样可能出现的问题。
+
+### 基本机制和思路
+关系数据库理论采用结构化的方式定义数据，严格的区分数据定义、处理的范围和边界。
+数据库管理系统作为专门的软件系统隔离了数据的定义、操作；应用程序通过预先定义的接口JDBC/ODBC等接口访问数据库系统。
+
+#### 数据定义
+数据的**结构抽象用schema来表述，逻辑上所有的数据都是满足给定schema的二维表**，每一行是一条记录；所有的记录都具有相同的列。
+每一行数据的相同列具有相同的定义和约束；每一行数据中的某些列作为访问的关键列（称为键）。这些列有些可以为空有些则必须不能为空。
+对数据的访问则以行为单位，可以进行增加、删除、修改等变更性操作和根据某些条件进行查询。
+**数据的完整性校验可以通过在数据发生变更的时候依靠数据库系统软件的自动检查**来完成。
+
+数据表之间可以有丰富多样的相互关联(通过主键、外键设置)，从而支持在查询的时候跨越多个表进行复杂的检索。
+为了便于应用逻辑处理，关系数据库系统还提供了虚拟的表（称之为视图），这些虚拟的表结构可以基于底层实际的"物理记录表"信息的变化而自动更新；
+触发器则支持设置类似于应用程序指定的“自动操作”，当对应的数据被更新的时候，触发器会被自动运行。
+
+通常情况下，复杂的业务数据**可以依据不同的范围来隔离**，可以放在不同的数据库中，也可以放在同一个数据库的不同数据表中。
+多个数据表之间的逻辑关联关系用关系代数来描述，一般不同的数据表之间有相对的关联，
+比如某个表的某一列也出现在另外一个表中作为另外一个表的主键，这样查询的时候，可以将两个表联合起来提供单个表不能提供的丰富信息。
+
+数据表之间的关系用数据库范式来描述，严格的关系数据库理论定义了多种关系范式，用以描述信息的冗余度、结构化程度；不同的范式可以大概表征数据一致性的维护难度。
+**复杂的范式往往也会带来性能开销和处理复杂度**，因此商业的应用程序中一般出于性能考虑不会采用很高的范式。
+
+#### 数据查询和SQL语言
+关系数据库系统一个最引人注目的特性是提供了一个关于数据定义的结构化模型和**接近于自然语言的领域特定语言SQL**，并将其和关系代数理论紧密结合在一起。
+SQL语言采用了类似于英语的语法，以数据查询为中心同时兼顾增加、删除和修改操作，
+并支持对数据集的聚集、归并、分类、排序等常见的操作，实现了对数据管理和访问的细节隔离，使得**应用程序仅仅需要关注于数据操作的意图**即可。
+
+SQL是面向数据操纵和访问用户的接口语言，数据库管理系统可以优化用户提供的SQL查询，转换成性能最好的内部实现。
+这也是DSL的好处，整个数据库管理系统**通过精心定义的查询语言将接口和实现分离**开；应用程序可以专注于业务逻辑的实现，而数据库关系系统可以专注于数据的管理和维护。
+这也是计算机科学一直采用的基本的分而治之的思路－分割问题领域，然后在各个击破之。
+从这个意义上来说，关系数据库系统提供了**良好的抽象和职责分离**。
+
+#### 查询优化和索引
+由于商业数据库的数据往往数据量非常大，可能被保存很长时间，因此大部分时候，绝大部分数据都是被保存在磁盘中（甚至是网络磁盘）并在需要的时候读取进来加载进内存中给用户使用。大部分时候，用户的查询操作比修改操作要多得多，因此查询的性能是至关重要的。
+
+虽然数据很多，但是**某个时候用户需要访问的可能只是一小部分数据，怎样快速地检索**到对应的数据并提供给用户就变得至关重要。
+关系数据库系统一般是通过在数据表上建立索引表来实现的，同时基于成熟的B+数数据结构，保证经过少数几次的磁盘IO读写操作就可以定位到具体的数据记录存储快，然后将对应的块读出操作系统内存中去。
+这也潜在的要求数据库系统组织**数据存储的时候，需要按照记录块的方式**将其存储在外部设备中；并最好和操作系统的虚拟内存所支持的页面大小保持对齐，尽可能减少磁盘的读写次数和寻道时间。
+
+当数据量特别大以至于简单的索引表也无法加载进内存的时候，可能需要建立多级索引结构，用一个新的结构指向某一部分数据的索引表在磁盘上存储的位置；而只是将最顶层的索引表放在内存中。
+查询的时候，则需要先通过一级索引找到对应小范围数据记录对应的索引的存储位置，通过一次额外的磁盘操作加载二级索引，然后通过二级索引的数检索操作，找到对应的数据块的物理位置。
+
+实际情况下，往往通过少数几次的IO操作（通过B+树的算法保证）便可定位到实际的数据并将其加载入内存中，减少慢速IO对性能的不利影响。
+
+#### 事务及ACID属性
+作为数据的访问接口，SQL定义了复杂的查询接口以适应复杂的数据访问、管理需求；然而深入到最底层，细粒度的数据访问仍然要落实到二维数据表的某一个行记录上。
+由于这些单一的行是操作的最小粒度，数据库处理系统必须要保证对记录的访问在外部用户看来总是处于合理的状态。
+
+譬如一个用户打算修改某记录的一个列值，而另外一个用户可能同时打算删除该记录，那么**两个用户可能是并行在使用数据库**，数据库系统必须保证两者的操作返回之后，数据库系统人然处于一个自然的状态；
+要么某个用户操作成功返回修改生效，另外一个用户得到失败的反馈，要么２者都失败需要某一方尝试重试，要么数据库系统在内部实现某种机制保证至少一个成功一个失败。
+当实际操作的SQL语句牵扯到多个数据表操作的时候，一致性保证将变得更为困难。因为从并发控制的角度来看，只要牵扯到同一个数据的读写，既要保证读到的数据不能是中间状态，也要保证写入之后数据库中的状态需要恰好是刚刚写入的值。
+
+关系数据库系统**用事务作为数据操作的基本单元的抽象**，一个事务用来封装一次对数据库的操作；关系数据库系统用内部机制保证事物操作满足四个基本的属性
+- 原子性(Atomicy)：事务操作必须像是在一个最基本的操作中完成的，执行过程中不会被另外一个打断
+- 一致性(Consistency)：一个事务被提交执行前后，数据库系统中所有的相关数据仍然处于一致性的状态，要么数据被按照事务期望的方式被修改（事务被执行），要么完全保持原样（事务撤销）
+- 隔离性(Isolation)：各个事务的执行和调度对应用程序是不可见的；从事务提交者的角度来看，好像就他自己在使用数据库系统
+- 持久性(Durablility)：事务操作的结果是持久有效的，即使是发生了故障或者重启，已经发生的修改必须被永久保存下去；不允许数据丢失情况的发生。
+
+ACID是关系数据库系统的基本特征，甚至于不支持ACID特性的数据库软件都不被认为是关系数据库软件；它被各大数据库厂商广泛地支持和实现。
+
+
+### 问题和挑战 
+
+ACID里边**最为关键和复杂的就是一致性和持久性**，尤其是当数据库系统的访问可能来自与网络的时候，由于延时的增加以及不可预期的复杂事务可能被远程调度执行，如何**高效、公平地实现事务的一致性控制**，又不引起性能的急剧恶化是个巨大的挑战。
+从数据持久性角度来看，数据库系统作为一个应用软件本身是运行在操作系统的用户空间，而真正将数据的更新落地到非易失性存储设备需要经历上层的IO调度到操作系统内核空间的控制和数据搬运，操作系统内核的实现和磁盘驱动的读写等等一系列异步操作，
+数据库系统需要始终保证**任何一个环节出错，数据总是能恢复到正确的状态**。
+
+为了实现这些复杂特性，很多数据库厂商（譬如Oracle）会通过修改操作系统驱动甚至内核等方式在可用性和性能之间进行折中。
+同时为了提高可用性并兼顾性能，某些数据库系统会**要求有非常好的单机性能**，使用具有高级特性的磁盘存储设备等。
+
+#### 和面行对象软件系统的集成难题
+关系数据库理论早于面向对象技术出现，然而软件开发领域内面向对象技术则在80~90年代迅速席卷了行业的大部分角落。
+应用程序上层用面向对象技术写成的特点注定了当它需要去访问数据的时候，**中间提供隔离的层次需要协调两者模型上的不一致**：
+面向对象技术组织数据操作的方式是通过继承、封装和多态来提供抽象能力，而数据库技术的组合方式是基于SQL查询。
+
+[ORM技术](https://en.wikipedia.org/wiki/Object-relational_mapping)被发明出来用以实现传统的[企业应用架构](https://www.martinfowler.com/books/eaa.html)中的对象和关系模型的映射，虽然**有一些复杂的框架技术来缓解这一难题**，总归是显得复杂而臃肿。
+好在Java语言用类型注解的方式提供了相对优雅的解决方案，从而通过少数几行代码就可以注入约束和检查，大大减小了数据访问层的负担。
+
+#### 扩展性的挑战
+由于商业数据库有很大的数据需要存储和使用，当系统需要动态扩展以支持更多的业务量的时候，**单实例、中心化的数据库系统往往能为扩展性的瓶颈**。
+
+维护数据一致性的代价越来越大，因为分布式数据库系统的扩展和优化需要面对[CAP理论](http://robertgreiner.com/2014/08/cap-theorem-revisited/)的限制：要么保证可用性牺牲一致性，要么保证一致性牺牲可用性。
+当有２个并发的用户访问数据库系统的时候，既保证数据的一致性，又保存高度的可用性会成为巨大的挑战,即如下的情况，在没有异常发生的时候N1的更新很容易通过网络同步、复制的方式被N2看到
+
+![normal case](http://www.julianbrowne.com/assets/attachments/brewers-cap-theorem/images/scenario-1.png)
+
+当网络发生异常的时候，就会出现不一致
+
+![network failure](http://www.julianbrowne.com/assets/attachments/brewers-cap-theorem/images/scenario-2.png)
+
+网络分割是无法妥协的，因为没有足够强大的机器来维持足够好的单机器性能;分布式应用基本无法在实际中妥协了。
+
+> No set of failures less than total network failure is allowed to cause the system to respond incorrectly.
+> 
+> --- [Partition Tolerance as defined by Gilbert & Lynn](http://www.julianbrowne.com/article/viewer/brewers-cap-theorem) 
+
+类似于两阶段提交算法等分布式事务(2PC)处理机制从理论的角度看起来很美好，实际应用中却因为性能过于低下而被束之高阁。
+
+**成本和投入产出比**也是需要考虑的显示因素，因为传统的关系数据库系统需要强大的专有硬件（如磁盘RAID、EMC专业存储方案）来保证较高的可靠性和可用性。
+在互联网技术日益发展深入的背景下，企业需要尽量控制IT支撑环境的成本，并快速部署给用户，并**需要技术架构和实现能随着业务量的增加而快速演进**，传统的将数据库作为独立中间件部署的方式因为太厚重而慢慢被边缘化了。
+
+## 非结构化数据和NoSQL技术
+21世纪头十年互联网技术的严谨为提非结构化数据(即键值数据库系统)蓬勃发展的土壤。从关系数据库理论的角度来看，没有提供ACID支持的数据库甚至都不叫数据库系统；
+然而新世纪IT技术对越来越多行业的深入改造带来了数量巨大的数据；而很多数据并不是天然具有很强的结构化特性；将他们强赛进关系数据库系统中会带来臃肿的设计、复杂的模型以及地下的性能。
+
+### 基本思路
+NoSQL技术从简化数据管理的角度来解决这一难题：一方面我们有大量的数据需要存储，这些数据之间没有非常强的相互关联；另外一方面对这些数据的访问可能有很高的并发需求和扩展性需求。
+**既然关系数据库提供的东西远远多于实际需要的，何不将这些复杂的功能向上移动到应用程序问题域**内？
+这样数据库系统仅仅需要管理没太多逻辑结构的数据，并提供足够好的并发访问性能、可扩展性、可靠性；而将怎样使用数据交给应用程序去处理？
+毕竟最了解数据使用场景的还是上层应用程序。
+
+### 数据管理特性和元数据
+NoSQL其实不是一类技术的统称，而是不采用强结构化形式管理数据的一大堆数据管理技术的集合。
+不同的方案提供不同的技术实现，并呈现出不同的特性；从简单的基于纯粹Key-Value对的大数据集合到能够提供一些稍微复杂一点的如关联映射、集合类型的多类型数据管理系统3（典型如Redis），
+乃至提供一些比较复杂的[面向文档](https://en.wikipedia.org/wiki/Document-oriented_database)的数据结构（相比SQL可以认为是半结构化）以及较强检索能力的中间型数据库（典型的如MongoDB提供了复杂的json互操作特性);总体上可谓是[百花齐放](https://en.wikipedia.org/wiki/NoSQL#Types_and_examples_of_NoSQL_databases)，各有千秋。
+
+### 亮点
+大部分NoSQL技术都提供了很高的性能和强大的集群管理能力，其处理能力想对于传统的关系数据库有很大的提升。
+之所以如此，是因为它从技术上打破了传统SQL要求的复杂限制，专注于自身特定的数据定义模型和特点，有针对性地最大化使用计算机硬件。
+
+同时大部分NoSQL技术设计的时候就考虑到了可能出错的情况，不再假设底层的硬件本身具有很高的性能，而是通过自身软件的设计达到较高的可用性和可靠度。譬如Redis本身常常被作为缓存系统使用，而其自身的持久化机制在合理配置的情况下，可以保证数据在１秒内内一定会被写入磁盘，从而尽可能减少数据丢失。
+
+### NoSQL的折中
+基于纯粹的KV关系的数据库系统对数据的具体结构接近与一无所知；从应用程序的角度看，它似乎仅仅是提供了数据操作层面的虚拟关联表。
+其好处是很容易达到很高的性能，但不足之处是，应用程序**如何合理地管理键的模式**是一个比较打的挑战。
+
+提供复杂结构的NoSQL的好处是应用层程序的负担比较小，因为一些常见的结构化操作已经有了不错的支持，可以直接调用即可。
+美中不足的是，这样的方案的性能往往也不是那么好，优化起来也会比较困难，因为数据的存储管理也相对比较复杂，如MongoDB采用树结构来保存数据，不深入其底层实现做针对性的优化就比较困难一些。
+
+### 挑战
+NoSQL自然也不是银弹，它也有它自己的问题需要应对；尤其是当它的用户企图将具有很强结构化特征的数据塞进去的时候：应用程序用来维护这些数据之间的关联关系就会变得异常复杂。
+
+另外一个比较麻烦的事情**是NoSQL的不同提供者具有不同的特性**，应用程序想从一种切换到另外一种就远远没有传统的SQL来的方便;很可能你需要某个数据库的高级特性在另外一个数据库中就不存在了。
+这也是**缺乏类似于SQL语言这类DSL的不足**;比如Redis定义了类似通配符的模糊查询键值的方式，并提供了类似于一个Key关联多个属性的数据控制原语；换到MongoDB上我们就需要不同的方式来解决类似的问题。
+
+这些复杂的数据操作可能在应用程序层面来看又比较常见和繁琐，以至于使用**纯粹的NoSQL会让人产生退回到SQL出现之前的混沌时代的错觉**！这当然也不是NoSQL的错，因为从来就没有银弹；合适的方案才是最好的；而怎样决定什么样的方案才是最好的？
+当然是需要一句具体的业务场景来确定了。
+
+### BASE理论
+NoSQL解决[数据一致性和高可用的CAP矛盾](https://www.cs.cornell.edu/Projects/mrc/IEEE-CAP.16.pdf)的方案是所谓的[BASE方法](http://www.dataversity.net/acid-vs-base-the-shifting-ph-of-database-transaction-processing/)，它常常被错误的想象为是ACID的对立面
+1. 基本可用而不是高可用(Base Availability) 强调数据库系统并不总是返回高度可用的数据，某些情况下可能出错或者不返回，或者返回不一致的数据；应用程序比系显式地处理这些情况
+2. 弱状态或不稳定状态（Soft state)表明数据的状态可能在不断发生变化，以至于传统关系数据库的这种事务回滚或者提交的状态则不复存在。这些都是为了应对最终一致性的目标。
+3. 最终一致性约束(Evenutal consistency)保证数据的更新经过一段时间的处理在没有后续输入的情况下可以达到一致状态；但是中间的不一致性状态仍然对应用程序是可见的。
+
+基本上**这些特性都是为最终一致性服务的**；数据库系统不再强制保证很强的一致性，而是由应用程序本身负责中间不一致状态的处理。
+好处是性能可以得到极大提高，因为数据库系统不需要采用很复杂的策略来保证每一项数据的高度可靠和一致，没有复杂的同步、锁策略，开销自然少；
+不利之处是应用程序需要仔细处理失败的情况，这在很多时候也是一个公平的折中，因为最了解数据特性的毕竟是上层程序本身。
+
+## 微服务架构下的数据演进和NewSQL
+随着云计算技术的深入发展和容器技术的广泛应用，微服务风格的架构技术变得愈发流行起来。
+按照微服务设计的思路，传统的分层、单体、集中式的架构方式被**分布式去中心化、按照业务领域分隔**以及轻量级的接口为特征的架构方式所取代。
+同时鉴于以上这些NoSQL技术的种种不足并不能一招通吃，**传统的SQL技术又被人们重新重视起来使用在合适的场景**中；
+在一个一个具体的服务内部，SQL所定义的查询语言作为完美的数据操作接口仍然有极大的魅力，我们依然可以继续享用它而不需要因为复杂的数据操作而增加应用程序的逻辑复杂度。
+
+最显著的不同在于，服务是较为细粒度的、以业务逻辑功能为核心的一个一个小的独立的进程。**数据也会根据此思路进行分割管理**，而不再统一的放在一个大的数据库中。
+从整个系统的角度看，数据的交换和同步是通过服务之间的协议接口进行的，因而这些协议要求必须是轻量级的，以减少数据序列化、反序列化的开销。
+因为**微服务的高可用是通过同时运行多个副本外加负载均衡等分布式技术**来实现的，服务之间的耦合必须是很松散的；分布式一致性的问题采用的依然是最终一致性的思路。
+
+这种新的结合了传统SQL接口来管理本地数据，用部分NoSQL思路来处理系统一致性的方式又被成为NewSQL,甚至于NoSQL又被重新宣称为是Not Only SQL的缩略词。
+显然在计算机科学领域，从来就没有一招打遍天下的技术，数据管理领域也不外如是。
+
+> There is no single development, in either technology or management technique, which by itself promises even one order of magnitude [tenfold] improvement within a decade in productivity, in reliability, in simplicity.
+>
+> -- Fred Books, 1986
+
+业界因为商业、宣传等各种原因，会在某个技术刚刚崭露头角的时候宣称可以包治百病(否则也不会引人注意得到发展)；
+经过比较长时间的洗礼**最终会回到其本源应用到其最合适的场合**，而怎样鉴别什么样的场合使用什么样的技术，依然是软件开发者、架构师最大的挑战之一。
\ No newline at end of file
diff --git a/_posts/2017-10-04-cpp-17-updates.md b/_posts/2017-10-04-cpp-17-updates.md
new file mode 100644
index 0000000..6a74a0a
--- /dev/null
+++ b/_posts/2017-10-04-cpp-17-updates.md
@@ -0,0 +1,166 @@
+---
+layout: post
+title: C++17整装待发
+comments: true
+categories: [language, programming, cpp]
+tags: [programming, cpp, language, fp]
+---
+9月份对于C++社区而言绝对是个令人振奋的收获季节。
+
+<!--more-->
+
+先是在９月上旬的时候，语言标准化委员会完成了新的语言标准的**草案投票并取得了全票**通过（虽然有一些小的语法、修辞上的评论待修改）；
+Herb Sutter第一时间在[其博客上发布了这一激动人心的消息](https://herbsutter.com/2017/09/06/c17-is-formally-approved/)：C++2017已经获得了实质性的通过静待最终发布。
+值得注意的是，这是C++这门大象一般行动缓慢的语言在变更为[更敏捷的火车发布模型](https://en.wikipedia.org/wiki/Software_release_train)之后，第一次按照时间点准时发布大的语言版本。
+之前可是有10多年才发布一个版本（说好的C++0x最终变成了十六进制年份的玩笑）导致开发者等到心凉自己造轮子的事情；而C++14是一个修复设计问题的小版本。
+
+另外一个大事件则是CppCon2017社区大会的成功举办，与往常一样有一大堆的新料演讲(已经放在[这里](https://github.com/CppCon/CppCon2017))放了出来供社区消化、学习。
+
+## C++17
+作为一个按照敏捷发布模型出来的第一个大的语言版本，由于需要照顾到质量、时间节点（毕竟需要按时发布）和参考实现成熟度等因素，本来新特性不会很多。
+然而作为一个语言的大版本来说，没有一定的新料自然也有滥竽充数的嫌疑；在敏捷的大背景下，谁也不愿意多等都希望马上出来一些质量够好、实现就绪马上可用的新特性；而且要不止一个，因为可供选择的编程语言实在是太多了。
+
+值得庆幸的是，WG21标准化小组早在３月份就完成了新语言特性的草稿准备工作。
+
+### 语言特性
+
+很多语法糖方面的更新，可以让程序员生产率更高，包括以下这些主要的更新
+
+#### 嵌套的命名空间声明
+这是一个小小的改进，但足以节省大家很多敲击键盘和格式化缩进的烦恼。因为在比较大的项目中，经常用嵌套的命名空间来隔离API和类，之前我们不得不这样写
+```cpp
+namespace outer{
+    namespace inner {
+        namesapce module {
+            //my module definitions...
+        }
+    }
+}
+```
+或者为了节省空间（采用微软的换行风格有强迫症的更要哭了），直接缩略为
+```cpp
+namespace outer{ namespace inner{ namespace module {
+    //my module definitions...
+}}}
+```
+新标准直接允许我们写为
+```cpp
+namespace outer::inner::module {
+    //my module definitions...
+}
+```
+是否清爽了很多，或者有本来就应该如此的感觉？为什么没有更早支持啊。
+
+#### `static_assert`的消息提醒参数变为可选
+这个是针对之前引入的用于与编译期间静态检查机制`static_assert`的一点小修正，允许其携带的消息提醒参数被忽略，以减少编译噪音。
+本来这个静态断言机制可以很好地服务于编译器多态检查，如果没问题就一路继续编译下去，如果出错，则会打印一条错误信息包含在错误诊断中，并终止编译。
+新的改动允许不提供该诊断信息。
+
+#### `auto`可以用于初始化列表的类型推导
+C++11通过重用`auto`关键字来做自动类型推断，而C++17将其扩充到了初始化列表类型，并要求它符合特定的规则。即
+
+```cpp
+auto x = {1}; //decltype(x) = initializer_list<int>:
+auto y = {2, 3}; //declytpe(y) = initializer_list<int, int>;
+auto x1 {1}; //same as x
+auto y1 {2, 3}; //ill-formed! Not a single element!
+```
+#### 字面量类型扩展
+字面量类型具有很好的声明式风格和良好的可读性，之前的语言标准支持的类型比较有限（比如字符常量、整数、浮点常量），而C++17引入了对其他字符集的支持
+- `u8'c-char'`用以支持UTF-8编码的字符常量，其类型依然是`char`类型，而其值则是用ISO10646编码的单个字符。
+- `u'c-char'`用以支持UCS2编码可以支持２个字节，内部类型是`char16_t`,如 `u'\U0001f34c'`
+- `U'c-char'`支持４个字节的UCS4,内部类型是`char32_t`,内部用Unicode编码，比如`U'猫'`
+
+浮点类型的常量声明支持了更多可读性更好的格式，下边的例子
+```cpp
+#include <iostream>
+int main()
+{
+  std::cout << 123.456e-67 << '\n'
+            << .1E4f       << '\n'
+            << 58.         << '\n'
+            << 4e2         << '\n';
+}
+```
+会输出四种方式所生命的浮点数字
+```
+1.23456e-65
+1000
+58
+400
+```
+#### 可变长模板参数中的折叠表达式
+C++11引入了可变长的模板参数，大大简化了模板元编程，而C++17则支持在变长模板参数中使用折叠或归约(函数式编程中的基本范式),
+可以支持从一堆模板参数中，指明第一个而省略其他，也可以指明最后一个省略前边的。这些参数中间可以用操作符来连接，编译器需要自己负责将他们按照既定的规则串联起来。
+
+比如这个例子
+```cpp
+template<typename... Args>
+bool all(Args... args) { 
+    //op is &&, pack parameters as ..., specified last parameter
+    return (... && args); 
+}
+
+//expanded as left fold, as 
+// ((true && true) && true) && false = false
+bool b = all(true, true, true, false);
+```
+
+详细的定义如下
+```cpp
+(pack op ...) //unary right fold
+(... op pack) //unary left fold
+(pack op ... op init) //binary right fold
+(init op ... op pack) //binary left fold 
+```
+
+一个更复杂一点的例子
+```cpp
+template<typename ...Args>
+void printer(Args&&... args) {
+    //left fold print
+    (std::cout << ... << args) << '\n';
+}
+ 
+template<typename T, typename... Args>
+void push_back_vec(std::vector<T>& v, Args&&... args)
+{
+    //binary left fold, push back from left to right, init=v
+    (v.push_back(args), ...);
+}
+ 
+// compile-time endianness swap based on http://stackoverflow.com/a/36937049 
+template<class T, std::size_t... N>
+constexpr T bswap_impl(T i, std::index_sequence<N...>) {
+  return (((i >> N*CHAR_BIT & std::uint8_t(-1)) << (sizeof(T)-1-N)*CHAR_BIT) | ...);
+}
+template<class T, class U = std::make_unsigned_t<T>>
+constexpr U bswap(T i) {
+  return bswap_impl<U>(i, std::make_index_sequence<sizeof(T)>{});
+}
+ 
+int main()
+{
+    printer(1, 2, 3, "abc");
+ 
+    std::vector<int> v;
+    push_back_vec(v, 6, 2, 45, 12);
+    push_back_vec(v, 1, 2, 9);
+
+    for (int i : v) std::cout << i << ' ';
+ 
+    static_assert(bswap<std::uint16_t>(0x1234u)==0x3412u);
+    static_assert(bswap<std::uint64_t>(0x0123456789abcdefULL)==0xefcdab8967452301ULL);
+}
+```
+
+####
+**TBD**
+
+### 标准程序库
+**TBD**
+#### `std::optional<T>`
+
+#### `std::variant<...Types>`
+
+## CppCon2017
\ No newline at end of file
diff --git a/_sass/minimal-mistakes/_base.scss b/_sass/minimal-mistakes/_base.scss
index c5311a2..6d2e34d 100644
--- a/_sass/minimal-mistakes/_base.scss
+++ b/_sass/minimal-mistakes/_base.scss
@@ -34,23 +34,23 @@ h1 {
 }
 
 h2 {
-  font-size: $type-size-4;
+  font-size: $type-size-3;
 }
 
 h3 {
-  font-size: $type-size-5;
+  font-size: $type-size-4;
 }
 
 h4 {
-  font-size: $type-size-6;
+  font-size: $type-size-4;
 }
 
 h5 {
-  font-size: $type-size-6;
+  font-size: $type-size-5;
 }
 
 h6 {
-  font-size: $type-size-6;
+  font-size: $type-size-5;
 }
 
 small, .small {
@@ -312,4 +312,4 @@ nav {
 b, i, strong, em, blockquote, p, q, span, figure, img, h1, h2, header, input, a, tr, td, form button, input[type="submit"], .btn, .highlight, .archive__item-teaser {
   -webkit-transition: $global-transition;
   transition: $global-transition;
-}
\ No newline at end of file
+}
diff --git a/_sass/minimal-mistakes/_page.scss b/_sass/minimal-mistakes/_page.scss
index 6b77b32..b02edf1 100644
--- a/_sass/minimal-mistakes/_page.scss
+++ b/_sass/minimal-mistakes/_page.scss
@@ -19,6 +19,9 @@
 }
 
 .page {
+  padding-left: 4%;
+  padding-right: 4%;
+
   @include breakpoint($large) {
     @include span(10 of 12 last);
     @include prefix(0.5 of 12);
@@ -405,4 +408,4 @@
   margin-bottom: 10px;
   font-size: $type-size-6;
   text-transform: uppercase;
-}
\ No newline at end of file
+}
diff --git a/_sass/minimal-mistakes/_variables.scss b/_sass/minimal-mistakes/_variables.scss
index 2e24c06..b923c75 100644
--- a/_sass/minimal-mistakes/_variables.scss
+++ b/_sass/minimal-mistakes/_variables.scss
@@ -13,8 +13,8 @@ $paragraph-indent           : false !default; // true, false (default)
 $indent-var                 : 1.3em !default;
 
 /* system typefaces */
-$serif                      : Georgia, Times, serif !default;
-$sans-serif                 : -apple-system, ".SFNSText-Regular", "San Francisco", "Roboto", "Segoe UI", "Helvetica Neue", "Lucida Grande", Arial, sans-serif !default;
+$serif                      : Georgia, "Times New Roman", SimSun, "宋体", serif !default;
+$sans-serif                 : -apple-system, ".SFNSText-Regular", "San Francisco", "Roboto", "Segoe UI", "Helvetica Neue", "Lucida Grande", "Microsoft YaHei", "微软雅黑", Arial, sans-serif !default;
 $monospace                  : Monaco, Consolas, "Lucida Console", monospace !default;
 
 /* sans serif typefaces */
@@ -106,7 +106,7 @@ $small                      : 600px !default;
 $medium                     : 768px !default;
 $medium-wide                : 900px !default;
 $large                      : 1024px !default;
-$x-large                    : 1280px !default;
+$x-large                    : 1920px !default;
 
 
 /*
@@ -126,4 +126,4 @@ $border-radius              : 4px !default;
 $box-shadow                 : 0 1px 1px rgba(0, 0, 0, 0.125) !default;
 $navicon-width              : 1.5rem !default;
 $navicon-height             : 0.25rem !default;
-$global-transition          : all 0.2s ease-in-out !default;
\ No newline at end of file
+$global-transition          : all 0.2s ease-in-out !default;
diff --git a/about.md b/about.md
new file mode 100644
index 0000000..5000202
--- /dev/null
+++ b/about.md
@@ -0,0 +1,6 @@
+---
+layout: single
+title: This site and the author
+---
+
+This is a personal blog site hosted on github pages, contents includes programming tips, tools, thinking on professional carrier.
diff --git a/assets/async_lib/asyncAndBlock.png b/assets/async_lib/asyncAndBlock.png
new file mode 100644
index 0000000..4246ffa
Binary files /dev/null and b/assets/async_lib/asyncAndBlock.png differ
diff --git a/assets/async_lib/asyncAndBlock.pu b/assets/async_lib/asyncAndBlock.pu
new file mode 100644
index 0000000..dd96480
--- /dev/null
+++ b/assets/async_lib/asyncAndBlock.pu
@@ -0,0 +1,34 @@
+@startuml
+title asynchronous and blocking for completion call
+control cpu
+actor AsyncActor
+ref over InterfaceScheduler, ServiceImpl: registeration of service
+== store for deferred call ==
+AsyncActor -> AsyncActor: time to call
+activate AsyncActor #Yellow
+AsyncActor -> AsyncActor : prepare onActionDone
+AsyncActor -> InterfaceScheduler : interfaceCall(async = true, waitforDone = true, onActionDone)
+activate InterfaceScheduler #Yellow
+InterfaceScheduler -> AsyncWorker : doSyncJob(action, onActionDone)
+InterfaceScheduler -> InterfaceScheduler : block context
+activate AsyncWorker #Yellow
+AsyncWorker -> AsyncWorker : prepare wakeupAction and wrapActionDone
+AsyncWorker -> AsyncWorker : save <action, onActionDone>
+cpu --[#Blue]> AsyncWorker : context switch
+activate AsyncWorker #Blue
+== blocked call wakeup==
+AsyncWorker -> AsyncWorker : scheduleOutstandingJobs
+AsyncWorker --[#Red]> ServiceImpl : action()
+note left #FFAAAA
+    concurrent data access
+     in unless call
+     in a strand
+end note
+AsyncWorker --[#Red]> AsyncWorker : onActionDone() [wrapped]
+AsyncWorker -> AsyncWorker : invoke wakeupAction
+AsyncWorker --> AsyncActor : onActionDone
+note right: sequential access to data
+deactivate AsyncWorker
+deactivate InterfaceScheduler
+deactivate AsyncActor
+@enduml
diff --git a/assets/async_lib/asyncNonBlock.png b/assets/async_lib/asyncNonBlock.png
new file mode 100644
index 0000000..4ead940
Binary files /dev/null and b/assets/async_lib/asyncNonBlock.png differ
diff --git a/assets/async_lib/asyncNonBlock.pu b/assets/async_lib/asyncNonBlock.pu
new file mode 100644
index 0000000..134fd0d
--- /dev/null
+++ b/assets/async_lib/asyncNonBlock.pu
@@ -0,0 +1,48 @@
+@startuml
+title asynchronous and non-blocking call
+
+control cpu
+actor AsyncActor
+
+ref over InterfaceScheduler, ServiceImpl: registeration of service
+
+== store for deferred call ==
+AsyncActor -> AsyncActor: time to call
+activate AsyncActor #Yellow
+AsyncActor -> AsyncActor : prepare onActionDone
+AsyncActor -> InterfaceScheduler : interfaceCall(async = true, onActionDone)
+
+activate InterfaceScheduler #Yellow
+InterfaceScheduler -> AsyncWorker : doJob(action, onActionDone)
+
+activate AsyncWorker #Yellow
+AsyncWorker -> AsyncWorker : save <action, onActionDone>
+AsyncWorker --> InterfaceScheduler
+InterfaceScheduler --> AsyncActor
+
+deactivate InterfaceScheduler
+deactivate AsyncActor
+
+cpu --[#Blue]> AsyncWorker : context switch
+activate AsyncWorker #Blue
+
+== deferred call ==
+
+AsyncWorker -> AsyncWorker : scheduleOutstandingJobs
+
+AsyncWorker --[#Red]> ServiceImpl : action()
+note left #FFAAAA
+    concurrent data access
+     in ServiceImpl, critical
+     data area
+end note
+
+AsyncWorker --[#Red]> AsyncActor : onActionDone()
+note left #FFAAAA
+    concurrent data access
+     in AsyncWorker, critical 
+     data area
+end note
+
+deactivate AsyncWorker
+@enduml
diff --git a/assets/async_lib/crc.png b/assets/async_lib/crc.png
new file mode 100644
index 0000000..acf037d
Binary files /dev/null and b/assets/async_lib/crc.png differ
diff --git a/assets/async_lib/crc.pu b/assets/async_lib/crc.pu
new file mode 100644
index 0000000..b53736c
--- /dev/null
+++ b/assets/async_lib/crc.pu
@@ -0,0 +1,47 @@
+@startuml
+class InterfaceScheduler{
+    This calls is responsible for scheduling external interface calls to managed workers according to specified call property.
+    A fixed number of thread pools are started by default to serve call requests (given asynchronous call required)
+    It is also supported to run multiple calls as a strand such that calls are forced without concurrent data access
+    --
+    void start(size_t poolSize)
+    void stop()
+    bool registerInterface(const std::string& name, std::function<bool(ParaArgsBase&)> cb)
+    bool interfaceCall(const std::string& name, CallProperty&& prop, const Args&... args)
+}
+class CallProperty{
+    Providing calling specialities declaration
+    --
+    bool async
+    bool waitForDone
+    std::function<bool()> onCallDone
+    std::string strand
+}
+class SyncWorker{
+    Schedule the actual job within the same context as caller
+    --
+    bool doJob(Callable call, Callable onCallDone)
+}
+note top of AsyncWorker: each AsyncWorker wraps an unique thread to run designated jobs, and may associate with many strands
+class AsyncWorker <<ActiveObject>>{
+    Wrap an asynchronous thread (active object) to run all outstanding jobs assigned one by one
+    Also provide wrapper for synchronous job execution, calling context would be blocked until job actually executed
+    --
+    bool doJob(Callable call, Callable onCallDone)
+    bool doSyncJob(Callable call, Callable onCallDone)
+    bool blockUntilReady()
+    bool stop()
+    size_t getLoad()
+    std::thread::id getId()
+}
+note right of ServiceImplementor: different business scenario may provide differnt services
+class ServiceImplementor <<ScenarioImpl>>{
+    The actual service implementation class which supply a certain service and registers itself for other entities to call 
+    --
+}
+InterfaceScheduler .. CallProperty : uses >
+InterfaceScheduler "1" *-- "1" SyncWorker : contains
+InterfaceScheduler "1" *-- "many" AsyncWorker : contains
+ServiceImplementor "many" -- "1" InterfaceScheduler : uses >
+ServiceImplementor "many" -- "many" ServiceImplementor : uses >
+@enduml
diff --git a/assets/async_lib/registerInterface.png b/assets/async_lib/registerInterface.png
new file mode 100644
index 0000000..5305ebf
Binary files /dev/null and b/assets/async_lib/registerInterface.png differ
diff --git a/assets/async_lib/registerInterface.pu b/assets/async_lib/registerInterface.pu
new file mode 100644
index 0000000..71d79ff
--- /dev/null
+++ b/assets/async_lib/registerInterface.pu
@@ -0,0 +1,10 @@
+@startuml
+title registration of service
+serviceImpl -> InterfaceScheduler: registerInterfaceFor<X, Y>(name, callbackType)
+InterfaceScheduler -> InterfaceScheduler : wrap closure and store for query
+InterfaceScheduler --> serviceImpl : registeration result
+... serving calls for name ...
+serviceImpl -> InterfaceScheduler: unRegiterInterface(name)
+InterfaceScheduler -> InterfaceScheduler : remove local storage
+InterfaceScheduler --> serviceImpl : return
+@enduml
diff --git a/assets/async_lib/strandCall.png b/assets/async_lib/strandCall.png
new file mode 100644
index 0000000..5e2c153
Binary files /dev/null and b/assets/async_lib/strandCall.png differ
diff --git a/assets/async_lib/strandCall.pu b/assets/async_lib/strandCall.pu
new file mode 100644
index 0000000..b97e656
--- /dev/null
+++ b/assets/async_lib/strandCall.pu
@@ -0,0 +1,37 @@
+@startuml
+title strand multiple async calls for force sequential execution
+!pragma teoz true
+actor AsyncActorA
+actor AsyncActorB
+ref over InterfaceScheduler, ServiceImpl1, ServiceImpl2: registeration of service
+AsyncActorA -> InterfaceScheduler : interfaceCall("serviceA",strand = "strandA")
+InterfaceScheduler -> AsyncWorker1 : doJob(actionA, onDoneA)
+activate AsyncWorker1 #Yellow
+AsyncActorA -> InterfaceScheduler : interfaceCall("serviceX")
+InterfaceScheduler -> AsyncWorker2 : doJob(actionX, onDoneX)
+activate AsyncWorker2 #Blue
+AsyncActorB -> InterfaceScheduler : interfaceCall("serviceB",strand = "strandA")
+InterfaceScheduler -> AsyncWorker1 : doJob(actionB, onDoneB)
+AsyncWorker1 -> AsyncWorker1: actionA()
+& AsyncWorker1 --> ServiceImpl1 : do real action A
+& AsyncWorker2 -> AsyncWorker2 : actionX()
+AsyncWorker1 -> AsyncWorker1: onDoneA()
+& AsyncWorker1 --> AsyncActorA : A done
+note over AsyncActorA, AsyncActorB
+    actionB and onDoneB only happens
+     after actionA and onDoneA
+end note
+AsyncWorker1 -> AsyncWorker1: actionB()
+& AsyncWorker1 --> ServiceImpl2 : do real action B
+& AsyncWorker2 -> AsyncWorker2 : onDoneX()
+note over AsyncActorA #FFAAAA 
+    Possible concurrent data access in
+    for X done, may interleave with
+    onDoneA 
+end note
+AsyncWorker2 --> AsyncActorA : X done
+AsyncWorker1 -> AsyncWorker1: onDoneB()
+AsyncWorker1 --> AsyncActorB : B done
+deactivate AsyncWorker1
+deactivate AsyncWorker2
+@enduml
diff --git a/assets/async_lib/subscribeForRegistration.png b/assets/async_lib/subscribeForRegistration.png
new file mode 100644
index 0000000..066f588
Binary files /dev/null and b/assets/async_lib/subscribeForRegistration.png differ
diff --git a/assets/async_lib/subscribeForRegistration.pu b/assets/async_lib/subscribeForRegistration.pu
new file mode 100644
index 0000000..4a56de8
--- /dev/null
+++ b/assets/async_lib/subscribeForRegistration.pu
@@ -0,0 +1,19 @@
+@startuml
+title subscribe for interface registration
+!pragma teosz true
+actor asynActor
+asyncActor -> InterfaceScheduler: subscribeForRegistration(name, cb)
+activate InterfaceScheduler #Yellow
+alt interface not registered yet
+InterfaceScheduler -> InterfaceScheduler: append to notifier list
+serviceImpl -> InterfaceScheduler: registerInterfaceFor<X, Y>(name, callbackType)
+InterfaceScheduler -> InterfaceScheduler : wrap closure and store for query
+InterfaceScheduler -> InterfaceScheduler : notify all watchers
+& InterfaceScheduler --[#Red]> asyncActor : calling back
+InterfaceScheduler -> InterfaceScheduler : clear all attached
+& InterfaceScheduler --> serviceImpl : registeration result
+else interface already registered
+InterfaceScheduler --> asyncActor: calling back
+end
+deactivate InterfaceScheduler
+@enduml
diff --git a/assets/async_lib/syncAndBlock.png b/assets/async_lib/syncAndBlock.png
new file mode 100644
index 0000000..b8a8125
Binary files /dev/null and b/assets/async_lib/syncAndBlock.png differ
diff --git a/assets/async_lib/syncAndBlock.pu b/assets/async_lib/syncAndBlock.pu
new file mode 100644
index 0000000..d945e94
--- /dev/null
+++ b/assets/async_lib/syncAndBlock.pu
@@ -0,0 +1,19 @@
+@startuml
+title sychronous (and blocking) call
+actor syncActor
+ref over InterfaceScheduler, ServiceImpl: registeration of service
+syncActor -> syncActor: time to call
+activate syncActor #Yellow
+syncActor -> syncActor : prepare onActionDone
+syncActor -> InterfaceScheduler : interfaceCall(async = false, onActionDone)
+activate InterfaceScheduler #Yellow
+InterfaceScheduler -> syncWorker : doSyncJob(action, onActionDone)
+activate syncWorker #Yellow
+syncWorker -> syncWorker : action()
+syncWorker --> ServiceImpl : action calling back
+syncWorker -> syncWorker : onActionDone()
+syncWorker --> syncActor : action done calling back
+deactivate syncWorker
+deactivate InterfaceScheduler
+deactivate syncActor
+@enduml
diff --git a/assets/images/jfr/jfr_code_calltrace.jpg b/assets/images/jfr/jfr_code_calltrace.jpg
new file mode 100755
index 0000000..c3b0f98
Binary files /dev/null and b/assets/images/jfr/jfr_code_calltrace.jpg differ
diff --git a/assets/images/jfr/jfr_code_hot_methods.jpg b/assets/images/jfr/jfr_code_hot_methods.jpg
new file mode 100755
index 0000000..885ee1e
Binary files /dev/null and b/assets/images/jfr/jfr_code_hot_methods.jpg differ
diff --git a/assets/images/jfr/jfr_code_overview.jpg b/assets/images/jfr/jfr_code_overview.jpg
new file mode 100755
index 0000000..57657f9
Binary files /dev/null and b/assets/images/jfr/jfr_code_overview.jpg differ
diff --git a/assets/images/jfr/jfr_memory_gc.jpg b/assets/images/jfr/jfr_memory_gc.jpg
new file mode 100755
index 0000000..4d690bc
Binary files /dev/null and b/assets/images/jfr/jfr_memory_gc.jpg differ
diff --git a/assets/images/jfr/jfr_memory_gc_cfg.jpg b/assets/images/jfr/jfr_memory_gc_cfg.jpg
new file mode 100755
index 0000000..eaf42e1
Binary files /dev/null and b/assets/images/jfr/jfr_memory_gc_cfg.jpg differ
diff --git a/assets/images/jfr/jfr_memory_gc_times.jpg b/assets/images/jfr/jfr_memory_gc_times.jpg
new file mode 100755
index 0000000..4110831
Binary files /dev/null and b/assets/images/jfr/jfr_memory_gc_times.jpg differ
diff --git a/assets/images/jfr/jfr_overview.jpg b/assets/images/jfr/jfr_overview.jpg
new file mode 100755
index 0000000..6f35de6
Binary files /dev/null and b/assets/images/jfr/jfr_overview.jpg differ
diff --git a/assets/images/jfr/jfr_threads_blocked.jpg b/assets/images/jfr/jfr_threads_blocked.jpg
new file mode 100755
index 0000000..a271802
Binary files /dev/null and b/assets/images/jfr/jfr_threads_blocked.jpg differ
diff --git a/assets/images/jfr/jfr_threads_contention.jpg b/assets/images/jfr/jfr_threads_contention.jpg
new file mode 100755
index 0000000..08da748
Binary files /dev/null and b/assets/images/jfr/jfr_threads_contention.jpg differ
diff --git a/assets/images/jfr/jfr_threads_hot_threads.jpg b/assets/images/jfr/jfr_threads_hot_threads.jpg
new file mode 100755
index 0000000..3411408
Binary files /dev/null and b/assets/images/jfr/jfr_threads_hot_threads.jpg differ
diff --git a/assets/images/jfr/jfr_threads_latency.jpg b/assets/images/jfr/jfr_threads_latency.jpg
new file mode 100755
index 0000000..956889c
Binary files /dev/null and b/assets/images/jfr/jfr_threads_latency.jpg differ
diff --git a/assets/images/jfr/jfr_threads_lock.jpg b/assets/images/jfr/jfr_threads_lock.jpg
new file mode 100755
index 0000000..b85ea5c
Binary files /dev/null and b/assets/images/jfr/jfr_threads_lock.jpg differ
diff --git a/assets/images/jfr/jfr_threads_overview.jpg b/assets/images/jfr/jfr_threads_overview.jpg
new file mode 100755
index 0000000..99b811a
Binary files /dev/null and b/assets/images/jfr/jfr_threads_overview.jpg differ
diff --git a/assets/images/me.jpg b/assets/images/me.jpg
new file mode 100755
index 0000000..a0aceeb
Binary files /dev/null and b/assets/images/me.jpg differ
diff --git a/staticman.yml b/staticman.yml
new file mode 100644
index 0000000..1d04e12
--- /dev/null
+++ b/staticman.yml
@@ -0,0 +1,16 @@
+comments:
+  allowedFields          : ['name', 'email', 'url', 'message']
+  branch                 : "master"
+  commitMessage          : "New comment."
+  filename               : comment-{@timestamp}
+  format                 : "yaml"
+  moderation             : true
+  path                   : "_data/comments/{options.slug}" # "/_data/comments/{options.slug}" (default)
+  requiredFields         : ['name', 'email', 'message']
+  transforms:
+    email                : "md5"
+  generatedFields:
+    date:
+      type               : "date"
+      options:
+        format           : "iso8601" # "iso8601" (default), "timestamp-seconds", "timestamp-milliseconds"
diff --git a/syncSite.sh b/syncSite.sh
new file mode 100755
index 0000000..7c2e735
--- /dev/null
+++ b/syncSite.sh
@@ -0,0 +1,39 @@
+#!/bin/bash
+deployDir=$(pwd)/_deploy
+siteDir=$(pwd)/_site
+siteUrl=https://github.com/skyscribe/skyscribe.github.io.git
+
+function setup() {
+    rm -fr $deployDir
+    mkdir -p $deployDir
+    cd "$deployDir"
+    git init
+    echo "dummy content" > index.html
+    git add .
+    git commit -m "dummy script init"
+    git branch -m master
+    git remote add origin "$siteUrl"
+    echo "Setup complete for $deployDir"
+}
+
+function deploy() {
+    bundle exec jekyll build
+    cd "$deployDir"
+    cp -r "$siteDir"/* "$deployDir/"
+    git pull origin master
+    git add -A
+    now=$(date "+%Y-%m-%d_%H:%M:%S")
+    git commit -m "site updated at $now"
+    git push origin master --force
+    echo "deploy completed"
+}
+
+case $1 in
+  setup)
+	    setup
+        ;;
+
+    * )
+        deploy
+        ;;
+esac
diff --git a/uml/a3fb2209926e5a47517b52b7b7751dc0.uml b/uml/a3fb2209926e5a47517b52b7b7751dc0.uml
new file mode 100644
index 0000000..7462c1c
--- /dev/null
+++ b/uml/a3fb2209926e5a47517b52b7b7751dc0.uml
@@ -0,0 +1,54 @@
+@startuml
+
+class InterfaceScheduler{
+    This calls is responsible for scheduling external interface calls to managed workers according to specified call property.
+    A fixed number of thread pools are started by default to serve call requests (given asynchronous call required)
+    It is also supported to run multiple calls as a strand such that calls are forced without concurrent data access
+    --
+    void start(size_t poolSize)
+    void stop()
+    bool registerInterface(const std::string& name, std::function<bool(ParaArgsBase&)> cb)
+    bool interfaceCall(const std::string& name, CallProperty&& prop, const Args&... args)
+}
+
+class CallProperty{
+    Providing calling specialities declaration
+    --
+    bool async
+    bool waitForDone
+    std::function<bool()> onCallDone
+    std::string strand
+}
+
+class SyncWorker{
+    Schedule the actual job within the same context as caller
+    --
+    bool doJob(Callable call, Callable onCallDone)
+}
+
+note top of AsyncWorker: each AsyncWorker wraps an unique thread to run designated jobs, and may associate with many strands
+class AsyncWorker <<ActiveObject>>{
+    Wrap an asynchronous thread (active object) to run all outstanding jobs assigned one by one
+    Also provide wrapper for synchronous job execution, calling context would be blocked until job actually executed
+    --
+    bool doJob(Callable call, Callable onCallDone)
+    bool doSyncJob(Callable call, Callable onCallDone)
+    bool blockUntilReady()
+    bool stop()
+    size_t getLoad()
+    std::thread::id getId()
+}
+
+note right of ServiceImplementor: different business scenario may provide differnt services
+class ServiceImplementor <<ScenarioImpl>>{
+    The actual service implementation class which supply a certain service and registers itself for other entities to call 
+    --
+}
+
+InterfaceScheduler .. CallProperty : uses >
+InterfaceScheduler "1" *-- "1" SyncWorker : contains
+InterfaceScheduler "1" *-- "many" AsyncWorker : contains
+ServiceImplementor "many" -- "1" InterfaceScheduler : uses >
+ServiceImplementor "many" -- "many" ServiceImplementor : uses >
+
+@enduml
\ No newline at end of file
